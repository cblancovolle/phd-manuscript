#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\usepackage{pifont}
\usepackage{graphicx}
\usepackage{forest}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
linguistics
\end_modules
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\float_alignment class
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008080
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Title
Adaptive Control via Local Online Learning
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
This thesis is financed by an automotive company.
 Initially the goal was to work on intelligent speed recommendation.
\end_layout

\begin_layout Plain Layout
I structure my introduction this way:
\end_layout

\begin_layout Plain Layout
- 1.
 Background and Motivation
\end_layout

\begin_layout Plain Layout
- 2.
 Problem Statement
\end_layout

\begin_layout Plain Layout
- 3.
 Contributions
\end_layout

\begin_layout Plain Layout
In 1.
 I want to present why our company cares about speed recommendation.
 Then,
 in this part I also want to show a short review of literature to show that several speed management systems are considered in research:
\end_layout

\begin_layout Plain Layout
- Open Loop systems => that recommend speed to the driver via simple rule based approaches without considering any driver feedback => These approaches are more interpretable but limited in terms of objectives considered and do not enable personalization
\end_layout

\begin_layout Plain Layout
- Closed Loop systems => that control the speed of the vehicle in an autonomous way => performance but no consideration of the driver
\end_layout

\begin_layout Plain Layout
We notice that both approaches are inherently limited in their consideration of the driver.
 Indeed,
 in a speed recommendation context,
 the driver can delay,
 accept or refuse a speed recommendation set point.
 Moreover,
 as introducing the driver in the loop generates uncertainty because all human drivers are different,
 speed recommendations should be personalized to each one to better align with their driving style to maximize acceptance of recommendation set points.
 In addition to that,
 to maximize acceptance and the positive behavioral impact on driving,
 speed recommendation strategies should be interpretable to be able to justify their decisions to some extent to the driver.
\end_layout

\begin_layout Plain Layout
To bridge the gap between performant autonomous approaches and speed recommendation systems,
 we propose to tackle the speed recommendation problem as a control problem under the assumption that the vehicle-driver system is continuously modeled to account for the non-stationarity of the driver behavior over his life.
 Formulated in this way,
 the speed recommendation problem is reduced to an adaptive control problem with a learned model.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This research investigates the use of local online learning methods based on multi-agent self organization mechanisms to control complex,
 non-stationary systems where the underlying dynamics are unknown beforehand.
 
\end_layout

\begin_layout Standard
While this work was initiated within the industrial framework of Intelligent Speed Recommendation for the automotive sector,
 we came to the conclusion that the fundamental scientific bottleneck lies in the ability of a controller to adapt continuously to non-stationary dynamics.
\end_layout

\begin_layout Standard
We structure the remainder of this introductory chapter as following.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Background-and-Motivation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 presents a contextualization on speed management systems and their current limitations.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Statement"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows how a speed recommendation problem can be asbtracted into an adaptive control problem with a continuously learning model.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Contributions"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 exposes a summary of all the contributions of our work to the fields of 
\emph on
online learning
\emph default
 and 
\emph on
control with learned models
\emph default
.
\end_layout

\begin_layout Section
Background and Motivation
\begin_inset CommandInset label
LatexCommand label
name "sec:Background-and-Motivation"

\end_inset


\end_layout

\begin_layout Standard
Excesses and mismanagement of speed on the roads have been proven to be positively correlated to the occurence of accidents with injuries and fatalities 
\begin_inset CommandInset citation
LatexCommand citep
key "hauerSpeedSafety2009,elvikSpeedRoadSafety2005"
literal "false"

\end_inset

.
 Studies have shown that vehicle speed control devices like Intelligent Speed Assist (ISA) could significantly contribute to the reduction of road accidents 
\begin_inset CommandInset citation
LatexCommand cite
key "tate1997implementation"
literal "false"

\end_inset

.
 Moreover,
 better speed management can lead to significant reduction in energy consumption 
\begin_inset CommandInset citation
LatexCommand cite
key "xu2021overview"
literal "false"

\end_inset

 making this issue a strategic concern for individuals,
 but also for fleet management companies 
\begin_inset CommandInset citation
LatexCommand cite
key "atri2024operational"
literal "false"

\end_inset

.
 Consequently,
 developing speed management technologies that help drivers maintain safe and efficient speeds is essential for public safety and for the sustainable development of the automotive industry.
\end_layout

\begin_layout Standard
From an industrial perspective,
 the main challenge for developing intelligent speed recommendation devices lies in designing a system that effectively influence vehicle speed while maintaining a high level of user acceptance,
 safety and energy efficiency.
 As the driver can chose to 
\emph on
accept
\emph default
,
 
\emph on
delay
\emph default
 or 
\emph on
refuse
\emph default
 a recommended speed set point,
 the effectivenes of such recommendation systems is largely determined by the underlying control architecture and how it interacts with an unpredictable human driver.
\end_layout

\begin_layout Standard
Research on speed management can be broken down into two distinct branches as displayed on Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Taxonomy-of-Vehicle"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 On one hand,
 
\emph on
Open-Loop
\emph default
 systems presented in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Open-Loop"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 comprise mainly advisory systems that do not consider any form of feedback from the vehicle state or driver response to recommendation set points.
 On the other hand,
 
\emph on
Closed-Loop
\emph default
 systems presented in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Closed-Loop"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 consider feedbacks from the vehicle state,
 removing the driver from the execution loop,
 enabling for safety guarantees,
 and stability and self correction.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Synthesis-and-Research-Gap"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a synthesis of research gaps identified after analysis of the literature.
 
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{
\backslash
columnwidth}{!}{%
\end_layout

\begin_layout Plain Layout


\backslash
begin{forest}
\end_layout

\begin_layout Plain Layout

for tree={
\end_layout

\begin_layout Plain Layout

	l sep=30pt
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

[Speed Management
\end_layout

\begin_layout Plain Layout

  [Open-Loop Systems
\end_layout

\begin_layout Plain Layout

    [Heuristic / Rules]
\end_layout

\begin_layout Plain Layout

    [Optimization]
\end_layout

\begin_layout Plain Layout

    [Offline Planning]
\end_layout

\begin_layout Plain Layout

    [Infrastructures]
\end_layout

\begin_layout Plain Layout

  ]
\end_layout

\begin_layout Plain Layout

  [Closed-Loop Systems
\end_layout

\begin_layout Plain Layout

	[Feedback Laws]
\end_layout

\begin_layout Plain Layout

    [Online Planning]
\end_layout

\begin_layout Plain Layout

	[Model-Free]
\end_layout

\begin_layout Plain Layout

    [HitL]
\end_layout

\begin_layout Plain Layout

  ]
\end_layout

\begin_layout Plain Layout

]
\end_layout

\begin_layout Plain Layout


\backslash
end{forest}%
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Taxonomy-of-Vehicle"

\end_inset

Taxonomy of Vehicle Speed Management approaches
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Open-Loop
\begin_inset CommandInset label
LatexCommand label
name "subsec:Open-Loop"

\end_inset


\end_layout

\begin_layout Standard
Open loop systems correspond to systems that do not consider feedback from the driver or vehicle state.
 In the speed management literature,
 these works primarily focus on translating environment constraints such as traffic light timings 
\begin_inset CommandInset citation
LatexCommand cite
key "krauseTrafficLightAssistantDriven2012,alsabaanOptimizationFuelCost2013"
literal "false"

\end_inset

,
 weather conditions 
\begin_inset CommandInset citation
LatexCommand cite
key "galanisEnvironmentalBasedSpeedRecommendation2019"
literal "false"

\end_inset

 or road geometry 
\begin_inset CommandInset citation
LatexCommand cite
key "hazoorDevelopmentNovelIntelligent2021"
literal "false"

\end_inset

,
 into recommended speed profiles.
 Among the proposed approaches,
 some employ advanced optimization techniques like Pontryagin's Maximum Principle 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayVelocityProfileOptimization2017"
literal "false"

\end_inset

 to maximize energy efficiency.
 Others rely on passive infrastructure-based interventions ranging from physical enforcements via road bumps 
\begin_inset CommandInset citation
LatexCommand cite
key "salauVehicleSpeedControl2004"
literal "false"

\end_inset

 to visual stimulations 
\begin_inset CommandInset citation
LatexCommand cite
key "zhaoHowDoesMural2022"
literal "false"

\end_inset

,
 aiming at increasing speed awareness through environmental design.
 
\end_layout

\begin_layout Standard
However,
 whether digital or physical,
 these approaches share the same structural limitation because they assume that the recommendation set points are going to be followed perfectly and instantaneously.
 This assumption ignores the non-stationarity and variability of human-behavior.
 Consequently,
 without online feedback mechanisms to account for driver acceptance,
 the theoretical benefits of these optimizations are rarely fully realized in real-world conditions.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Rules / Heuristics
\end_layout

\begin_layout Itemize
Communication of speed recommendation with smartphone (work on HMIs),
 rule-based approach based on traffic lights state and distance to traffic light to avoid dead stops (for energy consumption ) 
\begin_inset CommandInset citation
LatexCommand cite
key "krauseTrafficLightAssistantDriven2012"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Rule-based recommendation approach based on fusion of several data sources (weather,
 road profile,
 ...) and comparison to nominal speed profiles (for safety and comfort).
 
\begin_inset CommandInset citation
LatexCommand cite
key "galanisEnvironmentalBasedSpeedRecommendation2019"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Rule based recommendation approach based on Stopping Distance and Available Sight Distance (mainly for safety,
 then for energy efficiency) 
\begin_inset CommandInset citation
LatexCommand cite
key "hazoorDevelopmentNovelIntelligent2021"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Optimization
\end_layout

\begin_layout Itemize
Optimization based recommendation approach to determine the optimal Speed Limit (Variable Speed Limit problem) that is transmitted to the driver via V2I which is also used for collecting data for computind the optimal speed (for safety).
 
\begin_inset CommandInset citation
LatexCommand cite
key "wuCombinedConnectedVehicles2020"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Communication of speed recommendation with V2X (V2V and V2I).
 Optimization (Heuristic provided too for real time) based approach based on traffic light schedule (for energy consumption).
 
\begin_inset CommandInset citation
LatexCommand cite
key "alsabaanOptimizationFuelCost2013"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Optimization based speed recommendation method based on analytical PMP solution relying on offline linearization of road profile beforehand.
 Method is fast because analytical solution and adaptive a bit online because some parameters are dynamic (for energy consumption then for legal speed limit enforcement).
 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayVelocityProfileOptimization2017"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Offline Planning
\end_layout

\begin_layout Itemize
PMP speed control approach for cruising (for energy) which handles gear shifts and alternates between acceleration and idling.
 
\begin_inset CommandInset citation
LatexCommand cite
key "shenFuelOptimalPeriodicControl2018"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Infrastructures
\end_layout

\begin_layout Itemize
Infrastructure-based approach using road bumps.
 Communication of speed limitations to driver with signs and physical enforcement (vibration too hard above design speed limit).
 Study about road bump characteristics to enforce speed limit efficiently (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "salauVehicleSpeedControl2004"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Infrastructure / Heuristic approach using discontinuous mural decorations on tunnel sidewalls at specific frequencies to provide visual stimulation.
 It induces a passive psychological signal that enhances driver's ability to estimate his true speed => improving speed awareness and alertness (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhaoHowDoesMural2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Closed-Loop
\begin_inset CommandInset label
LatexCommand label
name "subsec:Closed-Loop"

\end_inset


\end_layout

\begin_layout Standard
Works on closed-loop speed management systems are rooted in the development of autonomous vehicles.
 In a sense,
 they resolve the main limitation of open-loop systems by completely ignoring the driver and focusing solely on vehicle control.
 In this context,
 the system plays an active role in speed regulation by acting directly on low level vehicle's actuators (throttle / brake),
 thereby bypassing the uncertainties of driver acceptance.
 The related literature can be divided into two technical branches:
 
\emph on
model-based online planning
\emph default
 and 
\emph on
data-driven
\emph default
 approaches.
\end_layout

\begin_layout Standard
On the one hand,
 model-based online planning approaches rely extensively on approaches on physical models of the vehicle coupled with Model Predictive Control (MPC) 
\begin_inset CommandInset citation
LatexCommand cite
key "asadiPredictiveCruiseControl2010,kamalModelPredictiveControl2012,hanSafeEcoDrivingControl2018"
literal "false"

\end_inset

,
 Pontryagin's Maximum Principle (PMP) 
\begin_inset CommandInset citation
LatexCommand cite
key "maEcodriveExperimentRolling2019,ozatayAnalyticalSolutionMinimum2014"
literal "false"

\end_inset

 or Dynamic Programming (DP) 
\begin_inset CommandInset citation
LatexCommand cite
key "sunOptimalEcoDrivingControl2020"
literal "false"

\end_inset

.
 These approaches take into account changes in the environment by solving constrained optimization problems in real-time that mostly balance energy efficiency,
 safety and travel time.
 Since solving many optimization problems can be costly,
 research efforts have focused on finding analytical solutions 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayAnalyticalSolutionMinimum2014,malikopoulosOptimalControlSpeed2018,hanSafeEcoDrivingControl2018"
literal "false"

\end_inset

 or using discretization techniques 
\begin_inset CommandInset citation
LatexCommand cite
key "jinPowerBasedOptimalLongitudinal2016,jinEnergyoptimalSpeedControl2023"
literal "false"

\end_inset

 to solve the optimization problems.
 These methods offer rigorous safety and stability guarantees as they rely on pre-defined physical models coupled with control theory.
 However,
 the main limitation exposed for open-loops systems remains,
 as the human driver is excluded form the control loop,
 resulting in mostly unusable systems when considering a human driver controlling the vehicle.
 Moreover,
 the capabilities of the resulting controllers depend on the accuracy of the physical models used.
 To ensure the controller operates in real-time,
 it is often necessary to make compromises on the complexity and accuracy of the physical model,
 making it more difficult to handle larger number of variables.
\end_layout

\begin_layout Standard
On the other hand,
 data-driven approaches have emerged to address the limitations of physical modeling,
 particularly for capturing complex,
 non-linear behaviors that are difficult to formalize analytically.
 By leveraging Reinforcement Learning,
 data-driven approaches simplify multi-objective optimization through the design of reward functions that balance energy,
 safety and comfort 
\begin_inset CommandInset citation
LatexCommand cite
key "xuHierarchicalSpeedControl2022,duComfortableEnergyefficientSpeed2022,liuLongitudinalControlConnected2023"
literal "false"

\end_inset

.
 Various architectures are leveraged to handle speed control tasks such as DDPG for car-following and heavy vehicles 
\begin_inset CommandInset citation
LatexCommand cite
key "sunDDPGBasedDecisionMakingStrategy2020,moghaddam2024cooperative"
literal "false"

\end_inset

,
 PPO for traffic efficiency 
\begin_inset CommandInset citation
LatexCommand cite
key "xuHierarchicalSpeedControl2022,liuLongitudinalControlConnected2023,zhao2024adaptive"
literal "false"

\end_inset

 or SAC and DQN for safe speed control 
\begin_inset CommandInset citation
LatexCommand cite
key "jiangReinforcementLearningBased2022,kim2025reinforcement"
literal "false"

\end_inset

.
 These methods also allow to generate human-like profiles by learning directly from vast datasets of driving trajectories 
\begin_inset CommandInset citation
LatexCommand cite
key "zhangHumanlikeAutonomousVehicle2018,zhuHumanlikeAutonomousCarfollowing2018"
literal "false"

\end_inset

.
 However,
 these approaches rely on extensive and sample inefficient training,
 resulting in frozen policies that cannot adapt to the non-stationary nature of the road environment.
 Furthermore,
 compared to model-based methods,
 data-driven controllers lack formal safety and stability guarantees.
 They mostly rely on neural networks which make enforcing hard constraints difficult in safety-critical control systems due to the brittleness of their predictions outside the training distribution and to the interpretability of their inner workings 
\begin_inset CommandInset citation
LatexCommand cite
key "zhang2020testing"
literal "false"

\end_inset

.
 Neural networks can be very successful but are black-boxes that are hard to trust and validate.
 Specifically in industrial safety critical use cases,
 the use of neural networks is mostly reduced to small certifiable networks,
 largely limiting the scalability potential 
\begin_inset CommandInset citation
LatexCommand cite
key "zhang2020testing"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Despite their differences,
 both model-based and data-driven closed-loop architectures share a common limitation:
 they prioritize the autonomy of the vehicle denying authority of the driver on his vehicle.
 Human-in-the-Loop (HitL) systems seek to tackle this limitation.
 These approaches attempt to reintegrate the driver into the control loop by treating human behavior as a dynamic variable of the problem rather than ignoring it by considering vehicle autonomy.
 In this field,
 literature focuses on personalizing speed recommendations by monitoring physiological signals such as heart rate to model stress levels 
\begin_inset CommandInset citation
LatexCommand cite
key "maganaDesignSpeedAssistant2017"
literal "false"

\end_inset

,
 or by estimating driver acceptance scores to modulate the speed recommendation strategy 
\begin_inset CommandInset citation
LatexCommand cite
key "vyas2021drivebfr"
literal "false"

\end_inset

.
 Other works use simple online reinforcement learning strategies to steer cloud-based planning toward the driver's historical preferences 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayCloudBasedVelocityProfile2014"
literal "false"

\end_inset

 or use context-aware models to predict expert driver reactions on blind intersections 
\begin_inset CommandInset citation
LatexCommand cite
key "saitoContextawareDriverModel2021"
literal "false"

\end_inset

.
 These approaches represent significant step toward driver consideration into closed-loop systems.
 However,
 they still remain limited by their offline nature.
 Most of these HitL systems are built upon static databases or pre-trained driver profiles that fail to account for the variability of human driving behaviors and for the non-stationarity of those behaviors that can evolve over time.
 In reality,
 a driver's response is not a fixed parameter but a non-stationary process influenced by physiological states,
 environmental context and lon-term behavioral adaptation.
 
\end_layout

\begin_layout Subsection
Synthesis and Research Gap
\begin_inset CommandInset label
LatexCommand label
name "subsec:Synthesis-and-Research-Gap"

\end_inset


\end_layout

\begin_layout Standard
The review of the literature on speed management systems reveals a significant gap in the state of the art.
 Open-loop advisory systems respect driver's autonomy but lack the consideration of feedbacks on driver's behavior to ensure high effectiveness.
 Conversely,
 closed-loop autonomous systems offer high performance and theoretical guarantees but exclude the human driver from the execution loop.
 Finally,
 Human-in-the-loop methods that try to reinsert the driver in the loop through personalization and data-driven approaches,
 are limited by their inability to adapt in real-time to non-stationary behavior and learn continuously.
\end_layout

\begin_layout Standard
We identified a research gap in the lack of interpretable methods capable of learning continuously to adapt to the non-stationarity of the human driver behavior.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Statement"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows that from the identified research gap,
 the industrial speed recommendation problem can be abstracted to a more fundamental scientific challenge which is the control of complex non-stationary systems.
 By considering the vehicle-driver plant as a whole with unknown non-stationary dynamics,
 the problem is reformulated as a task of Adaptive Control with a Learned Model which represents the core focus of this thesis.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Feedback Laws
\end_layout

\begin_layout Itemize
Offline Policy computation via Stochastic Dynamic Programming from Markov Chains then online exploitation of the policy from feedback on terrain (for tradeoff between energy and travel speed) 
\begin_inset CommandInset citation
LatexCommand cite
key "kolmanovskyTerrainTrafficOptimized2010"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $H_{\infty}$
\end_inset

 control for eco-driving speed control for car following scenario (for energy and safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "chenComparativeStudyModel2021"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Online Planning
\end_layout

\begin_layout Itemize
Eco-driving speed control approach using Relaxed PMP from V2I data for planning and PID for speed trajectory tracking (for energy with safety constraints).
 Similar to MPC.
 
\begin_inset CommandInset citation
LatexCommand cite
key "maEcodriveExperimentRolling2019"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dynamic Programming speed control in space (not time) to make it suitable for online planning.
 Method to handle traffic lights intersections (for energy with safety constraints).
 
\begin_inset CommandInset citation
LatexCommand cite
key "sunOptimalEcoDrivingControl2020"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Predictive Cuise Control using MPC + Rules to determine target speed to handle traffic light intersections (for energy,
 travel time,
 safety,
 comfort).
 
\begin_inset CommandInset citation
LatexCommand cite
key "asadiPredictiveCruiseControl2010"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC for speed control with real time traffic information and V2V / V2I communication (vehicles / traffic signals).
 Mainly an advanced ACC system (for energy,
 safety,
 comfort) 
\begin_inset CommandInset citation
LatexCommand cite
key "kamalModelPredictiveControl2012"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC with analytical solution (for energy,
 safety and legality) for autonomous connected vehicle.
 
\begin_inset CommandInset citation
LatexCommand cite
key "hanSafeEcoDrivingControl2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC optimized with Mixed Integer Linear Programming (MILP) for speed control.
 Discretization of states to make the optimization faster in an online setting.
 Heavy offline computations to compute costs for discretized map.
 (for energy and safety).
\begin_inset CommandInset citation
LatexCommand cite
key "jinPowerBasedOptimalLongitudinal2016"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC optimized with MILP for speed control (for energy and safety) for buses.
 
\begin_inset CommandInset citation
LatexCommand cite
key "jinEnergyoptimalSpeedControl2023"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Analytical solution to PMP for speed control (intelligent cruise control) under some assumptions to allow for real time recomputations and embedding on board of the vehicle (for energy).
 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayAnalyticalSolutionMinimum2014"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Analytical solution for speed control based on Hamiltonian analysis to tackle approach of speed reduction zones or bottlenecks (for energy and safety).
 
\begin_inset CommandInset citation
LatexCommand cite
key "malikopoulosOptimalControlSpeed2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MinMax on learned transition model to control the speed of the vehicle (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "messaoudiAgentbasedIntervehicleCooperative2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Model-based RL for eco-driving (for energy).
 Maintain domain knowledge of vehicle dynamics while maintaining model-free adaptability.
 
\begin_inset CommandInset citation
LatexCommand cite
key "leeModelBasedReinforcementLearning2020"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Model-Free
\end_layout

\begin_layout Itemize
Policy gradient RL for speed control for safe longitudinal car following (safety and efficiency).
 
\begin_inset CommandInset citation
LatexCommand cite
key "desjardinsCooperativeAdaptiveCruise2011"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
RL based dynamic speed limit control model for stochastic traffic networks (for energy consumption of vehicles in the network) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhuAccountingDynamicSpeed2014"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Human-like speed control through Deep Q Learning (for human-like behavior) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhangHumanlikeAutonomousVehicle2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Human-like speed control through DDPG for car following (for human-like behavior) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhuHumanlikeAutonomousCarfollowing2018"
literal "false"

\end_inset

 
\end_layout

\begin_layout Itemize
Speed control through variant of PPO (for safety,
 energy and comfort) 
\begin_inset CommandInset citation
LatexCommand cite
key "xuHierarchicalSpeedControl2022"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Adaptive Cruising (speed control) of heavy vehicles through DDPG (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "sunDDPGBasedDecisionMakingStrategy2020"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Speed control on rough pavement through DDPG (for comfort and energy) 
\begin_inset CommandInset citation
LatexCommand cite
key "duComfortableEnergyefficientSpeed2022"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Longitudinal speed control through Soft-Actor-Critic (SAC) (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "jiangReinforcementLearningBased2022"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Speed control through PPO with reward shaping (for energy,
 safety,
 traffic efficiency) 
\begin_inset CommandInset citation
LatexCommand cite
key "liuLongitudinalControlConnected2023"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Variable Speed Limit throught DQN 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2025reinforcement"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Adaptive Cruise Control using safe Deep Reinforcement Learning (Projected Constrained Policy Optimization) (for safety and traffic efficiency) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2024adaptive"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Adaptive Cruise Control suing DDPG (for safety,
 comfort,
 energy) 
\begin_inset CommandInset citation
LatexCommand cite
key "moghaddam2024cooperative"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Rule-based
\end_layout

\begin_layout Itemize
Rule based geometric approach to account for curve estimation and legal constraints (mainly for safety)
\begin_inset CommandInset citation
LatexCommand cite
key "gamezsernaDynamicSpeedAdaptation2017"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Human-in-the-Loop
\end_layout

\begin_layout Itemize
Offline planning via Dynamic Programming (before trip) but a simple reinforcement learning module looks online to maximize acceptance by steering the recommendations towards an acceptable range (for energy) 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayCloudBasedVelocityProfile2014"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Offline computation via Dynamic Programming of optimal speed profile to then obtain local action rules for elementary road sections.
 These actions rules are chosen dynamically online to give speed recommendations (for energy with safety / legality constraints).
 
\begin_inset CommandInset citation
LatexCommand cite
key "jimenezRealtimeSpeedProfile2013"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Speed Recommendation approach that monitors state of vehicle and traffic signal's state to dynamically calculate speed recommendation set points to avoid red light dead stop based on remaining distance (for energy).
 Safety override to avoid danger.
 
\begin_inset CommandInset citation
LatexCommand cite
key "mahlerCellularCommunicationTraffic2017"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Particle Swarm Optimization and Deep Learning to estimate and recommend optimal average speed for upcoming road segments.
 Balancing predicted driver stress level estimated from heart rate and driving behavior against total trip time (for comfort) 
\begin_inset CommandInset citation
LatexCommand cite
key "maganaDesignSpeedAssistant2017"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Estimation of driver behavior score through a Mixture of Expert method (Neural Net),
 then optimize to find the speed recommendation looking for a normal behavior and reduced energy consumption => Claim to be personalized but learned offline 
\begin_inset CommandInset citation
LatexCommand cite
key "vyas2021drivebfr"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Context-aware driver model that uses multiple linear regression and database of near-miss incidents to determine recommended driving speed for blind intersections (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "saitoContextawareDriverModel2021"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Problem Statement
\begin_inset CommandInset label
LatexCommand label
name "sec:Problem-Statement"

\end_inset


\end_layout

\begin_layout Standard
To address the gaps identified in the literature,
 this thesis proposes a shift in perspective.
 Rather than viewing speed recommendation as a static recommendation task,
 we treat it as a Human-Robot Collabotation (HRC) problem.
 For a robot to work effectively with humans,
 it requires anticipatory skills 
\begin_inset CommandInset citation
LatexCommand cite
key "dani2024human"
literal "false"

\end_inset

.
 The controller must infer the driver's intended motion and behavior to synchronize its recommendations effectively.
 By forecasting a human's response,
 the controller can provide set points that are complementary to the human's intent rather than being reactionary or disruptive.
\end_layout

\begin_layout Standard
Consequently,
 we propose to tackle the speed recommendation problem as a control problem under the assumption that the vehicle-driver plant is modeled as a whole.
 Given the non-stationarity and complexity of human behavior,
 this plant cannot be described by a static physical model.
 Instead,
 it must be continuously learned online from experience.
 Formulated in this way,
 the speed recommendation problem is abstracted into a problem of Adaptive Control that can be decomposed into two subproblems:
 
\series bold
online learning
\series default
 and 
\series bold
optimal control with learned model
\series default
.
\end_layout

\begin_layout Standard
First,
 the online learning subproblem consists in the continuous generation of a predictive model 
\begin_inset Formula $\hat{f}:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$
\end_inset

 of the vehicle-driver dynamics from a stream of state-action pairs 
\begin_inset Formula $\left[s_{t},u_{t}\right]\in\mathbb{R}^{n}$
\end_inset

.
 Function 
\begin_inset Formula $\hat{f}$
\end_inset

 maps a states and actions to next state prediction such as
\begin_inset Formula 
\begin{equation}
\hat{f}\left(s_{t},u_{t}\right)=s_{t+1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Then,
 the optimal control with learned model subproblem consists in the derivation of a control law that minimizes a cost function 
\begin_inset Formula $J$
\end_inset

 over a horizon 
\begin_inset Formula $H$
\end_inset

 based on the predictions of the learned model 
\begin_inset Formula $\hat{f}$
\end_inset

.
\end_layout

\begin_layout Standard
To solve these subproblems in a non-stationary environment,
 we argue for the necessity of using a local learning approach in which the feature space is partitioned into regions managed by local experts.
 This choice is driven by the requirements for interpretability and real-time adaptability.
 In the context of HRC,
 interpretability may not be a strict mathematical requirement for control but it is a functional necessity to ensure system certifiability 
\begin_inset CommandInset citation
LatexCommand cite
key "kress2021formalizing"
literal "false"

\end_inset

 and to improve human trust toward the controller 
\begin_inset CommandInset citation
LatexCommand cite
key "anjomshoae2019explainable"
literal "false"

\end_inset

.
 For safety,
 industrial standards require that the internal models driving the system's decisions be traceable and verifiable.
 This task remains notoriously difficult with black-box global approximators.
 For HRC,
 a human is more likely to accept and cooperate with a system whose behavior is predicatble and grounded in transparent logic.
\end_layout

\begin_layout Standard
Local learning provides transparency by decomposing complex global dynamics into a set of specialized local models.
 Unlike global architectures where a single weight update can unpredictably affect the entire model,
 a local learning approach can ensure that any update stays local.
 This spatialization ensures that any prediction is traceable to a specific region of the feature space.
\end_layout

\begin_layout Standard
Moreover,
 global approximation methods often struggle with the stability-plasticity dilemma 
\begin_inset CommandInset citation
LatexCommand cite
key "mermillod2013stability"
literal "false"

\end_inset

 where learning new behaviors leads to the forgetting of old ones.
 With local learning methods,
 the model can adapt to new behaviors locally and incrementally without corrupting knowledge stored in other regions.
 This allows the model to remain accurate across different driving contexts without requiring computationally heavy,
 and often impossible,
 offline training.
\end_layout

\begin_layout Standard
The long-term goal of this research is to enable efficient HRC,
 specifically in the automotive sector.
 This goal depends on the reliability of the underlying control architecture.
 Therefore,
 this thesis does not address the high-level social or psychological aspects of HRC but rather the foundational subproblems required to make the best out of HRC:
 local online learning and control with learned models.
 The following section details our contributions to these two research fields.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Itemize
For successful human-robot collaboration,
 the robot must infer the human's intended motion to synchronize its actions.
 Anticipatory skills are required for robots to work effectively with humans.
 By forecasting a human's trajectory,
 the robot can set a control set point that is complementary to the human's current and future behavior rather than being reactionary or disruptive.
 
\begin_inset CommandInset citation
LatexCommand cite
key "dani2024human"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Thus,
 from the previous statement,
 we deduce that to bridge the gap between performant autonomous approaches and speed recommendation systems,
 the speed recommendation problem can be tackled as a control problem under the assumption that the vehicle-driver system is continuously modeled to account for the non-stationarity of the driver behavior.
 Formulated in this way,
 the speed recommendation problem can be abstracted into an adaptive control problem with a learned model.
\end_layout

\begin_layout Itemize
Therefore,
 the problem can be broken down into 2 subproblems:
 Online modeling and Control with learned model [HOW TO JUSTIFY THIS MPC ARCHITECTURE ?]
\end_layout

\begin_layout Itemize
[SHOULD WE INTRODUCE LOCAL LEARNING HERE OR WAIT FOR STATE OF THE ART ?]
\end_layout

\begin_layout Plain Layout
We notice that both approaches are inherently limited in their consideration of the driver.
 Indeed,
 in a speed recommendation context,
 the driver can delay,
 accept or refuse a speed recommendation set point.
 Moreover,
 as introducing the driver in the loop generates uncertainty because all human drivers are different,
 speed recommendations should be personalized to each one to better align with their driving style to maximize acceptance of recommendation set points.
 In addition to that,
 to maximize acceptance and the positive behavioral impact on driving,
 speed recommendation strategies should be interpretable to be able to justify their decisions to some extent to the driver.
\end_layout

\begin_layout Plain Layout
To bridge the gap between performant autonomous approaches and speed recommendation systems,
 we propose to tackle the speed recommendation problem as a control problem under the assumption that the vehicle-driver system is continuously modeled to account for the non-stationarity of the driver behavior over his life.
 Formulated in this way,
 the speed recommendation problem is reduced to an adaptive control problem with a learned model.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Contributions
\begin_inset CommandInset label
LatexCommand label
name "sec:Contributions"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Itemize
In this thesis we contribute to online learning and control with learned models but we do not tackle HRC as is.
 This work represents a step toward HRC,
 works still remain to do.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="left" valignment="top" width="95col%">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intrinsic XAI through Self-Organization Analysis:
 Developed the oCELL algorithm and formalized a novel methodology leveraging agent self-organization structures to perform model introspection and infer underlying function properties for enhanced explainability and interpretability.
 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Empirical Evaluation of oCELL Performance:
 A low-dimensional comparative study demonstrating oCELL's competitive performance against SotA ensemble algorithms.
 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Non-Stationary Adaptation Capabilities:
 Development of the kCELL algorithm and a study demonstrating its ability to adapt to non-stationary dynamics for forward prediction,
 using introspection to analyze the system's behavior.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Integration for Constrained Optimal Control:
 Formalization of a novel coupling method to integrate the kCELL learning mechanism into traditional optimization solvers for solving complex constrained optimal control problems with learned models.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Introspection-Enhanced Safe Control:
 Proposal of a novel methodology that utilizes kCELL's intrinsic introspection capabilities to enhance the safety and performance of the solved constrained optimal control problems with learned models.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Constraint-Impact Explainability Method:
 Proposal of a novel XAI method leveraging kCELL's structure to quantify and explain the impact of constraints on optimization outcomes in safe control.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scalable CELL Spatialization:
 Proposal of Principal Component Analysis (PCA) as a novel technique to scale the CELL paradigm to higher-dimensional feature spaces,
 including a comparative evaluation.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scalable Gaussian Process Learning (SGP-CELL):
 Development of the SGP-CELL algorithm,
 a novel machine learning model that leverages the CELL paradigm to achieve online learning and scalability in Gaussian Processes (GP) with respect to the number of data points.
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of Contributions
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Chapter
State of the Art
\begin_inset CommandInset label
LatexCommand label
name "chap:State-of-the-Art"

\end_inset


\end_layout

\begin_layout Standard
This chapter provides a comprehensive review of the literature on speed recommendation systems.
 We decompose the problem into two sub-problems:
 a 
\emph on
modeling problem
\emph default
,
 which involves continuously estimating vehicle dynamics under driver-specific influence to enable personalized and realistic speed recommendations;
 and a 
\emph on
control problem
\emph default
,
 which leverages the learned model to optimize speed profiles with respect to predefined objectives and operational constraints.
 To establish a rigorous foundation and position our approach within the field,
 we examine state-of-the-art methods across three relevant domains:
 speed control and recommendation,
 online machine learning and  optimal control.
\end_layout

\begin_layout Section
Vehicle Speed Management
\end_layout

\begin_layout Subsection
Open-Loop Speed Recommendation
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
- Absence of feedback signals from the vehicle actual state or the driver response to a recommendation set point
\end_layout

\begin_layout Plain Layout
- Mainly information layers based on generalist rules translating environment and legal constraints into advisory set points
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
* Heuristic and Rule-Based
\end_layout

\begin_layout Plain Layout
* Context Aware
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Open-loop speed recommendation systems can be defined as all the speed management systems that consider the driver as an external component to the system.
 In this case the system do not receive the driver's response into the recommendation logic,
 ignoring if the driver accepts,
 delays or refuses the recommendation.
 Thus,
 the system works mainly as an information layer to the driver,
 translating environment and legal constraints into speed recommendation set points.
\end_layout

\begin_layout Subsubsection
Heuristic and Rule-based
\end_layout

\begin_layout Subsubsection
Context Aware
\end_layout

\begin_layout Subsection
Closed-Loop Speed Control
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
* State Feedback Regulation (PID,
 LQR,
 Hinf) => reactive approaches (not proactive),
 hard to consider constraints,
 do not consider driver,
 mainly linear approaches
\end_layout

\begin_layout Plain Layout
* Optimal Trajectory Planning [
\end_layout

\begin_layout Plain Layout
- Offline Trajectory Planning (PMP,
 Dynamic Programming) => computationally heavy,
 not suited for real-time control
\end_layout

\begin_layout Plain Layout
- Online Trajectory Planning (MPC) with receding horizon => handles constraints in real time depending on chosen optimizer
\end_layout

\begin_layout Plain Layout
]
\end_layout

\begin_layout Plain Layout
* Learning Based Control (model free RL) => handles complex nonlinear scenarios,
 too sample inefficient,
 need accurate simulators (hard reality gap),
 MDP assumption that does not fit when considering driver in the loop
\end_layout

\begin_layout Plain Layout
=> Rigorous framework grounded in robust optimization pipelines for optimizing speed.
 However,
 their primary limitations is that they treat the vehicle as a robot that follows command perfectly.
 In a speed recommendation context,
 the actuator is the driver who may delay or refuse the command.
\end_layout

\begin_layout Plain Layout
To apply those tools to speed recommendation we must consider the driver-vehicle system as a whole with its uncertainties.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Human-in-the-Loop Control
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
- Speed recommendation should be treated as a control problem (unified framework).
\end_layout

\begin_layout Plain Layout
- A signal is send to the driver which adds uncertainty into the system.
 Indeed,
 the driver can refuse or delay the application of speed set points.
 Furthermore each driver is different and has a behavior that evolves over his life.
 => NOT A TRADITIONAL ACTUATOR
\end_layout

\begin_layout Plain Layout
- [Acceptance Hypothesis LOOK FOR LITERATURE] Acceptance of a speed recommendation inversely proportional to the behavioral proximity between the proposed set point and the driver's natural habits.
 => need also for explainability to justify decisions to the driver to enhance acceptance
\end_layout

\begin_layout Plain Layout
- Necessity to break down speed recommendation into 2 subproblems (modeling,
 exploiting).
\end_layout

\begin_layout Plain Layout
* Can't use RL because we can't simulate each driver individually
\end_layout

\begin_layout Plain Layout
- We need to learn and update the model online to continuously model the evolution of the driver behavior
\end_layout

\begin_layout Plain Layout
/!
\backslash
 INTRODUCE XAI /!
\backslash
 as a need to justify 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Online Machine Learning
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
scalebox{.8}{
\backslash
begin{forest}
\end_layout

\begin_layout Plain Layout

for tree={
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

[Online Machine Learning
\end_layout

\begin_layout Plain Layout

	[Parametric]
\end_layout

\begin_layout Plain Layout

	[Non Parametric
\end_layout

\begin_layout Plain Layout

    	[Probabilistic]
\end_layout

\begin_layout Plain Layout

		[Trees]
\end_layout

\begin_layout Plain Layout

    	[Local Learning]
\end_layout

\begin_layout Plain Layout

	]
\end_layout

\begin_layout Plain Layout

]
\end_layout

\begin_layout Plain Layout


\backslash
end{forest}}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Taxonomy of Vehicle Speed Management approaches
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
TAXONOMY
\end_layout

\begin_layout Plain Layout
* Parametric (Fixed Complexity) (Neural Nets + SGD,
 RLS,
 Kalman Filters)
\end_layout

\begin_layout Plain Layout
// * Adaptive Drift Detection (ADWIN,
 DDM,
 EDDM,
 ...)
\end_layout

\begin_layout Plain Layout
* Non Parametric (Adaptive Complexity) [
\end_layout

\begin_layout Plain Layout
- Probabilistic (Online GPs,
 Bayesian,)
\end_layout

\begin_layout Plain Layout
- Local Learning (LWPR,
 kNN,
 SACL) => our work falls in that
\end_layout

\begin_layout Plain Layout
- Tree-based (Hoeffding Trees,
 )
\end_layout

\begin_layout Plain Layout
]
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
PLAN
\end_layout

\begin_layout Plain Layout
- Parametric Methods => NN whole model modified,
 risk of catastrophic forgetting;
 RLS,
 Kalman are linear and myopic
\end_layout

\begin_layout Plain Layout
- Tree-based Online Learning (Hoeffding Trees,
 EFDT,
 Online Random Forest) => non differentiable which is a disadvantage for control
\end_layout

\begin_layout Plain Layout
- Probabilistic and Uncertainty-aware (Online GPs) => good models but computationally heavy and memory heavy
\end_layout

\begin_layout Plain Layout
- Local Learning & Memory-Based (LWPR,
 kNN,
 SACL) =>
\end_layout

\begin_layout Plain Layout
- Ensemble Learning to enhance robustness => weighted weak learners depending on individual performances => to handle concept drift ?
 => loss of interpretability (trade with explainability)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Start with supervised learning,
 then machine learning then ensemble learning then online learning
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We provide an overview of related works about multiagent learning,
 ensemble methods and eXplainable AI (XAI) to better situate the CELL paradigm within the existing literature.
\end_layout

\begin_layout Subsection
Multi-Agent Learning
\end_layout

\begin_layout Standard
Multi-agent systems (MAS) have gained popularity due to their ability to solve complex problems by breaking them down into simpler sub-problems that can be easily addressed by autonomous agents,
 whether interconnected or not 
\begin_inset CommandInset citation
LatexCommand cite
key "dorri2018multi"
literal "false"

\end_inset

.
 The interaction rules between agents or with the environment are defined by the system designer to achieve a specific objective.
 The use of MAS has proven effective in fields such as civil engineering 
\begin_inset CommandInset citation
LatexCommand cite
key "SHAMSHIRBAND20132105"
literal "false"

\end_inset

 or electrical engineering,
 particularly with issues related to smart grids 
\begin_inset CommandInset citation
LatexCommand cite
key "rohbogner2014design"
literal "false"

\end_inset

.
 In more recent years,
 reinforcement learning has been seriously considered to bypass the phase of designing rules that define agent behavior.
 Indeed,
 in Multi-Agent Reinforcement Learning (MARL),
 agents' behaviors are learned using reinforcement signals obtained by continuously interacting with an environment 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In this chapter,
 we present various two instantiations of CELL,
 a MAS paradigm derived from the Self Adaptive Context Learning (SACL) 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 that combines both approaches to tackle online supervised learning problems.
 Agents of the system update using both reinforcement learning signals and cooperation rules.
 Unlike MARL,
 CELL requires fewer environment interactions and focuses on specialized agents collaborating within a supervised learning framework,
 differing from MARL's dynamic interactions aiming to maximize cumulative rewards through adaptive strategies (
\emph on
competitive
\emph default
 or 
\emph on
cooperative
\emph default
) 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Ensemble Learning
\end_layout

\begin_layout Standard
To achieve more accurate predictions and provide better approximations of nonlinear functions,
 it is common to aggregate multiple models for making predictions.
\end_layout

\begin_layout Standard
Ensemble learning is based on the emergence of collective intelligence within a set of weak learners.
 A weak learner is a model whose performance is at least as good as a model making random predictions.
 During the learning process,
 a set of models (which may differ from one another) are trained in parallel or sequentially 
\begin_inset CommandInset citation
LatexCommand cite
key "polikarEnsembleLearning2012"
literal "false"

\end_inset

.
 The objective is to encourage diversity among the models so that they do not all capture the same patterns in the data 
\begin_inset CommandInset citation
LatexCommand cite
key "dietterichEnsembleMethodsMachine2000"
literal "false"

\end_inset

.
 An input is transmitted to all weak learners,
 each of which makes a prediction proposal.
 A heuristic is implemented to select one of the proposals or to weight each of them in order to construct the final prediction.
 We distinguish several major approaches in ensemble learning which are Boosting,
 Bagging and Stacking.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add figure to compare bagging,
 boosting and stacking
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visual comparison of bagging,
 boosting and stacking
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Bagging 
\begin_inset CommandInset citation
LatexCommand cite
key "breiman1996bagging"
literal "false"

\end_inset

 multiple models (usually homogeneous) are trained in parallel on different subsets of the training data to introduce diversity,
 reduce variance and improve stability.
 Then the final prediction is obtained by averaging the predictions of the weak learners (regression) or by majority voting (classification).
 Unlike Bagging,
 in Boosting 
\begin_inset CommandInset citation
LatexCommand cite
key "freund1997decision"
literal "false"

\end_inset

,
 the models are trained sequentially.
 Each new model focuses on correcting the errors of the previous ones to reduce bias and improve accuracy.
 Then the final prediction is obtained from a weighted average of the predictions of the all the weak learners.
 Finally,
 there is Stacking 
\begin_inset CommandInset citation
LatexCommand cite
key "wolpert1992stacked"
literal "false"

\end_inset

 that falls under meta-learning.
 We train in parallel a set of heterogeneous models and then a meta-model is trained to combine the predictions of each model to obtain the final output of the system,
 in order to capture complementary strengths of each learning algorithms involved in the learning process.
\end_layout

\begin_layout Standard
The family of systems presented in this chapter,
 CELL,
 falls within ensemble learning and we could label it as a Bagging approach because we consider a set of weak learners as a collection of self-organizing cooperative agents.
 Each one of them is a local expert on the function to be approximated.
\end_layout

\begin_layout Subsection
XAI
\begin_inset CommandInset label
LatexCommand label
name "subsec:XAI"

\end_inset


\end_layout

\begin_layout Standard
The field of eXplainable Artificial Intelligence (XAI) addresses the opacity of complex models by providing insights into their decision-making processes.
 However,
 interpretability and explainability are defined in various ways 
\begin_inset CommandInset citation
LatexCommand cite
key "gilpin2018explaining,doshi2017towards"
literal "false"

\end_inset

 and often used interchangeably.
 Thus,
 following the distinction made in 
\begin_inset CommandInset citation
LatexCommand cite
key "burkart2021survey"
literal "false"

\end_inset

,
 we differentiate between interpretability and explainability.
 
\series bold
Interpretability
\series default
 is defined as the inherent ability to understand how the model works as a whole,
 focusing on the model's structure and mechanisms (i.e transparency).
 In contrast,
 
\series bold
Explainability 
\series default
is associated with the methodologies used to communicate the reasoning for a specific decision taken by a model.
 
\end_layout

\begin_layout Standard
Approaches such as deep learning achieve good performance across a wide variety of tasks.
 However,
 these approaches generate highly complex models.
 There must be a compromise between the model's performance and its ability to produce explainable predictions and interpretable structures 
\begin_inset CommandInset citation
LatexCommand cite
key "linardatosExplainableAIReview2020"
literal "false"

\end_inset

.
 Some approaches were developed to adress the explainability of predictions.
 SHAP looks for the impact of each feature on the prediction using cooperative game theory 
\begin_inset CommandInset citation
LatexCommand cite
key "lundberg2017unified"
literal "false"

\end_inset

 and LIME builds an interpretable surrogate model that approximate a black-box model locally 
\begin_inset CommandInset citation
LatexCommand cite
key "ribeiro2016should"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Within this discourse,
 machine learning models are typically categorized as white-box or black-box models 
\begin_inset CommandInset citation
LatexCommand cite
key "loyola-gonzalezBlackBoxVsWhiteBox2019"
literal "false"

\end_inset

.
 
\series bold
Black-box
\series default
 models have opaque and complex inner workings that are difficult for an external observer to understand.
 This categorisation includes deep learning models 
\begin_inset CommandInset citation
LatexCommand cite
key "lecunDeepLearning2015"
literal "false"

\end_inset

 and some ensemble models 
\begin_inset CommandInset citation
LatexCommand cite
key "breimanRandomForests2001,polikarEnsembleLearning2012,chenXGBoostScalableTree2016,keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

.
 Conversely,
 
\series bold
White-box
\series default
 models have simpler and less opaque inner workings.
 These models,
 considered more explainable than black-box models,
 include linear regression models 
\begin_inset CommandInset citation
LatexCommand cite
key "weisbergAppliedLinearRegression2005"
literal "false"

\end_inset

,
 decision trees 
\begin_inset CommandInset citation
LatexCommand cite
key "rokachDecisionTrees2005"
literal "false"

\end_inset

  and  other rule-based approaches.
 To achieve explainability,
 white-box models are preferred.
\end_layout

\begin_layout Standard
The explainability of a prediction is partly linked to the concept of uncertainty.
 An informed decision-making process must take uncertainty into account.
 We distinguish between epistemic uncertainty and aleatoric uncertainty 
\begin_inset CommandInset citation
LatexCommand cite
key "chuaDeepReinforcementLearning2018,hullermeierAleatoricEpistemicUncertainty2021"
literal "false"

\end_inset

.
 
\series bold
Aleatoric uncertainty
\series default
 arises from the inherent natural variations in the studied phenomena.
 It may be due to random fluctuations,
 measurement errors,
 or other unpredictable factors.
 
\series bold
Epistemic uncertainty
\series default
 on the other hands,
 stems from a lack of knowledge or complete understanding of the studied phenomenon.
 This type of uncertainty is related to the lack of data in certain regions of the feature space.
\end_layout

\begin_layout Section
Control with Learned Models
\end_layout

\begin_layout Subsubsection
Reinforcement Learning
\end_layout

\begin_layout Subsubsection
Model-Based approaches
\end_layout

\begin_layout Subsubsection
Exploration
\end_layout

\begin_layout Section
Positioning
\end_layout

\begin_layout Chapter
Context Ensemble Local Learning (CELL)
\begin_inset CommandInset label
LatexCommand label
name "chap:Context-Ensemble-Local"

\end_inset


\end_layout

\begin_layout Standard
To achieve speed recommendation,
 the behavior of a vehicle driven by a human driver in response to speed recommendation set points need to be modeled.
 Therefore,
 we need a modeling algorithm able to perform online learning and learn efficiently seeing a data point once while having transparent inner workings and explainable predictions.
 For that reason we explored the use of multiagent systems as a mean of solving supervised learning tasks.
 
\end_layout

\begin_layout Standard
As showed in 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 a supervised learning problem can be modeled as a multiagent system.
 This perspective offers several advantages,
 including design simplicity,
 transparency,
 interpretability and explainability properties that naturally emerge from the structural organization of agents.
\end_layout

\begin_layout Standard
Building upon the Self Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

,
 this chapter introduces the CELL (Context Ensemble Local Learning) learning paradigm,
 which provides the core hypotheses and theoretical grounds for designing spatialized multiagent learning systems suited for modeling the dynamics of complex systems from online streaming data.
 This paradigm addresses online supervised learning through self-organization of multiple local expert agents paving the feature space.
 These agents are created and updated dynamically according to predefined learning rules.
 Each agent occupies a specific region in feature space,
 representing the area where it is most confident in the quality of its predictions.
 Contrary to previous works on this type of system 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 we introduce novelties regarding explainability and interpretability while exploring new cooperation mechanisms between agents and new spatialization approaches.
\end_layout

\begin_layout Standard
By leveraging the spatialization of local experts and the inherent transparency of the model,
 we derive unique informative explainability properties that provide valuable insights about the approximated function.
 Furthermore,
 we outline practical guidelines for scaling with the number of agents,
 keeping a bounded computational complexity.
 Therefore,
 the CELL paradigm is introduced through two distinct learning systems:
 oCELL and kCELL.
\end_layout

\begin_layout Standard
First,
 in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 oCELL is introduced,
 its capabilities are presented in terms of predictive performance and explainability,
 as well as its structural limitations.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 then describes kCELL,
 a more robust and expressive instantiation of CELL that addresses several of oCELL's limitations while preserving its intrinsic explainability and interpretability properties.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Parallelization-and-Differentiability"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses practical considerations for efficient implementation,
 including strategies for obtaining differentiable operations,
 GPU parallelization and  spatial indexing to optimize learning speed and inference.
\end_layout

\begin_layout Section
CELL Learning Paradigm
\begin_inset CommandInset label
LatexCommand label
name "sec:CELL-Learning-Paradigm"

\end_inset


\end_layout

\begin_layout Section
oCELL:
 Multiagent Ensemble Learning with Orthotopes
\begin_inset CommandInset label
LatexCommand label
name "sec:oCELL"

\end_inset


\end_layout

\begin_layout Standard
This section introduces the first instantiation of CELL,
 referred to as oCELL (orthotope CELL).
 CELL systems are multiagent systems composed of autonomous agents,
 each possessing local knowledge and specific capabilities.
 These systems build upon the Self-Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to address online supervised learning tasks.
\end_layout

\begin_layout Standard
The objective is to approximate a function 
\begin_inset Formula $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$
\end_inset

 that maps feature vectors to target vectors from a continuous stream of data.
 oCELL processes incoming data points by routing them to its primary components,
 the context agents.
 These agents are dynamically created and updated according to predefined learning rules.
 Each agent occupies a distinct region of the feature space defined as an orthotope,
 where it maintains the highest confidence in its predictions.
 This spatial organization allows agents to determine 
\emph on
when
\emph default
 they should contribute to the prediction process.
 To determine 
\emph on
what
\emph default
 to predict,
 each agent maintains a local machine learning model over its confidence region.
\end_layout

\begin_layout Standard
First,
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Context-Agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the internal structure of context agents is described,
 including their spatialization in the feature space and their prediction mechanisms.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Learning-Rules"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces the learning rules that cover agent creation,
 adaptation and self-organization leading to the emergence of learning in the system.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Comparative-Study"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a comparative study evaluating the performance of oCELL against other machine learning algorithms on a two-dimensional benchmark.
 Subsequently,
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents an analysis of the capabilities of oCELL in terms of interpretability and explainability,
 which naturally arise from the spatial organization of agents.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses the limitations of oCELL and outline directions for future research,
 some of which are addressed in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Context Agents
\begin_inset CommandInset label
LatexCommand label
name "subsec:Context-Agents"

\end_inset


\end_layout

\begin_layout Standard
The main entities of oCELL are context agents.
 A context agent,
 denoted as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i},f_{i}\right\} 
\]

\end_inset

is defined by two core components:
 an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

.
 The activation function determines whether the agent should contribute to the prediction for a given input 
\begin_inset Formula $x$
\end_inset

,
 while the prediction function provides the corresponding output.
\end_layout

\begin_layout Standard
Each agent can adapt the parameters of its activation and prediction functions based on reinforcement signals derived from its performance,
 enabling it to refine its behavior according to local conditions in feature space.
 Conceptually,
 a context agent acts as a local expert for the target function with activation function governing 
\emph on
when
\emph default
 the agent predicts and  the prediction function specifying 
\emph on
what
\emph default
 it predicts.
\end_layout

\begin_layout Standard
First,
 the spatialization mechanism of context agents based on orthotopes is described.
 Then the prediction mechanisms arising from interactions within an agents neighborhood are detailed.
\end_layout

\begin_layout Subsubsection
Spatialization with Orthotopes
\begin_inset CommandInset label
LatexCommand label
name "subsec:Spatialization-with-Orthotopes"

\end_inset


\end_layout

\begin_layout Standard
To ensure transparency and interpretability,
 oCELL spatialize context agents using orthotopes (also referred to as hyper-rectangles in the literature).
 Orthotopes provide a clear geometric representation of an agent's confidence region in the feature space,
 allowing precise evaluation of local structures and facilitating shape adaptation during self-organization.
 This representation allows independent manipulation of each feature dimension,
 simplifying expansion and retraction operations.
\end_layout

\begin_layout Standard
Learning with orthotopes has been explored in previous works on supervised learning 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022,konstantinov2023interpretable"
literal "false"

\end_inset

.
 These approaches typically partition the feature space into orthotopes and model the target function locally.
 For instance,
 
\begin_inset CommandInset citation
LatexCommand cite
key "konstantinov2023interpretable"
literal "false"

\end_inset

,
 employs a gradient boosting to learn orthotope bounds,
 where each region corresponds to a simple constant model.
 However this approach is not suitable for online learning from data streams.
\end_layout

\begin_layout Standard
oCELL borrows a similar spatialization principle to 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 which uses the SACL paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to progressively pave the feature space with context agents to address classification tasks.
 However,
 unlike 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 oCELL addresses issues specifically related to regression tasks such as the need for a smoother spatialization of agents to smooth prediction accuracy (i.e smooth the learned function).
\end_layout

\begin_layout Standard
Each agent's activation function defines a 
\begin_inset Formula $n$
\end_inset

-dimensional orthotope in the feature space.
 For each feature dimension 
\begin_inset Formula $j\in\left\{ 1,\dots,n\right\} $
\end_inset

,
 the orthotope is parameterized by a lower bound 
\begin_inset Formula $l_{j}$
\end_inset

 and an upper bound 
\begin_inset Formula $h_{j}$
\end_inset

 such as
\begin_inset Formula 
\begin{equation}
\mathcal{H}_{i}=\left[l_{1},h_{1}\right]\times\dots\times\left[l_{n},h_{n}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The volume 
\begin_inset Formula $v\left(\mathcal{A}_{i}\right)$
\end_inset

 of the orthotope associated to 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined by
\begin_inset Formula 
\begin{equation}
v\left(\mathcal{A}_{i}\right)=\prod_{j=1}^{n}\left(h_{j}-l_{j}\right)\label{eq:orthotope-volume}
\end{equation}

\end_inset

An observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is considered as intersecting an orthotope if,
 for all feature 
\begin_inset Formula $j$
\end_inset

,
 
\begin_inset Formula 
\begin{equation}
l_{j}\leq x_{j}\leq h_{j}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Additionaly,
 an orthotope 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 intersects another orthotope 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

 if,
 for all feature 
\begin_inset Formula $j$
\end_inset

,
\begin_inset Formula 
\begin{equation}
\max\left(l_{1,j},l_{2,j}\right)\leq\min\left(h_{1,j},h_{2,j}\right)\label{eq:orthotope-intersection}
\end{equation}

\end_inset

with 
\begin_inset Formula $l_{1,j}$
\end_inset

,
\begin_inset Formula $l_{2,j}$
\end_inset

 and 
\begin_inset Formula $h_{1,j}$
\end_inset

,
\begin_inset Formula $h_{2,j}$
\end_inset

 denote the lower and upper bounds of 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Agents in oCELL are constructed based on the assumption of uniform knowledge over their confidence region,
 i.e the area delimited by the associated orthotope.
 We distinguish between activation and neighborhood.
 When an agent is activated by a point,
 it means it is confident in its expertise to predict for that point.
 When an agent is a neighbor of a point,
 it means it has doubts about its expertise to predict for that point.
 In other words,
 it is an agent that is a candidate to become an activated agent for that point.
 The way an agent updates itself differs depending on whether the agent is activated or a neighbor.
\end_layout

\begin_layout Definition
A Context Agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is considered activated by an observation 
\begin_inset Formula $x$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 intersects with the orthotope 
\begin_inset Formula $\mathcal{H}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{\mathcal{H}}:\mathbb{R}^{n}\mapsto\left\{ 0,1\right\} $
\end_inset

 of 
\begin_inset Formula $\mathcal{A}$
\end_inset

.
 In other words,
 we define the activation function of 
\begin_inset Formula $\mathcal{A}$
\end_inset

 as
\begin_inset Formula 
\begin{equation}
\phi_{\mathcal{H}}\left(x\right)=\begin{cases}
1 & \text{if}\,\,\forall j,\,\,l_{j}\leq x_{j}\leq h_{j}\\
0 & \text{else}
\end{cases}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The neighborhood of an observation 
\begin_inset Formula $x$
\end_inset

 is defined as an orthotope 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset

 centered on 
\begin_inset Formula $x$
\end_inset

.
 A context Agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is considered a neighbor of 
\begin_inset Formula $x$
\end_inset

 if the orthotope 
\begin_inset Formula $\mathcal{H}_{i}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{i}$
\end_inset

 of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

,
 intersects with 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:orthotope-intersection"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
For self-organization,
 agents must adapt their shape and position in the feature space.
 Unlike 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 which minimizes overlap to avoid ambiguity in classification (for example agents could push each other),
 oCELL allows overlapping regions to allow prediction smoothing through ensemble averaging.
 This property is particularly useful for regression tasks as it can be more informative to average the predictions of several weak models to smooth the learned function.
 It also facilitates integration into non-linear optimization processes (cf.
 section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Hard-Constraints"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Therefore,
 an agent can change its shape by contracting or expanding its orthotope without worrying about the positions of other agents.
\end_layout

\begin_layout Definition
If a context agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 expands (resp.
 contracts) by a factor 
\begin_inset Formula $\alpha$
\end_inset

 in the direction of an observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

,
 then the upper bounds 
\begin_inset Formula $h_{j}^{t}$
\end_inset

 and lower bounds 
\begin_inset Formula $l_{j}^{t}$
\end_inset

 of the associated orthotope are updated according to the following relationship:
\begin_inset Formula 
\begin{align}
h_{j}^{t+1} & =\begin{cases}
\left(h_{j}^{t}-l_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+l_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
h_{j}^{t} & \text{else}
\end{cases}\\
l_{j}^{t+1} & =\begin{cases}
\left(l_{j}^{t}-h_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+h_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
l_{j}^{t} & \text{else}
\end{cases}
\end{align}

\end_inset

with
\begin_inset Formula 
\begin{equation}
\varepsilon=\begin{cases}
\left(1+\alpha\right) & \text{if expansion}\\
\left(1-\alpha\right) & \text{if retraction}
\end{cases}
\end{equation}

\end_inset

and 
\begin_inset Formula $k$
\end_inset

 the number of features such that 
\begin_inset Formula $l_{j}^{t}\leq x_{j}\leq h_{j}^{t}$
\end_inset

.
 Thus,
 the new volume of the orthotope associated with 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is given by the relation:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align}
v_{\mathcal{A}}^{t+1} & =\varepsilon v_{\mathcal{A}}^{t}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
In summary,
 agents are spatialized through activation functions defining orthotopes that represent their 
\emph on
confidence region
\emph default
 (i.e area of expertise) in feature space.
 Each agent can adapt its bounds,
 expanding or contracting its associated orthotope as needed.
 Intuitively,
 larger agents act as 
\emph on
generalists
\emph default
,
 while smaller agents serve as 
\emph on
specialists
\emph default
.
 Consequently,
 complex regions of feature space tend to host many small agents,
 whereas simpler regions tend to be covered by fewer larger agents.
 This assumption aligns with the use of simple local models such as linear regressions,
 which we leverage in subsequent experiments to demonstrate the transparency and interpretability of oCELL.
\end_layout

\begin_layout Subsubsection
Neighborhood Prediction
\begin_inset CommandInset label
LatexCommand label
name "subsubsec:Neighborhood-Prediction"

\end_inset


\end_layout

\begin_layout Standard
The objective of oCELL is to perform online regression from a continuous data stream.
 Spcifically,
 it aims at modeling the nonlinear dynamics of a complex system for subsequent use in an optimization pipeline for optimal control (see Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Therefore,
 it is desirable to minimize gradient noise and ensure the learned function is smooth,
 as irregularities can significantly disrupt the optimization process 
\begin_inset CommandInset citation
LatexCommand cite
key "nesterov2013introductory"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
To achieve this,
 oCELL allows multiple agents to contribute to the final prediction,
 in contrast to previous works 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,dato2021apprentissage,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 where a single agent was ultimately selected for prediction.
\end_layout

\begin_layout Standard
To obtain the prediction 
\begin_inset Formula $\hat{y}$
\end_inset

 from an observation 
\begin_inset Formula $x$
\end_inset

,
 the most competent agents are selected to predict the value of 
\begin_inset Formula $\hat{y}$
\end_inset

.
 If some agents are neighbors of 
\begin_inset Formula $x$
\end_inset

,
 then they each make a prediction proposal.
 If 
\begin_inset Formula $x$
\end_inset

 has no neighbor,
 the 
\begin_inset Formula $k$
\end_inset

-closest agents are selected instead.
 This fallback mechanism prevents prediction failures in regions where the system has limited knowledge (i.e poor paving of the area around 
\begin_inset Formula $x$
\end_inset

).
 The final prediction is then given by the arithmetic mean of the proposals of selected agents such as
\begin_inset Formula 
\[
\hat{y}=\frac{1}{\left|D_{\text{selected}}\right|}\times\sum_{i\in D_{\text{selected}}}f_{i}\left(x\right)
\]

\end_inset

where 
\begin_inset Formula $D_{\text{selected}}$
\end_inset

is the set of selected agents (neighbors or closest) and 
\begin_inset Formula $f_{i}\in\mathbb{R}^{m}$
\end_inset

 the internal prediction function of the 
\begin_inset Formula $i$
\end_inset

-th agent.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/cell_prediction_diagram.png
	lyxscale 30
	width 90text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of the prediction process with agents in CELL paradigm
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-cell-prediction"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Learning Rules
\begin_inset CommandInset label
LatexCommand label
name "subsec:Learning-Rules"

\end_inset


\end_layout

\begin_layout Standard
In CELL systems,
 the design of learning rules revolves around a set of actions and trigger conditions that decide how to digest the continuous stream of 
\begin_inset Formula $\left(x_{new},y_{new}\right)$
\end_inset

 data.
 Some actions are tied to individual agents such as updating their model (prediction function) or shape (activation function);
 and others are more meta-level actions such as destroying or creating new agents.
 These actions are triggered by conditions.
 In oCELL,
 those conditions depend on the number of current neighbors,
 on the number of activated agents and on a feedback values calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
To determine the appropriate action for an agent,
 we define the prediction quality 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

 of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as
\begin_inset Formula 
\[
L_{\mathcal{A}_{i}}=g\left(\hat{y},y\right)
\]

\end_inset

 where 
\begin_inset Formula $g:\mathbb{R}^{m}\times\mathbb{R}^{m}\mapsto\mathbb{R}$
\end_inset

 is a distance measure between the proposal 
\begin_inset Formula $\hat{y}$
\end_inset

 and the true value 
\begin_inset Formula $y$
\end_inset

.
 The largest 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

,
 the worse the quality of the proposal.
 In oCELL,
 we use the squared error as the 
\begin_inset Formula $g$
\end_inset

 function but other types of error functions could be used instead.
 
\end_layout

\begin_layout Standard
We define two thresholds 
\begin_inset Formula $\tau_{\text{good}}$
\end_inset

 and 
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset

 to partition the values of 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

 into three regimes:
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

 for 
\emph on
good
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

 for 
\emph on
inaccurate
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

 for 
\emph on
bad
\emph default
 predictions.
 These thresholds control the degree of accuracy expected from the system and influence the frequency of some rule activation.
\end_layout

\begin_layout Paragraph
Inaccuracy
\end_layout

\begin_layout Standard
When there are 
\begin_inset Formula $N_{A}\geq1$
\end_inset

 activated agents for 
\begin_inset Formula $x_{new}$
\end_inset

,
 it means the region around 
\begin_inset Formula $x_{new}$
\end_inset

 is already known because it is covered by agents.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

,
 it means the prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 and it was right to declare itself as an expert on 
\begin_inset Formula $x_{new}$
\end_inset

.
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 will therefore seek to generalize in the direction of 
\begin_inset Formula $x_{new}$
\end_inset

 by extending its area of expertise.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 then the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
inaccurate
\emph default
 but not catastrophic,
 so it only refines its internal model and keeps its positions waiting for another signal to expand if needed.
 Then,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

,
 the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
bad,

\emph default
 meaning that it shouldn't have been activated.
 In reaction to that,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 will retract to get away from 
\begin_inset Formula $x_{new}$
\end_inset

.
 This rule is the core of agents local self-organization.
 It allows the agents to move in feature space and refine their model as needed to exclude or include points to better model their close surroundings in response to feedbacks on the quality of their predictions.
\end_layout

\begin_layout Paragraph
Incompetence
\end_layout

\begin_layout Standard
When there are 
\begin_inset Formula $N_{A}=0$
\end_inset

 activated agents and 
\begin_inset Formula $N\geq1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of the closest agents are candidate on becoming activated on 
\begin_inset Formula $x_{new}$
\end_inset

.
 In this situation,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 i.e prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
,
 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 could become an expert on 
\begin_inset Formula $x_{new}$
\end_inset

 so it refines its model and expands towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 Otherwise,
 if no neighbor gives 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
 predictions,
 a new agent centered on 
\begin_inset Formula $x_{new}$
\end_inset

 is created.
 This rule promotes knowledge reuse and limit redundant agent creation.
\end_layout

\begin_layout Paragraph
Uselessness
\end_layout

\begin_layout Standard
In practice,
 we observe a need for agent destruction mechanisms within the system.
 Indeed,
 some agents may evolve into degenerate shapes if they receive too much negative feedbacks in a row.
 They become far too small to be informative.
 These 
\emph on
dead
\emph default
 agents most probably won't be activated ever again and are no longer useful in the system.
 Consequently,
 all agents whose volume falls below a certain threshold value 
\begin_inset Formula $\tau_{\text{vol}}$
\end_inset

 are destroyed.
\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Learning-rules-of-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 summarize the learning rules governing the behavior of agents in oCELL and Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Flowchart-illustrating-oCELL-learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the learning process.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="4">
<features tabularvalignment="middle" tabularwidth="95col%">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model 
\begin_inset Newline newline
\end_inset

+ shape (expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\forall\mathcal{A}_{i},\,L_{\mathcal{A}_{i}}\notin\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(retract)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of oCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-oCELL"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert flowchart to explain learning
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Flowchart illustrating the learning process
\begin_inset CommandInset label
LatexCommand label
name "fig:Flowchart-illustrating-oCELL-learning"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Therefore,
 oCELL relies on several hyperparameters that must be initialized prior to training.
 These parameters have an influence on the convergence of the system.
 These parameters include:
\end_layout

\begin_layout Itemize
Initial orthotope size (
\begin_inset Formula $R$
\end_inset

):
 determines the initial confidence region of newly created agents;
 overly small regions may hinder proper activation and make new agents overspecialize locally.
\end_layout

\begin_layout Itemize
Prediction thresholds (
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset

 and 
\begin_inset Formula $\tau_{\text{good}}$
\end_inset

):
 define accuracy regimes and influence rule activation frequency.
\end_layout

\begin_layout Itemize
Volume variation coefficient (
\begin_inset Formula $\alpha$
\end_inset

):
 controls the rate of expansion or retraction of agents as a fraction of their current volume.
\end_layout

\begin_layout Itemize
Destruction threshold (
\begin_inset Formula $\tau_{\text{vol}}$
\end_inset

):
 specifies the minimum volume below which an agent is considered as a candidate for destruction.
\end_layout

\begin_layout Subsection
Comparative Study
\begin_inset CommandInset label
LatexCommand label
name "subsec:Comparative-Study"

\end_inset


\end_layout

\begin_layout Standard
To evaluate the performances of oCELL,
 we conducted a comparative study against standard machine learning algorithms on a regression task.
 This section outlines the experimental protocol and compare performances against various metrics.
 For this experiment,
 each context agent employs a linear regression as its internal model.
 This choice is motivated by the simplicity and transparency of the inner workings of linear transformations.
 This aligns with the design of oCELL and facilitate clear analysis of the system's behavior.
\end_layout

\begin_layout Subsubsection
Experimental Setup
\end_layout

\begin_layout Standard
The experiment is conducted on four two-dimensional benchmark functions commonly used in optimization research.
 These functions were selected due to their nonlinear characteristics and the challenges they present for optimization,
 particularly for gradient-based methods 
\begin_inset CommandInset citation
LatexCommand cite
key "Jamil2013ALS"
literal "false"

\end_inset

.
 This choice is motivated by the fact that state-of-the-art machine learning algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "chenXGBoostScalableTree2016,keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

 partially rely on gradient-based optimization during the learning process.
\end_layout

\begin_layout Standard
To ensure relevance of the evaluation while keeping it low-dimensional,
 we selected classical functions known for their optimization difficulty,
 characterized by multiple local optima and nonlinear variations 
\begin_inset CommandInset citation
LatexCommand cite
key "aliNumericalEvaluationSeveral2005,Jamil2013ALS"
literal "false"

\end_inset

.
 The functions considered are the SSR functions (
\begin_inset Formula $f\left(x,y\right)=\sin\left(\sqrt{x^{2}+y^{2}}\right)$
\end_inset

),
 Booth,
 Goldstein-Price and  Beale functions (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmaps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 For each function,
 a synthetic dataset comprising 8000 observations was generated by uniformly sampling points within the feature space.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/functions_heatmap_line.png
	lyxscale 35
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of the 2D functions used to generate the benchmark datasets.
 The color levels approaching yellow correspond to higher values,
 while the color levels approaching blue correspond to lower values.
\begin_inset CommandInset label
LatexCommand label
name "fig:Heatmaps"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We compare oCELL against widely used ensemble algorithms and common weak learners.
 The selected weak learners include decision trees 
\begin_inset CommandInset citation
LatexCommand cite
key "breimanClassificationRegressionTrees2017"
literal "false"

\end_inset

,
 SVMs 
\begin_inset CommandInset citation
LatexCommand cite
key "changLIBSVMLibrarySupport2011"
literal "false"

\end_inset

 and  linear regression 
\begin_inset CommandInset citation
LatexCommand cite
key "weisbergAppliedLinearRegression2005"
literal "false"

\end_inset

.
 For ensemble methods,
 we consider both classical approaches such as gradient boosting 
\begin_inset CommandInset citation
LatexCommand cite
key "friedmanGreedyFunctionApproximation2001"
literal "false"

\end_inset

 and random forests 
\begin_inset CommandInset citation
LatexCommand cite
key "breimanRandomForests2001"
literal "false"

\end_inset

,
 alongside state-of-the-art algorithms:
 XGBoost 
\begin_inset CommandInset citation
LatexCommand cite
key "chenXGBoostScalableTree2016"
literal "false"

\end_inset

 and LightGBM 
\begin_inset CommandInset citation
LatexCommand cite
key "keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
All input features are normalized to the range 
\begin_inset Formula $-1$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

.
 Hyperparameter optimization is performed via a grid search with the goal of minimizing the mean squared error obtained through 5-fold cross-validation.
 The resulting best configurations found are reported in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "tab:Best-hyperparameters-set"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 These configurations correspond to the parameter sets exposed by the interfaces of the scikit-learn 
\begin_inset CommandInset citation
LatexCommand cite
key "pedregosaScikitlearnMachineLearning2012"
literal "false"

\end_inset

,
 xgboost 
\begin_inset CommandInset citation
LatexCommand cite
key "chenXGBoostScalableTree2016"
literal "false"

\end_inset

 and  lightgbm 
\begin_inset CommandInset citation
LatexCommand cite
key "keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

 python libraries.
 For oCELL,
 
\begin_inset Formula $R$
\end_inset

 is a vector corresponding to the initial length on each dimension of the sides of the orthotope for a newly created context agent.
 The parameters 
\begin_inset Formula $\tau_{\text{good}},\tau_{\text{bad}},\alpha\in\mathbb{R}^{3}$
\end_inset

 correspond to those introduced in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Learning-Rules"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 and  
\emph on
memory_length
\emph default
 sepcifies the maximum memory size allocated to an agent.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/prediction_mas_line.png
	lyxscale 30
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-the-predictions"

\end_inset

Visualization of oCELL predictions on data not included in the training dataset.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Results
\end_layout

\begin_layout Standard
The results obtained using the selected evaluation metrics across the considered benchmark functions are reported in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "tab:Comparisons-results"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 oCELL achieves the lowest mean absolute error (MAE) and the highest coefficient of determination (
\begin_inset Formula $R^{2}$
\end_inset

) for all four functions.
 It also attains the best mean squared error (MSE) on the SSR,
 Goldstein-Price and  Booth functions,
 while XGBoost performs slightly better in terms of MSE on the Beale function.
 Overall,
 oCELL demonstrates comparable performances to XGBoost and LightGBM for most functions,
 while consistently outperforming the weak learners.
 These results indicate that oCELL effectively captures the nonlinear variations of the underlying functions from the data,
 as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-the-predictions"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure*}[!ht]
\end_layout

\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Float table
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{0.95
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="37" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="20col%">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
hyperparameters
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
SSR
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Booth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Goldstein-Price
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Beale
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $R$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.35$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.05$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{\text{good}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.15
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\alpha$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
memory_length
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
XG
\begin_inset Newline newline
\end_inset

Boost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
learning_rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n_estimators
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
objective
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
squ.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Light
\begin_inset Newline newline
\end_inset

GBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
learning_rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n_estimators
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
objective
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_child_samples
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
huber
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
l2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
tweedie
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
tweedie
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bootstrap
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
criterion
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_features
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_leaf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_split
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n_estimators
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
criterion
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_features
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_leaf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_split
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
learning_rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
huber
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
squ.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
huber
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_features
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_leaf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_split
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
epsilon
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
gamma
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
kernel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
rbf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
rbf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poly
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
rbf
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
fit_intercept
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Best-hyperparameters-set"

\end_inset

Best hyperparameters set found by grid search on 5-fold cross validation results
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "40col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Float table
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{0.95
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="33" columns="5">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="20col%">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $R^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MSE
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MAE
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Beale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,983
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,94e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,07e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,995
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,08e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,19e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,996
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,61e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,75e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-0,001
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,16e+08
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,19e+04
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,997
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,34e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
2,53e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,995
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,02e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,23e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-0,139
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,74e+08
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8,28e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,997
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,29e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,11e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Booth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,994
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,29e+03
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,60e+01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,39e+02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,44e+00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,38e+02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8,09e+00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,426
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,17e+05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,63e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
9,52e+00
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
9,91e-01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,998
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,57e+02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,31e+01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,811
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,89e+04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,85e+01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8,72e+01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,01e+00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Goldstein-Price
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,994
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,02e+08
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,29e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,37e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,62e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,80e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,82e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,249
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,22e+10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,79e+04
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,21e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
7,02e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,998
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,98e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,38e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-0,127
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,83e+10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,17e+04
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,46e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,61e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
SSR
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,960
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,89e-02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9,30e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,997
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,22e-03
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,30e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,998
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,68e-04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,98e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,77e-01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,09e-01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
4,97e-04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,39e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,978
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,03e-02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,48e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,972
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,32e-02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,90e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,93e-04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,65e-02
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Comparisons-results"

\end_inset

Comparison between oCELL and the reference algorithms (best scores in bold)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{figure*}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Explainability and Interpretability
\begin_inset CommandInset label
LatexCommand label
name "subsec:Explainability-oCELL"

\end_inset


\end_layout

\begin_layout Standard
The CELL instantiations are designed to possess native mechanisms for introspection.
 While its architecture is similar to the localized approximation approach used by techniques such as LIME 
\begin_inset CommandInset citation
LatexCommand cite
key "ribeiro2016should"
literal "false"

\end_inset

,
 oCELL achieves intrinsic local explainability through its structural multiagent design.
\end_layout

\begin_layout Subsubsection
Interpretability
\end_layout

\begin_layout Standard
oCELL's design provides a basis for full model interpretability.
 When the agents employ inherently transparent models such as linear regression,
 oCELL itself works as a structurally interpretable white-box model in accordance with the definition introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:XAI"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 The system's final prediction is derived from a linear combination of predictions proposed by a restricted,
 spatially-localized subset of agents.
 This mechanism simplifies the process of credit assigment compared to traditional global ensemble models (e.g bagging or boosting),
 which often involve contributions from a large set of weak learners.
 This property makes oCELL intrinsically interpretable.
\end_layout

\begin_layout Standard
Consequently the spatial organization and internal structures of the model can be systematically analyzed to extract essential information about the function underlying the data and its complexity.
 For didactic purposes,
 the remainder of this section is based on a training carried out on a synthetic dataset generated from the Beale function (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmaps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 This nonlinear function exhibits regimes of amplitude variations that are very different across its domain of definition.
 The amplitude of the gradients of the Beale function varies greatly at the boundaries of the definition domain (
\begin_inset Formula $-4\leq x,y\leq4$
\end_inset

),
 while in the central plateau,
 the variations in gradient amplitude are more subtle.
 The Beale function is frequently used as a benchmark for testing optimization algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "zhuangAdaBeliefOptimizerAdapting2020,Jamil2013ALS"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_agents_english.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-tiling-beale"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_neighborhood_english.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-neighborhood-beale"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of the tiling of the space (normalized between 
\begin_inset Formula $-1$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

) by the context agents for the Beale function 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-tiling-beale"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 Each blue rectangle represents a context agent and  the red rectangle is an example of the neighborhood of an observation.
 Visualization of the context agents in the neighborhood of an observation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-neighborhood-beale"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Uncertainty and Confidence
\end_layout

\begin_layout Standard
The notion of neighborhood and more broadly the spatial organization of agents allows to extract various metrics of the local organization of agents in the feature space.
\end_layout

\begin_layout Paragraph
Epistemic Uncertainty
\end_layout

\begin_layout Standard
During training,
 the agents organize themselves in the feature space.
 Depending on the training dataset and the complexity of the underlying function,
 the results of self-organization varies.
 As illustrated in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-tiling-beale"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 gaps (uncovered zones) in the agent tiling may remain.
 It is possible that for a given observation,
 no agent is activated.
 In such cases,
 making a prediction requires relying on the proposals of the nearest agents in the observation's neighborhood.
 To determine if the agents' prediction is reliable,
 we define the coverage index 
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

 of the observation's neighborhood as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p_{\text{coverage}}=\frac{V_{\text{agents}}}{V_{\text{neighborhood}}}
\end{equation}

\end_inset

where 
\begin_inset Formula $V_{\text{agents}}$
\end_inset

 is the volume covered by the 
\emph on
Context
\emph default
 agents in the neighborhood and 
\begin_inset Formula $V_{\text{neighborhood}}$
\end_inset

 is the volume of the hyperrectangle representing the neighborhood.
\end_layout

\begin_layout Standard
Thus,
 if 
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

 is close to 
\begin_inset Formula $1$
\end_inset

,
 the space around the observation contains few gaps:
 our model is proficient in that region of space.
 Therefore,
 it is relevant to consider the predictions of nearby agents.
 Conversely,
 if 
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

 is close to 
\begin_inset Formula $0$
\end_inset

,
 then the space around the observation contains many gaps.
 There is a high probability that this region of space was underexplored during training.
 This may indicate either gaps in the training data specific to that area of space,
 or that training did not proceed as expected for various reasons (strong non-linearities in the function to approximate,
 presence of noise,
 discontinuity,
 etc...).
 We illustrate the utility of the coverage index in a scenario where our system learns from a dataset with an entire portion of missing data 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Comparison-coverage-index"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 We observe that the coverage index helps identify the missing portion of data in the training dataset without having directly access to the actual training dataset.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/side_by_side_missing_data_cover_index_english.png
	lyxscale 30
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Comparison-coverage-index"

\end_inset

Comparison of the distribution map of observations used to train the model (left) and the visualization of the coverage index associated with this model (right).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The covergae index is therefore a quantitative measure of the epistemic uncertainty associated with a prediction.
 it provides a direct assessment of the model's learned boundaries and limitations in various regions of the feature space.
 For the development of critical systems,
 this property is essential to observe in order to assess the risk of extrapolation or interpolation errors.
 
\end_layout

\begin_layout Standard
This measure is fundamentally linked to both explainability and interpretability.
 Locally,
 at the individual prediction level,
 coverage index serves as a crucial component of explanation.
 By quantifying the reliability of the output,
 it effectively represents a degree of trustworhtiness and the necessity of relying on neighborhood averaging (cf.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsubsec:Neighborhood-Prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Globally,
 the aggregated coverage index allows for the systematic analysis and visualization of the entire agent organization across the feature space.
 This analysis of the overall tiling pattern directly addresses interpretability by giving tools for understanding the model's inherent structure and mechanisms.
\end_layout

\begin_layout Paragraph
Aleatoric Uncertainty
\end_layout

\begin_layout Standard
After training,
 when an observation is provided to the model,
 each activated agent makes a prediction proposal.
 We can thus calculate the discrepancy between the prediction proposals from the set of proposals of the activated agents (
\begin_inset Formula $\mathcal{D}_{\text{proposals}}$
\end_inset

) to deduce a measure of aleatoric uncertainty:
 
\begin_inset Formula 
\begin{equation}
\sigma_{\text{activated}}=\sqrt{\sum_{p\in\mathcal{D}_{\text{proposals}}}\frac{\left|p-p_{\text{mean}}\right|}{N_{A}}}
\end{equation}

\end_inset

where 
\begin_inset Formula $p_{\text{mean}}$
\end_inset

 is the average of the proposals in the set of 
\begin_inset Formula $\mathcal{D}_{\text{proposals}}$
\end_inset

 and 
\begin_inset Formula $N_{A}$
\end_inset

 is the number of activated agents.
 This value estimates the disagreement among agents which judge themselves as equally competent to propose a prediction.
\end_layout

\begin_layout Standard
This value of discrepancy quantifies the aleatoric uncertainty associated with the model's predictions.
 It captures the inherent noise and stochasticity as a disagreement among locally activated agents.
 It's linked to explainability because it primarily relates to locality at the prediction-level,
 providing useful tools to explain predictions under the angle of trust.
\end_layout

\begin_layout Standard
Then,
 as oCELL is agnostic of the internal model of the agents that compose it,
 it is possible to use a class of models capable of inherently providing a measure of uncertainty on predictions,
 such as Gaussian Processes.
 Those are models which allow estimation of both epistemic and aleatoric uncertainties 
\begin_inset CommandInset citation
LatexCommand cite
key "schulzTutorialGaussianProcess2018"
literal "false"

\end_inset

.
 Exploiting the strength of this type of model could make the estimation of aleatoric uncertainty more robust.
 Indeed,
 several activated agents are needed for 
\begin_inset Formula $\sigma_{\text{activated}}$
\end_inset

 to be informative,
 using Gaussian Processes would allow to still have a discrepancy value to use even when only one agent is activated.
 To overcome this drawback,
 we present later a generalization of this metric so that it can be used to analyze the geometric structures formed by agents during learning.
\end_layout

\begin_layout Paragraph
Variations of the Underlying Function
\end_layout

\begin_layout Standard
The shape of an agent depends on the region of space it occupies.
 Moreover,
 within its confidence area delimited by the orthotope associated to its activation function,
 the function underlying the data is locally approximable by a simple model.
 Therefore,
 in a region containing a large number of agents,
 variations in the underlying function are likely to be more 
\emph on
difficult
\emph default
 to learn.
 Thus,
 we define the density of agents around an observation as
\begin_inset Formula 
\begin{equation}
\rho=\frac{N_{\text{agents}}}{V_{\text{neighborhood}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $V_{\text{neighborhood}}$
\end_inset

 is the volume of the orthotope representing the neighborhood and 
\begin_inset Formula $N_{\text{agents}}$
\end_inset

 is the number of agents intersecting it.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-density"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the density of agents in the input variable space for the Beale function.
 We observe a corridor in the center of the figure for 
\begin_inset Formula $y\in\left[-1,1\right]$
\end_inset

 where the density of agents is low.
 In the rest of the figure,
 the density of agents is higher.
 By examining the distribution of the average volume of agents in the neighborhood of observations (
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-volume"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 we note that areas with high agent density contain smaller agents and  conversely for low-density areas.
\end_layout

\begin_layout Standard
These two regions correspond to very different variation regimes of the Beale function.
 Indeed,
 the region containing the largest agents (low density) corresponds to a plateau where the gradient magnitude of the function varies little.
 In contrast,
 the region containing the smallest agents (higher density) corresponds to a region of space where the gradient magnitude of the function varies strongly as one approaches the boundary of the definition area (
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-density"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
Finally,
 to complete the analysis,
 we define the degree of discrepancy 
\begin_inset Formula $\kappa$
\end_inset

 (which is a derivative of the discrepancy of activated agents 
\begin_inset Formula $\sigma_{\text{activated}}$
\end_inset

 presented earlier) among the predictions of all agents in the neighborhood (
\begin_inset Formula $\mathcal{D}_{\text{proposals}}$
\end_inset

) as
\begin_inset Formula 
\begin{equation}
\kappa=\frac{\sqrt{\sum_{p\in\mathcal{D}_{\text{proposals}}}\frac{\left|p-p_{\text{mean}}\right|}{N}}}{\left|y_{\text{mean}}\right|}
\end{equation}

\end_inset

where 
\begin_inset Formula $N$
\end_inset

 is the number of agents in the neighborhood and  
\begin_inset Formula $y_{\text{mean}}$
\end_inset

 is the average of predictions from the agents in the neighborhood.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\kappa$
\end_inset

 is close to 
\begin_inset Formula $0$
\end_inset

,
 then the predictions of the agents in the neighborhood are very close to each other.
 This indicates that the underlying function of the data varies little around the observation.
 Conversely,
 if its value is high,
 then the agents in the neighborhood make very different predictions,
 suggesting that the regime of variation of the underlying function is likely to change abruptly in that area.
 The degree of discrepancy helps identify regions in the input space where approximating the underlying function is most challenging.
 For the Beale function,
 the degree of discrepancy highlights regions of the space with the most complex variations (see 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-discrepancy"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 where the yellow areas represent the highest disagreement between agents).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_density_english.png
	lyxscale 30
	width 28text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-density"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_mean_volume_english.png
	lyxscale 30
	width 28text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-volume"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_consensus_degree_english.png
	lyxscale 30
	width 28text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-discrepancy"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of density 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-density"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 average volume 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-volume"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 degree of discrepancy 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-discrepancy"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 of 
\emph on
Context
\emph default
 agents.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The metrics presented above allow to extract measures of epistemic and aleatoric uncertainty on predictions,
 as well as information on function variations based on the shape and position of agents in the feature space.
\end_layout

\begin_layout Standard
We have extracted measures of epistemic (coverage index) and aleatoric (activated discrepancy) uncertainty from the predictions of the system as well as information about the variations of underlying function from the shape (volume and density) and spatial organization of agents in the feature space (degree of discrepancy).
 These introspection tools reveal capabilities that are useful for various purposes such as fault detection,
 model debugging,
 or smart resampling strategies to improve learning in specific,
 uncertain regions of the feature space.
 Finally,
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Summary-Metrics-Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 summarizes the scopes and links between the defined metrics and the notions of explainability and interpretability.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Metric
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scope
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Explainability
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Interpretability
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Coverage Index (
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local + Global
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated Discrepancies (
\begin_inset Formula $\sigma_{\text{activated}}$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\times$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Density (
\begin_inset Formula $\rho$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local + Global
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Degree of Discrepancy (
\begin_inset Formula $\kappa$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local + Global
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of the metrics introduced and their link to explainability or interpretability
\begin_inset CommandInset label
LatexCommand label
name "tab:Summary-Metrics-Explainability-oCELL"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Limitations
\begin_inset CommandInset label
LatexCommand label
name "subsec:Limitations"

\end_inset


\end_layout

\begin_layout Standard
We demonstrated that oCELL can address supervised learning tasks,
 but several limitations remain,
 which are tackled partly in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
A first limitation concerns the neighborhood prediction mechanism.
 Our current design assumes that an agent possesses uniform knwoledge throughout its activation region (the orthotope associated with its activation function).
 In practice,
 an agent is typically more reliable near its centroid and less accurate near the boundaries of its region.
 Despite this,
 all agents contributing to a prediction currently receive equal weight.
 This is an artifact of the uniform-knowledge assumption.
 A more principle approach would weight each agent according to its estimated local expertise level at the query point.
\end_layout

\begin_layout Standard
We explored this idea by weighting predictions using the Euclidean distance between the input and each agent's centroid,
 but this did not improve performance,
 likely because centroid distance alone does not reflect the whole geometry of each orthotope.
 A more appropriate distance measure should incorporate both the agent's centroid and the shape of its support.
 As illustrated in 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Limitation orthotope agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 (side by side comparison of an overgeneralizing agent and a representative agent by visualizing their respective orthotopes (represented by a blue rectangle) and training data (represented by red dots)),
 an agent may occupy a large orthotope while its training data populate only a small manifold (i.e a subregion),
 causing spurious known-region responses and false positives.
 Accurate spatialization and potentially richer base shapes is therefore essential to capture local data structures and prevent overgeneralization.
\end_layout

\begin_layout Standard
Furthermore,
 we observed that oCELL's agent destruction mechanism was inadequate.
 Agent overproduction was a frequently observed phenomenon,
 occasionally resulting in significant local redundancy and the persistence of harmful parasitic agents within the collective.
 This necessitates the development of more sophisticated destruction strategies explicitly designed to enforce local cooperation.
 In addition to that,
 the current single-point agent creation scheme seems too limited,
 as it directly contributes to local redundancy (slow local convergence).
 It should be more stable to initialize agents using multiples points to minimize local overlap and make local convergence faster.
\end_layout

\begin_layout Standard
Moreover,
 we observed that oCELL's agent destruction system was not sufficient and that agent overproduction was fairly common,
 sometimes leading to high local redundancy and the persistence of agents that parasitize the collective without improving it.
 This highlights a need for smarter destruction mechanisms that are designed towards local cooperation and more efficient agent creation schemes because creating agents with only one point can cause high local redundancy.
\end_layout

\begin_layout Standard
Furthermore,
 although oCELL is designed for online learning,
 it treats incoming samples as independent,
 failing to exploit temporal correlations in data streams.
 This limits its sample efficiency and reduces its ability to adapt to evolving distributions.
\end_layout

\begin_layout Standard
Finally,
 some hyperparameters remain difficult to tune.
 In particular,
 the initial side lengths of newly created agents have a disproportionate impact on performance and require specifying a scale per feature dimension.
 Similarly,
 the error thresholds used to classify predictions as 
\emph on
good
\emph default
,
 
\emph on
inaccurate
\emph default
 or 
\emph on
bad
\emph default
 are hard to tune properly to enable an efficient balence in the triggering of the various adaptation mechanisms or agents (i.e learning rules).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/sane_orthotope_agent.png
	lyxscale 40
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Representative orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Representative-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/overgeneralized_orthotope_agent.png
	lyxscale 40
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Overgeneralizing orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Overgeneralizing-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Side by side comparison of representative 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Representative-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 agent against a overgeneralizing agent 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Overgeneralizing-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 The blue rectangle corresponds to the orthotope associated to the activation function of the Context agent.
 Each red dot corresponds to a training point seen by the Context agent.
\begin_inset CommandInset label
LatexCommand label
name "fig:Limitation orthotope agents"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Taken together,
 these limitations expose a broader structural issue.
 oCELL relies on spatialization and prediction aggregation mechanisms that are too rigid.
 The orthotope representation is too coarse to support reliable interpolation when agents overlap or specialize unevenly.
 These limitations also highlight the need for inference machanisms that weight agents according to their estimated expertise level rather than using discrete activations.
 These considerations motivate the design of a new CELL system in which spatialization,
 inference and adaptation are grouned in smoother data representations.
\end_layout

\begin_layout Section
kCELL:
 Multiagent Ensemble Learning with Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "sec:kCELL"

\end_inset


\end_layout

\begin_layout Standard
Building upon the limitations of oCELL,
 we introduce kCELL (kernel CELL),
 the second instantiation of the CELL paradigm.
 With oCELL,
 we demonstrated that a population of agents can achieve competitive performance and provide valuable introspection signals such as epistemic and aleatoric uncertainty estimates and qualitative information about local function variations.
 However,
 its rigid spatial representation ultimately limits its ability to build reliable and adaptive regions of expertise.
 This constraint becomes problematic when there is need for fast adaptation in an online setting.
\end_layout

\begin_layout Standard
kCELL addresses these issues by replacing orthotope-based spatialization with a kernel-based representation.
 Each agent has its activation function in the form of a RBF kernel that defines a smooth continuous distance between input features and agents,
 drawing inspiration from RBF Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "lowe1988multivariable"
literal "false"

\end_inset

 and MoE (Mixture of Experts) 
\begin_inset CommandInset citation
LatexCommand cite
key "yukselTwentyYearsMixture2012"
literal "false"

\end_inset

 gating mechanisms.
 This change allows the system to express spatial structures more finely,
 with more degrees of freedom than what is permitted with orthotopes,
 thus breaking the assumption of knowledge uniformity over the region of expertise of oCELL.
\end_layout

\begin_layout Standard
In addition to that,
 kCELL introduces a smooth aggregation rule in which agents contribute to predictions proportionally to their kernel-defined relevance,
 i.e proportionally to their estimated expertise level.
 This brings the inference closer to the probabilistic weighting strategies used in Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "seeger2004gaussian"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
For those reasons kCELL improves interpolation quality,
 agents' data representations and yield more stable learning dynamics that are less dependent on brittle hyperparameters,
 which is better suited for online adaptive learning.
 kCELL is a more expressive and robust extension of the CELL paradigm that also preserves the explainability properties demonstrated with oCELL.
\end_layout

\begin_layout Standard
First,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Context-Agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 describes the internal structure of context agents in kCELL,
 including their spatialization in the feature space and their prediction mechanisms.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Learning-Rules"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces the learning rules that cover agent creation,
 adaptation and self-organization leading to the emergence of learning in the system.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Adaptation-to-Non-Stationary"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a study of kCELL's capabilities in terms of adaption in a non-stationary environment leveraging the introspection tools specific to the models derived from CELL.
 Subsequently,
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Discussions-and-Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses the key differences between oCELL and kCELL and details the limitations of kCELL.
\end_layout

\begin_layout Subsection
Context Agents
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Context-Agents"

\end_inset


\end_layout

\begin_layout Standard
As for oCELL 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Ref to definition of context agents in oCELL
\end_layout

\end_inset

,
 the main entities of kCELL are the Context agents.
 A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is characterized by an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

 such as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i},f_{i}\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
However,
 unlike in oCELL,
 the Context agents of kCELL are spatialized differently.
 In oCELL,
 a binary activation (the point is inside or outside the associated orthotope) is used while in kCELL,
 a RBF kernel is used as a continuous and smooth activation function to represent the area of expertise in feature space.
\end_layout

\begin_layout Standard
First,
 the spatialization mechanism of context agents based on RBF kernels is described.
 Then the soft weighted prediction mechanism allowing for weighting based on estimated level of expertise is presented.
\end_layout

\begin_layout Subsubsection
Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kernel-Spatialization"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 contrary to using orthotopes a RBF kernel is used as the activation function to unlock more degrees of freedom to represent the areas of expertise 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add ref to illustration Figure
\end_layout

\end_inset

.
 This activation function is smooth and differentiable,
 making the system more optimization-friendly to be used for control tasks as a dynamics model.
 Therefore,
 an agent is spatialized by the mean 
\begin_inset Formula $\mu_{i}\in\mathbb{R}^{n}$
\end_inset

 and covariance matrix 
\begin_inset Formula $\Sigma_{i}\in\mathbb{R}^{n\times n}$
\end_inset

 of the distribution of its training points.
 Since this activation function has statistical significance,
 it is easier to define the neighborhood as a confidence interval whose confidence value can be adjusted.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison between area of expertise oCELL vs kCELL
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Definition
The distance between a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 and a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined as the mahalanobis distance:
\begin_inset Formula 
\[
d\left(\mathcal{A}_{i},x\right)=D_{M}\left(\mu_{i},\Sigma_{i},x\right)=\sqrt{\left(x-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x-\mu_{i}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is considered as a neighbor of 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 is likely to belong to the training dataset of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 such as 
\begin_inset Formula 
\[
D_{M}\left(\mu_{i},\Sigma_{i},x\right)^{2}\leq\chi_{n,0.95}^{2}
\]

\end_inset

 where 
\begin_inset Formula $\chi_{n,0.95}^{2}$
\end_inset

 denotes the 
\begin_inset Formula $95$
\end_inset

th percentile of the chi-squared distribution with 
\begin_inset Formula $n$
\end_inset

 degrees of freedom.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The activation function 
\begin_inset Formula $\phi_{i}:\mathbb{R}^{n}\mapsto\left]0,1\right]$
\end_inset

 of a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 for a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is given by the RBF kernel value
\begin_inset Formula 
\[
\phi_{i}\left(\mathcal{A}_{i},x\right)=\exp\left(-\frac{d\left(\mathcal{A}_{i},x\right)}{2l^{2}}\right)
\]

\end_inset

with 
\begin_inset Formula $l$
\end_inset

 the lengthscale of the kernel.
\end_layout

\begin_layout Definition
The activation score of a point 
\begin_inset Formula $x$
\end_inset

 for a given agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 can be interpreted as the likelihood that the agent has previously been trained on points similar to 
\begin_inset Formula $x$
\end_inset

 and  thus reflects the agent's degree of knowledge over the corresponding region of feature space.
 We can draw a parallel between this activation function based on RBF kernel and the coverage index 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert ref to coverage index in previous section
\end_layout

\end_inset

,
 an explainability metric derived from oCELL which is also linked to the degree of knowledge of a point.
 In kCELL,
 this explainability property related to the knowledge of a point emerges naturally from the definition of the system.
\end_layout

\begin_layout Definition
One of the requirements of kCELL is to be lightweight,
 meaning that as few points as possible should be retained in memory to truly represent information through local models.
 As previously stated,
 the spatialization of each agent can be fully described by a mean 
\begin_inset Formula $\mu_{i}$
\end_inset

 and a covariance matrix 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 which are the parameters of the activation function 
\begin_inset Formula $\phi_{i}$
\end_inset

.
 Each time a point is ingested by agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

,
 its mean and covariance matrix are updated using the Welford's algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "welford1962note"
literal "false"

\end_inset

 such as 
\begin_inset Formula 
\begin{eqnarray*}
\mu_{i\,|\,t+1} & = & \mu_{i\,|\,t}+\frac{x-\mu_{i\,|\,t}}{n+1}\\
\Sigma_{i\,|\,t+1} & = & \frac{1}{n}\left(\Sigma_{i\,|\,t+1}+\left(x-\mu_{i\,|\,t}\right)\left(x-\mu_{i\,|\,t+1}\right)^{\top}\right)
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $n$
\end_inset

 is the number of points ingested by the agent to update its shape.
 With this approach the shape change is expressed purely as a mean and covariance estimation problem.
\end_layout

\begin_layout Definition
The notion of volume expressed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Context-Agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 (cf.
 Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:orthotope-volume"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) still carries on.
 The volume of an agent is tied to the volume of a confidence ellipsoid defined by a theshold on squared mahalanobis distance.
 Thus the volume of an agent is proportional to the square root of the determinant of the associated covariance matrix
\begin_inset Formula 
\[
v\left(\mathcal{A}_{i}\right)\propto\sqrt{\det\left(\Sigma_{i}\right)}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Soft-Weighted Prediction
\begin_inset CommandInset label
LatexCommand label
name "subsubsec:Soft-Weighted-Prediction"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 we get rid of the knowledge uniformity hypothesis of agents to better represent the knowledge of the system.
 Therefore the activation function of a context agent materializes its area of expertise through a smooth RBF kernel.
 The further a point is from the agent's centroid,
 the lower its activation value.
 This is because we assume that expertise is maximized at the agent's center.
 Agents with higher activation values contribute more heavily to the final output because they are more expert than others at predicting.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $S_{k}=\left\{ i|\mathcal{A}_{i}\,\text{is in the \ensuremath{k}-closest to}\,x\right\} $
\end_inset

 denote the index set of the 
\begin_inset Formula $k$
\end_inset

 nearest agents in feature space.
 The final prediction 
\begin_inset Formula $f\left(x\right)\in\mathbb{R}^{m}$
\end_inset

 of the system is then given by
\begin_inset Formula 
\[
f\left(x\right)=\sum_{i\in S_{k}}w_{i}\left(x\right)f_{i}\left(x\right)
\]

\end_inset

where the normalized contribution weights 
\begin_inset Formula $w_{i}\left(x\right)$
\end_inset

 are defined as
\begin_inset Formula 
\[
w_{i}\left(x\right)=\frac{\phi_{i}\left(x\right)}{\sum_{j\in S_{k}}\phi_{j}\left(x\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
This formulation ensures that each contributing agent's influence on the final prediction is proportional to its estimated competence.
\end_layout

\begin_layout Subsection
Learning Rules
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Learning-Rules"

\end_inset


\end_layout

\begin_layout Standard
As in oCELL,
 learning rules are designed around a set of actions and conditions that triggers those actions to digest 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 that are fed to the system sequentially as a data stream.
 In context agent learning systems,
 the set of actions consists of the actions that can be performed individually by agents such as updating their model or shape;
 and more meta-level actions such as destroying or creating new agents.
 These actions are triggered by conditions that generally depend on two factors:
 the number of current neighbors and a feedback value calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
When there are 
\begin_inset Formula $N>1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of those agents are theoretically considered as experts to predict for 
\begin_inset Formula $x_{new}$
\end_inset

.
 As the final prediction of the system 
\begin_inset Formula $f\left(x\right)=\hat{y}$
\end_inset

 is computed from the proposals of all those agents,
 the agents need to cooperate together locally to improve the local knowledge.
 For this purpose,
 we define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

,
 the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process,
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}=\frac{E_{-i}-E}{E}=\frac{\left|\hat{y}_{-i}-y_{new}\right|-\left|\hat{y}-y_{new}\right|}{\left|\hat{y}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E$
\end_inset

 is the prediction error,
 
\begin_inset Formula $E_{-i}=\left|\hat{y}_{-i}-y_{new}\right|$
\end_inset

 is the prediction error without considering the proposition of prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset

 then it means that removing agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 from the prediction group had a negative impact on the prediction error,
 meaning that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 has a positive contribution to reducing the error locally and conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset

.
 This value indicates for a given point,
 which agents are strong and which are weak in predicting for 
\begin_inset Formula $x_{new}$
\end_inset

.
 We can therefore consider that weak agents need to improve their local model,
 while strong agents are already good and need to strengthen their local anchoring at the given point.
 This update rule allows for the continuous improvement of the group locally by improving the weakest agents while keeping them mobile,
 thus allowing them to position themselves elsewhere if needed.
\end_layout

\begin_layout Standard
When there is only one agent (
\begin_inset Formula $N=1$
\end_inset

) that is neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

,
 it can't be updatd according to the same rules.
 Indeed,
 its contribution to the error cannot be compared to the ones of other neighors (as if 
\begin_inset Formula $N>1$
\end_inset

).
 Therefore,
 we define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

,
 the relative error reduction compared to a baseline prediction given by a running short term linear predictor
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}^{\prime}=\frac{E_{base}-E_{i}}{E_{base}}=\frac{\left|y_{base}-y_{new}\right|-\left|\hat{y}_{i}-y_{new}\right|}{\left|y_{base}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E_{base}$
\end_inset

 is the prediction error of the short term linear predictor,
 
\begin_inset Formula $E_{i}=\left|\hat{y}_{i}-y_{new}\right|$
\end_inset

 is the prediction error of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 outperforms the short term linear predictor locally around 
\begin_inset Formula $x_{new}$
\end_inset

,
 giving indications that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 might be useful locally and  conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

.
 This value allows to estimate how expert the agent is relative to the short-term baseline.
 We can therefore consider that if the only neighbor agent is beaten by the baseline,
 then it probably shouldn't be a neighbor to this point.
 It should skip interacting this 
\begin_inset Formula $x_{new}$
\end_inset

 and 
\begin_inset Formula $y_{new}$
\end_inset

,
 waiting to reposition itself by ingesting new points,
 to be destroyed,
 or for another agent to become a neighbor in that area so they can improve together.
 Conversely,
 if it is better than the baseline,
 then it is a local expert whom should stay in that area since it represents the only local source of knowledge.
 So,
 it should improve its local model and strengthen its local anchoring around 
\begin_inset Formula $x_{new}$
\end_inset

.
 This update rule allows single neighbors to specialize locally even when alone in an area.
\end_layout

\begin_layout Standard
Finally if no agent is considered a neighbor (
\begin_inset Formula $N=0$
\end_inset

),
 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 is computed since as in the case 
\begin_inset Formula $N=1$
\end_inset

,
 there is no neighbor to compare to.
 Thus,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

,
 it means that the neared agent is more relevant than the short term linear predictor.
 Therefore,
 it seems that this agent should encompass the point and become its neighbor by improving its model and extending its shape towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 On the other hand,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

,
 it means that even the nearest agent is not relevant for prediction and therefore the system probably has no knowledge of 
\begin_inset Formula $x_{new}$
\end_inset

 and should add it to its knowledge base by covering the space around it by creating a new agent.
 To avoid initializing the new agent with only one point (as in oCELL) and accelerate local convergence,
 it is initialized from a short term buffer containing last points seen by the system.
\end_layout

\begin_layout Standard
Since agents are created,
 a destruction mechanism is needed.
 An,
 agent might position poorly in the feature space or choose to ingest the wrong points making its model no longer representative of the covered area.
 Decision errors happen almost all the time when working in an online setting because it is impossible to know what the future points will look like.
 It can only be guessed from local relationships between successive points.
 If no destruction mechanism is introduced to mitigate the proliferation of agents,
 the number of agents will grow indefinitely and performances will be hurt by bad agents,
 preventing local specialization in the system and ultimately dragging down the predictive accuracy.
 
\end_layout

\begin_layout Standard
Therefore,
 we define instantaneous normalized confidence 
\begin_inset Formula $c_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

 of an agent as the various feedbacks received by the agent
\begin_inset Formula 
\[
c_{i}=\tanh\left(k\times\begin{cases}
\Delta_{\mathcal{A}_{i}} & \text{if}\,N>1\\
\Delta_{\mathcal{A}_{i}}^{\prime} & \text{else}
\end{cases}\right)
\]

\end_inset

where 
\begin_inset Formula $k$
\end_inset

 is the steepness of the 
\begin_inset Formula $\tanh$
\end_inset

 function.
\end_layout

\begin_layout Standard
Then,
 we define 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

,
 the running confidence of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as the exponental moving average of successive instantaneous confidence values (i.e feedback values) received by the agent
\begin_inset Formula 
\[
\bar{C}_{\mathcal{A}_{i}\,|\,t+1}=\left(1-\lambda\right)\bar{C}_{\mathcal{A}_{i}\,|\,t}+\lambda c_{\mathcal{A}_{i}}
\]

\end_inset

where 
\begin_inset Formula $\lambda$
\end_inset

 the smoothing factor.
\end_layout

\begin_layout Standard
The confidence value 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}$
\end_inset

 is calculated for each agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 and updated each time 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

is selected as a neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

.
 It allows to track its performance over the course of successive updates.
 When 
\family roman
\series medium
\shape up
\size normal
\emph off
\nospellcheck off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}>0$
\end_inset

,
 it means that,
 on average,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is categorized as strong compared to other neighbors or the short-term baseline predictor and  conversely if 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}<0$
\end_inset

.
 Confidence this allows us to distinguish between agents that strengthen the system and those that degrade it.
 We deduce that an agent whose trust falls below a certain threshold 
\begin_inset Formula $\tau_{\text{confidence}}$
\end_inset

 should be destroyed to allow the emergence of new and more efficient local structures.
\end_layout

\begin_layout Standard
Finally,
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Learning-rules-of-kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a summary of the learning rules that describe the behavior of context agents in kCELL.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N>1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of kCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-kCELL"

\end_inset

 where 
\begin_inset Formula $N$
\end_inset

 is the number of neighbors,
 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 the relative error reduction compared to a baseline prediction and 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
To visualize the result of a learning and local cooperation of agents,
 we use a 1-dimensional example.
 We generate a small synthetic dataset from the function 
\begin_inset Formula $f\left(x\right)=\sin\left(x\right)+\epsilon\,\mathcal{N}\left(0,1\right)$
\end_inset

 with 
\begin_inset Formula $\epsilon\in\mathbb{R}$
\end_inset

 the noise scaling factor.
 We simulate online learning by sequentially feeding the agent one 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 tuple at a time.
 Each point is only seen once during learning as this is an important property of an effective and rapid online learning algorithm especially useful in real time dynamics modeling.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1D-Visualization-of-local-coop"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a side-by-side visualization of the spatial organization of agents 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Spatial-organization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 against the result of aggregating their predictions 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Resulting-prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 We can observe that the agents overlap and do not fit perfectly across their entire area of expertise;
 at the edges of agents the fit seems to have more errors and conversely on the center.
 This is the expected behavior resulting from the assumption of non-uniformity in the knowledge within areas of expertise.
 Finally,
 we observe that the overall predictions approximate closely the function considering the noise added to the data.
 It demonstrates kCELL's ability to generalize effectively by interpolation.
 This highlights the usefulness of a weighted aggregation function as presented in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsubsec:Soft-Weighted-Prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/local_coop_1D_illustration/viz_agents_sin1D.png
	lyxscale 40
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Spatial organization
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Spatial-organization"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/local_coop_1D_illustration/viz_inference_sin1D.png
	lyxscale 45
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Resulting prediction
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Resulting-prediction"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of local cooperation of agents in predicting a noisy sinus function.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Spatial-organization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents the spatial organization of agents where is colored segment represents the mapping of an individual agent between feature space and output space.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Resulting-prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the resulting predictions obtained from the aggregation of agents local models,
 illustrating the interpolation capabilities of the model.
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Visualization-of-local-coop"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Adaptation to Non-Stationary Dynamics
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Adaptation-to-Non-Stationary"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 the agents learn a function from a stream of data through local modeling and cooperation.
 In this section we present an experiment and introspection studies to demonstrate the capabilities of kCELL in terms of online adaptation and raw performances in online non-stationary dynamics modeling.
\end_layout

\begin_layout Subsubsection
Experimental Protocol
\end_layout

\begin_layout Standard
To evaluate the capabilities of kCELL to adapt online to non-stationary dynamics,
 we conducted experiments on two MuJoCo 
\begin_inset CommandInset citation
LatexCommand cite
key "todorov2012mujoco"
literal "false"

\end_inset

 simulation environment:
 InvertedPendulum and Hopper.
 For each environment,
 datasets were collected under three gravitational acceleration values (
\emph on
default 
\emph default
gravity
\emph on
 
\emph default

\begin_inset Formula $g=9.81$
\end_inset

,
 
\emph on
low 
\emph default
gravity 
\begin_inset Formula $g=4$
\end_inset

 ,
 
\emph on
high
\emph default
 gravity 
\begin_inset Formula $g=20$
\end_inset

) using pretrained reinforcement learning agents trained with Soft-Actor-Critic (SAC) algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "haarnoja2018soft"
literal "false"

\end_inset

 (with stable-baselines3 implementation 
\begin_inset CommandInset citation
LatexCommand cite
key "stable-baselines3"
literal "false"

\end_inset

).
 Training data were streamed in the same order (
\emph on
default 
\begin_inset Formula $\rightarrow$
\end_inset

 low 
\begin_inset Formula $\rightarrow$
\end_inset

 high
\emph default
) to simulate abrupt changes in the underlying system dynamics.
 The characteristics of the generated datasets are presented in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Characteristics-of-datasets"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
The environments were selected to contrast a low-dimensional setting (InvertedPendulum with 4-dimensional states and 1 action) with a higher-dimensional one (Hopper with 11-dimensional state and 3 actions).
 Mahalanobis distance values become larger the higher the number of dimensions.
 Thus we want to study the impact of increasing dimensionality on the representativity of the spatialization of kCELL which was one of the main limitations of oCELL (cf 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 We also compare kCELL to Adaptive Hoeffding Trees 
\begin_inset CommandInset citation
LatexCommand cite
key "bifet2009adaptive"
literal "false"

\end_inset

 which is an efficient adaptive online learning method based on decision trees designed to handle concept drift.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Environment
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
State Size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nb Actions
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dynamic Changes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nb Learning Steps
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
InvertedPendulum
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g\in\left\{ 9.81,4,20\right\} $
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
30k
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hopper
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g\in\left\{ 9.81,4,20\right\} $
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50k
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Characteristics of datasets generated with different values of 
\begin_inset Formula $g$
\end_inset

.
 
\emph on
State Size
\emph default
 stands for the number of features in states,
 
\emph on
Nb Actions
\emph default
 stands for the number of continuous actions,
 
\emph on
Dynamic Changes
\emph default
 corresponds the set of 
\begin_inset Formula $g$
\end_inset

 values used to generate the datasets,
 
\emph on
Nb Learning Steps
\emph default
 corresponds to the budget in number of training steps used to train the RL agent used to generate each dataset (one RL Agent per dataset).
\begin_inset CommandInset label
LatexCommand label
name "tab:Characteristics-of-datasets"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Prediction Error Analysis
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the evolution of Mean Absolute Error (MAE) for kCELL and Adaptive Hoeffding Trees algorithms measured on the test sets associated with each value of 
\begin_inset Formula $g$
\end_inset

 for each environment.
 Across both environments,
 the MAE consistently decreases on the test set corresponding to the currently observed gravity value,
 indicating effective online adaptation to changes in dynamics (refer to semi-transparent red areas in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
For the InvertedPendulum environment (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-mae-dynamic-changes-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 kCELL systematically outperforms Adaptive Hoeffding Trees when the training and testing gravity values coincide,
 exhibiting lower MAE throughout each stationary phase.
 This suggests that the local spatialized modeling strategy employed by kCELL allows more accurate approximation of the underlying dynamics in low-dimensional settings.
 For the Hopper environment (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 both approaches achieve comparable MAE across the different gravity regimes.
 However,
 we notice that the error curve of kCELL displays higher variance,
 reflecting the self organization mechanisms of agents (creation,
 destruction,
 updates).
 This could also be due to numerical out-of-distribution prediction instability of CELL approaches which is a known problem.
 Indeed,
 due to spatialization,
 kCELL is not designed to predict too far outside their domain of expertise leading to very low activation scores for far away points and potential numerical instabilities.
\end_layout

\begin_layout Standard
For kCELL,
 we notice that for InvertedPendulum,
 transitions between gravity values lead to an increase in MAE on past test sets,
 seemingly reflecting partial forgetting of earlier dynamics.
 In contrast,
 for Hopper,
 kCELL exhibits stable MAE on previously encountered gravity values even after multiple regime changes,
 suggesting retiention of prior knowledge.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/mae_comparison_testsets_invertedpendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-mae-dynamic-changes-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/mae_comparison_testsets_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-mae-dynamic-changes-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of test error on each test dataset.
 Each horizontal plot shows the evolution of error on a test dataset (in order top to bottom:
 
\begin_inset Formula $g=9.81$
\end_inset

 (
\emph on
default
\emph default
),
 
\begin_inset Formula $g=4$
\end_inset

 (
\emph on
low gravity
\emph default
),
 
\begin_inset Formula $g=20$
\end_inset

 (
\emph on
high gravity
\emph default
).
 The semi-transparent red area corresponds to the training period in which the training and test sets correspond to the same dynamic variations.
 The dotted vertical red lines corresponds to changes in dynamics i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of points ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the MAE over the corresponding training set.
 The blue curve corresponds to kCELL's MAE measurements.
 For example the top plot corresponds to the MAE calculated on test data for 
\begin_inset Formula $g=9.81$
\end_inset

 and red area corresponds to the training phase in which 
\begin_inset Formula $g=9.81$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-mae-dynamic-changes"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Structural Evolution of Agent Population
\end_layout

\begin_layout Standard
We analyze the evolution of agent population during training illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-nb-agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 As previously hinted by MAE analysis,
 we notice contrasting dynamics in the population evolution during learning between the two environments.
 In InvertedPendulum (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 each gravity change induces a short-term surge in the number of agents,
 followed by a reduction and stabilization around a nominal value.
 This indicates a restructuring of the population,
 where novelty triggers agent creation and confidence-based mechanisms triggers destruction to eliminate less relevant agents.
\end_layout

\begin_layout Standard
In Hopper (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 the number of agents grows monotonically throughout training.
 Distinct growth regimes are observed for each gravity value with first a logaritmic growth (
\begin_inset Formula $g=9.81$
\end_inset

),
 second a seemingly linear growth (
\begin_inset Formula $g=4$
\end_inset

) and third a slight logarithmic growth (
\begin_inset Formula $g=20$
\end_inset

) with stabilization around 20k steps.
 This accumulation of agents suggests a continuous detection of local dynamics without systematic removal of existing agents.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/nb_agents_colored_zones_no_title_invertedpendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-nb-agents-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/nb_agents_colored_zones_no_title_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-nb-agents-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the number of agents in kCELL during learning.
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the number of agents in the system.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-nb-agents"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Age and Confidence Dynamics
\end_layout

\begin_layout Standard
The mean age of agents provides further insights on kCELL as presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-age"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 In InvertedPendulum (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-age-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 gravity changes coincide with abrupt drops in mean agent age.
 This means that the population becomes suddenly younger,
 which is consistent with the replacement of older agents by newly created ones following a shift in dynamics.
 This behavior aligns with a confidence-driven selection mechanism that favors agents specialized to the current dynamics.
\end_layout

\begin_layout Standard
In Hopper (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-age-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) however,
 the mean agent age increases almost constantly,
 with only minor decreases follwoing the first gravity change and a slight slowdown after the second.
 This indicates that older agents persist over time and are not fully displaced by newer ones,
 despite agent creations.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/age_of_agents_w500_no_title_colored_inverted_pendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-age-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/age_of_agents_w500_no_title_colored_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-age-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the age of agents in kCELL during learning (smoothed with a window of 500 steps).
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the mean age of agents (in steps) in the system .
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-age"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Activation and Local Expertise
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-activations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 shows the evolution of the activation of closest agent during learning.
 In InvertedPendulum (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-activations-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 each gravity change results in a sharp drop in activation,
 signaling a loss of relevance of existing local modals.
 Activation values subsequently recovers as new agents acquire expertise under the new dynamics.
\end_layout

\begin_layout Standard
In Hopper (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-activations-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 activation levels differ across the different gravity regimes,
 with distinct nominal mean activation value observed for each values of gravity acceleration.
 Slight activation decreases are detectable immediately following changes in dynamics,
 these effects are less visible than in InvertedPendulum and partially blurred by higher variance regimes.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/max_activation_smooth_w500_colored_inverted_pendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-activations-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/max_activation_smooth_w500_colored_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-activations-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the maximum activation value of agents in kCELL during learning (smoothed with a window of 500 steps).
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the maximum activation value of agents.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-activations"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the higher-dimensional Hopper environment,
 agent persistence can be explained by two non-exclusive mechanisms.
 First,
 it is possible that agents trained under earlier gravity settings retain partial competence in overlapping regions of the state-action space.
 Those agents are then incrementally adapted as new data arrives leading to multi-regime reuse.
 In this case the growth of agents can be explained mainly by the modeling complexity introduced by the change in dynamics.
 Second,
 high-dimensional effects may reduce the sensitivity of the Mahalanobis distance,
 yielding sparse activation of older agents that prevents both their meaningful adaption and confidence degradation.
 In this case,
 those agents can be considered as frozen because they are too tightly tied to previously visited regions that do not overlap with newly discovered ones after dynamic changes.
\end_layout

\begin_layout Standard
To disambiguate whether agent persistence in the Hopper environment arises from adaptive reuse or from limited cross-regime activation,
 we analyze the activation patterns of the final agent population obtained after full training.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-of-activations-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a heatmap of agent activations for all training samples,
 where columns correspond to agents sorted by age (from oldest to youngest) and rows correspond to training data points (in order) aggregated into bins.
 The resulting heatmap exhibits distinct block patterns,
 with older agents primarily activated for samples from the earliest dataset and progressively younger agents ddominating activation for later datasets.
 We can also observe that the shape of the number of agents curve (presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) appears in the heatmap drawn by points where agents are the most active.
 This organization further indicates that agents remain selectively active for the dynamics under which they were trained and created rather than becoming inactive or obsolete.
\end_layout

\begin_layout Standard
Complementary,
 we provide a two-dimensional UMAP 
\begin_inset CommandInset citation
LatexCommand cite
key "mcinnes2018umap"
literal "false"

\end_inset

 projection of the training data in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:UMAP-of-training-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 with samples colored according to their corresponding gravity regime.
 The projection reveals a clear separation between training datasets,
 suggesting that changes in dynamics induce distinct regions in the state-action space.
 This structural separation provides a plausible geometric explanation for the coexistence of multiple generations of agents.
 Because data from different dynamics regimes occupy largely disjoint regions,
 agents specialized to earlier dynamics remain relevant for their corresponding subspaces without interfering with those created for later regimes.
\end_layout

\begin_layout Standard
These analyses support the claim that agent retention in the Hopper environment is primarily driven by regime-specific specialization in a high-dimensional space,
 rather than by passive survival due to insufficient confidence updates that would prevent the destruction process.
 While Mahalanobis distance may lose discriminative power in higher dimensional spaces,
 the observed seperation of state-action distributions enables kCELL to maintain multiple local experts corresponding to different dynamics.
 This results in stable prediction performance across successive dynamics changes.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/agents_activation_heatmap_no_title_w300.png
	lyxscale 30
	width 70col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Heatmap of final Agents Activations on Training Datasets.
 
\begin_inset Formula $y$
\end_inset

-axis correspond to the training data (in order) aggregated into bins of size 300 (from top to bottom) and 
\begin_inset Formula $x$
\end_inset

-axis corresponds to agents ids sorted from the oldest to the youngest (left to right).
 The dotted horizontal red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The colors corresponds to activation levels of agents over each aggregated training data bins with yellow meaning high activation and blue meaning low activation.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Heatmap-of-activations-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/train_umap_without_agents.png
	lyxscale 30
	width 70col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of UMAP projection of Training data where each point is colored depending on the training dataset it comes from (blue for 
\begin_inset Formula $g=9.81$
\end_inset

;
 yellow for 
\begin_inset Formula $g=4$
\end_inset

;
 pink for 
\begin_inset Formula $g=20$
\end_inset

)
\begin_inset CommandInset label
LatexCommand label
name "fig:UMAP-of-training-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Discussion
\end_layout

\begin_layout Standard
The results presented suggest that kCELL were able to adapt to non-stationary dynamics through a combination of local specialization and structural plasticity with behaviors that depend strongly on the dimensionality and geometry of the feature space.
 In both environments,
 kCELL succesfully reduces prediction error on the currently observed dynamics demonstrating effective online adaptation without explicit task or concept drift detection modules.
 Compared to a Hoeffding Adaptive Tree baseline,
 kCELL achieves lower MAE for the low-dimensional InvertedPendulum environment when training and testing distributions coincide.
 It also achieves comparable performances for the higher-dimensional Hopper environment although with increased variability due to its structural adaptivity.
\end_layout

\begin_layout Standard
For the InvertedPendulum environment,
 changes in dynamics induced a rapid loss of relevance of agents trained on previous dynamics leading to their destruction or adjustment.
 This is reflected by sharp drops in agent activation,
 decreases in mean agent age,
 temporary surges in the number of agents followed by a stabilization and the observed increase in MAE on previously encountered dynamics.
 These indicate a population renewal process driven by confidence degradation and agent replacement.
 In this setting,
 partial forgetting emerges as a natural consequence of the overlap between the geometry of different dynamics and reflects appropriate structural adaptation rather than failure of retention.
\end_layout

\begin_layout Standard
In contrast,
 the Hopper environment exhibits persistent agent populations and stable prediction performance across successive dynamics changes.
 Although the number of agents grows monotonically,
 confidence-based destruction prevents the survival of agents that negatively impact prediction accuracy.
 The absence of population turnover is therefore not attributable to ineffective agent pruning.
 Analysis of agent activations reveals a structured specialization pattern.
 The activation heatmap of the final agent population shows distinct blocks associated with different training phases.
 Older agents are selectively activated for earlier gravity regimes and younger agents for later ones.
 This organization indicates retention of regime-specific expertise rather than passive persistence of obsolete models.
 Indeed,
 the agents do not know when a new dynamics change might occur and which dynamics will replace the current one.
\end_layout

\begin_layout Standard
This interpretation is further supported by the UMAP analysis of the training data,
 which reveals clear separation between datasets generated with different gravity values.
 The existence fo well-separated regions in the state-action space provides a plausible explanation for the coexistence of multiple generations of agents without destructive interference.
 Thus,
 in this case,
 high dimensionality enables to allocate distinct subsets of agents to different dynamics.
 Although Mahalanobis distance may lose discriminative precision as dimensionality increases,
 for this experiment with 11-dimensional states and 3-dimensional actions (resulting in a 14-dimensional input vector),
 the geometric separation induced by gravity changes appears sufficient to maintain effective specialization.
\end_layout

\begin_layout Standard
Overall,
 the results suggest that kCELL implicitly adjusts the tradeoff between forgetting and retention based on the structure of the data distribution rather than relying on explicit task boundaries.
 In low-dimensional spaces,
 adaptation is achieved through agent replacement and partial forgetting,
 while in higher-dimensional settings with separable regimes,
 the system favors retention and specialization.
 These results highlight both the strength and current limitations of kCELL.
 It paves the way for future works on the use of more robust distance metrics and activation mechanisms to account for high-dimensional geometry.
\end_layout

\begin_layout Standard
Finally,
 we highlight the ability to analyze kCELL through the spatial organization and activation patterns of agents as a key advantage in terms of interpretability.
 Introspection of agent properties allows to identify which regions of the state-action space correspond to different dynamics.
 This provide understanding on how the model responds to non-stationary conditions which can be useful to debug,
 refine learning mechanisms or build fallback strategies.
 This relates to the properties we presented in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 showing that despite the design differences with oCELL,
 some related properties remain.
\end_layout

\begin_layout Subsection
Online Stationary Modeling
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on SARCOS + D4RL + KUKA to test raw performances with river-ml algorithms
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Comparative Study of CELL Variants
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Comparison of paving for robot in maze / or pendulum between oCELL and kCELL
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on SARCOS + D4RL to test raw performances
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on number of neighbors and mahalanobis distances in various dimensions and  mention agent growth and problems of dimensionality
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Discussions and Limitations
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Discussions-and-Limitations"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add comparison between oCELL and kCELL
\end_layout

\begin_layout Plain Layout
- Gaussian representation better via smoothness and degrees of freedom but still is an assumption about daat distribution => corrected via PCA ?
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Solving Control Tasks with CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Solving-Control-Tasks"

\end_inset


\end_layout

\begin_layout Standard
Building upon the Self Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

,
 we introduced the CELL (Context Ensemble Local Learning) paradigm,
 which provides the core hypothesis and theoretical ground for designing spatialized multiagent learning systems.
 Within this paradigm,
 algorithms such as oCELL and kCELL rely on a population of agents spatialized in feature space.
 Each agent learns a local predictive model from a stream of data.
 These online learning systems exhibit intrinsic interpretability and explainability properties that arise from the spatial organization of agents,
 spatialized local learning and agent-level interactions.
 
\end_layout

\begin_layout Standard
This chapter investigates how these properties can be exploited for model-based control with learned model without prior knowledge of system dynamics.
 In this setting,
 control policies are built from the combination of a learned predictive model and an optimizer.
 This corresponds to the Model Predictive Control (MPC) framework,
 in which control actions are obtained by repeatedly optimizing predicted trajectories over a finite horizon 
\begin_inset CommandInset citation
LatexCommand cite
key "rawlings2017model"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
When the predictions of learned models lie outside the regions in the state-action space that have been sufficiently represented in the training data,
 the model is inherently limited in terms of accuracy.
 This limitation needs to be considered in optimal control problems involving hard constraints related to safety,
 stability or physical feasibility 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

.
 Indeed,
 unreliable predictions lead to unreliable optimization results.
 While data-driven control methods have achieved promising results,
 they often rely on opaque inner workings and struggle to provide reliable guarantees when operating outside the support of the training data 
\begin_inset CommandInset citation
LatexCommand cite
key "prag2022toward,berberich2025overview"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In this chapter we show that kCELL's structural transparency provides introspection tools that can be directly embedded into control and optimization pipelines.
 kCELL exposes measurable quantities such as distance-based competence,
 local prediction disagreement that provide proxies for quantifying epistemic and aleatoric uncertainties (cf Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:XAI"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 for definitions).
 kCELL's properties can then be leveraged to guide exploration,
 regularize exploitation and explain control decisions in a unified framework.
\end_layout

\begin_layout Standard
More specifically,
 the core contributions presented in this chapter are fourfold:
\end_layout

\begin_layout Itemize
We provide a discussion on how kCELL can be efficiently integrated into real-time,
 model-based control frameworks by exploiting its local linearization capabilities for gradient-based optimization and implementation strategies based on parallel computation or spatial indexing for fast trajectory unfolding in population-based MPC.
\end_layout

\begin_layout Itemize
We introduce introspection-driven strategies based on agent spatial organization and local disagreement for exploration of a low-dimensional environment without prior knowledge of the dynamics.
 We show that these strategies lead to more effective coverage of the state-action space than uninformed exploration mechanisms.
\end_layout

\begin_layout Itemize
We introduce an introspection-driven conservative regularization mechanism for trajectory optimization that leverages kCELL's explicit notion of local model competence,
 reducing the risk of extrapolation errors and improving robustness of control with learned dynamics.
\end_layout

\begin_layout Itemize
We present a novel local explanation method based on Linear Quadratic Regulator (LQR) 
\begin_inset CommandInset citation
LatexCommand cite
key "kalman1960contributions"
literal "false"

\end_inset

 for constrained model-based control.
 This approach allows quantification of constraint impact and feature importance estimation in optimized control policies.
\end_layout

\begin_layout Standard
This chapter is organized as follows.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Parallelization-and-Differentiability"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses the computational and differentiability properties of kCELL that make it suitable for real-time constrained control within a MPC scheme.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Exploration-MPC"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 focuses on exploration of unknown dynamics and shows how the spatial organization and local interactions of agents can be exploited to drive data-efficient exploration.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conservative-MPC"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 addresses robust exploitation by introducing knowledge-aware regularization for trajectory optimization with kCELL.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Explainable-Control-(LQR)"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces a novel LQR-based explanation mechanism for constrained controllers to evaluate the impact of constraints on the optimization process and to estimate feature importance,
 highlighting how kCELL allows to obtain interpretable and explainable control decisions.
\end_layout

\begin_layout Section
Efficient kCELL for Real-Time Control
\begin_inset CommandInset label
LatexCommand label
name "sec:Parallelization-and-Differentiability"

\end_inset


\end_layout

\begin_layout Standard
kCELL provides a more robust and expressive instantiation of the CELL paradigm.
 It is capable of handling non-stationary online learning tasks and maintaining interpretability.
 However,
 its practical deployment in model-based control requires additional computational and structural considerations.
\end_layout

\begin_layout Standard
Model Predictive Control (MPC) relies on repeated model evaluations within an optimization loop.
 When using learned models,
 inference speed and mathematical structure are important to the feasibility and reliability of control,
 especially if real-time constraints need to be met.
\end_layout

\begin_layout Standard
To this end,
 two main requirements must be addressed.
 First,
 population-based optimization methods commonly employed in data-driven MPC,
 such as the Cross-Entropy Method (CEM) 
\begin_inset CommandInset citation
LatexCommand cite
key "de2005tutorial"
literal "false"

\end_inset

,
 require fast and batched predictions over large sets of candidate trajectories whose computational cost must remain predictable across control steps.
 Purely sequential inference with naive expert lookup in kCELL prohibitively expensive.
 Second,
 gradient-based optimization methods,
 such as Sequential Quadratic Programming (SQP) 
\begin_inset CommandInset citation
LatexCommand cite
key "rawlings2017model"
literal "false"

\end_inset

,
 require differentiable predictive models in order to compute local linearization of the dynamics and to handle hard constraints efficiently.
\end_layout

\begin_layout Standard
kCELL must therefore comprise optimized implementations to enable fast batched inference and differentiable representations to support gradient-based control methods.
 Regarding computational efficiency,
 in kCELL,
 expert selection can be accelerated significantly through spatial indexing or parallel execution,
 enabling efficient batched inference on modern hardware such as GPUs.
 Regarding differentiability,
 when activation functions and internal models are differentiable,
 kCELL admits analytic gradients and straightforward local linearization,
 making it naturally compatible with gradient-based MPC formulations.
\end_layout

\begin_layout Standard
Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Efficient-Implementation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses strategies that can be implemented to accelerate inference and learning in kCELL,
 making it suitable for use with random shooting optimization methods like CEM.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:MPC-and-Local-Linearization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows how the local structure of kCELL lead to trivial local linearizations of the learned dynamics,
 making kCELL suited for constrained MPC solved using SQP.
\end_layout

\begin_layout Subsection
Efficient Implementation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Efficient-Implementation"

\end_inset


\end_layout

\begin_layout Standard
Population based trajectory optimization algorithms are broadly used in robotics for their robustness to non-convex and non-smooth dynamics or cost functions 
\begin_inset CommandInset citation
LatexCommand cite
key "chai2019review"
literal "false"

\end_inset

.
 This includes stochastic shooting methods such as Model Path Predictive Integral (MPPI) or CEM (which is used in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Exploration-MPC"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 These methods rely heavily on parallel evaluation of large population of candidate trajectories at each control step within the MPC framework.
 In this section,
 we show that GPU parallel brute force is more reliable than geospatial indexing for nearest neighbor selection to speed up learning and inference process in kCELL for population based MPC.
\end_layout

\begin_layout Subsubsection
Geospatial Tree Indexing
\end_layout

\begin_layout Standard
In CELL instanciations like kCELL and oCELL,
 a learning step always begins with a neighboring agent selection phase.
 Since the agents are spatially distributed in the feature space,
 then the selection of neighboring agents can be broken down into two components:
 distance calculation to find the closest agents and thresholding of those distances to discriminate neighbors.
\end_layout

\begin_layout Standard
Because agents are spatially distributed within the feature space,
 managing the ensemble of agents as a geospatial database can be considered.
 In this case,
 to speed up nearest neighbor searches,
 spatial indexing techniques can be leveraged to select the k-closest agents with a reduced complexity.
 Indexing in geospatial databases is most commonly performances using tree-based methods such as KD-tree or R-tree 
\begin_inset CommandInset citation
LatexCommand cite
key "guting1994introduction"
literal "false"

\end_inset

.
 The KD-tree (for k-dimensional tree) is a binary tree data structure.
 It recursively partition space by splitting along alternating dimensions,
 making it efficient for range queries and nearest neighbor searches on point data 
\begin_inset CommandInset citation
LatexCommand cite
key "bentley1975multidimensional"
literal "false"

\end_inset

 (cf Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-KD-tree"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 The R-tree is a hierarchical tree structure designed for indexing multi-dimensional objects like rectangles or polygons.
 Each node of the tree represents a bounding rectangle that encloses child nodes.
 R-trees are particularly suited for range,
 intersection and nearest neighbor queries in GIS and geospatial databases 
\begin_inset CommandInset citation
LatexCommand cite
key "guttman1984r"
literal "false"

\end_inset

 (cf Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-R-tree"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/kdtree_illustration.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
KD-tree
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-KD-tree"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/rtree_illustration.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
R-tree
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-R-tree"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of KD-tree and R-tree on 2D data
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-KD-tree-and-R-tree"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the context of CELL instantiations,
 R-trees are better suited than KD-trees because they are designed to handle polygons and orthotopes,
 i.e 
\begin_inset Formula $n$
\end_inset

-dimensional generalizations of rectangles.
 Therefore,
 agents can be indexed by their bounding orthotope.
 For kCELL,
 this is the orthotope encompassing the agent's confidence interval specified as a parameter.
 Furthermore,
 R-trees can be incrementally updated,
 making them compatible with the online learning nature of CELL instantiations 
\begin_inset CommandInset citation
LatexCommand cite
key "guttman1984r"
literal "false"

\end_inset

.
 Finally,
 with a spatial index based on a R-tree,
 the selection process can be broken down into three ordered steps:
 searching for the k-closest agents in the R-tree,
 calculating the distances between the point and the k-closest agents and  finally thresholding the distances to discriminate the neighbor agents.
\end_layout

\begin_layout Standard
Implementing a R-tree as a geospatial index over the agents reduces the neighborhood searches from 
\begin_inset Formula $O\left(n\right)$
\end_inset

 in the naive case to 
\begin_inset Formula $O\left(\log n\right)$
\end_inset

.
 However,
 for insertion and deletion,
 the average time complexity increases from 
\begin_inset Formula $O\left(1\right)$
\end_inset

 in the naive case to 
\begin_inset Formula $O\left(\log n\right)$
\end_inset

 with geospatial indexing.
 While geospatial indexing seems less advantageous in terms of insertion and deletion,
 it should be remembered that agent creations and destructions are generally less frequent then neighborhood searches in kCELL.
\end_layout

\begin_layout Subsubsection
GPU Parallelization
\end_layout

\begin_layout Standard
However,
 as the dimensionality of the feature space increases,
 the structural advantages of the R-tree diminish due to distance distention and bounding box overlap making the search complexity degenerate to 
\begin_inset Formula $O\left(n\right)$
\end_inset

.
 In such cases,
 the overhead induced by geospatial indexing offers no advantage over a brute-force approach.
 To address these limitations,
 the embarrassingly parallelizable nature of neighborhood search in kCELL (and oCELL) can be exploited through GPU acceleration.
 By shifting from pointer-based tree structures to dense tensor representations,
 kCELL (and oCELL) can leverage massive parallel throughput as the selection phase can be executed as a vectorized linear algebra operation.
\end_layout

\begin_layout Paragraph
Memory Layout
\end_layout

\begin_layout Standard
To maximize the efficiency of using the GPU for agent selection,
 agent data is stored in contiguous memory block.
 For example,
 for kCELL system,
 we define two global agent tensors for storing the parameters of the activation functions,
\begin_inset Formula 
\[
\mathcal{T}_{\mu}\in\mathbb{R}^{N\times n},\,\,\mathcal{T}_{\Sigma}\in\mathbb{R}^{N\times n\times n}
\]

\end_inset

 where 
\begin_inset Formula $N$
\end_inset

 is the maximum agent capacity of the agent pool and 
\begin_inset Formula $n$
\end_inset

 is the number of features.
 
\begin_inset Formula $\mathcal{T}_{\mu}$
\end_inset

 is for storing the means and 
\begin_inset Formula $\mathcal{T}_{\Sigma}$
\end_inset

 is for storing the covariance matrices.
 With this layout,
 the GPU hardware can easily saturate its bandwith for efficient distance computations.
\end_layout

\begin_layout Paragraph
Dynamic Agent Population
\end_layout

\begin_layout Standard
In CELL systems,
 the number of agents is dynamic.
 Agents can be created or destroyed depending on the needs of the system.
 In a GPU parallelization context with contiguous memory storage,
 managing a dynamic set of agents requires efficient creation and deletion strategies to avoid costly memory allocations.
\end_layout

\begin_layout Standard
The most straightforward approach consists in a dynamic reallocation of memory each time an agent is created or destroyed as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Illustration-of-dynamic-reallocation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 Although easy to implement,
 this approach is unsuitable for high-frequency learning loops due to the overhead induced by re-allocating GPU memory and copying of existing data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/dynamic_reallocation_creation_destruction.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of agent creation and destruction in dynamic reallocation regime
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-dynamic-reallocation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
To achieve 
\begin_inset Formula $O\left(1\right)$
\end_inset

 updated complexity,
 another strategy can be considered.
 Fixed-capacity tensors are pre-allocated to store agents data.
 A boolean masking vector 
\begin_inset Formula $\mathcal{M}\in\left\{ 0,1\right\} ^{N}$
\end_inset

 is maintained to track which memory slot contains an agent or not.
 
\end_layout

\begin_layout Standard
Agent creation then consists in assigning new agents data to the first index 
\begin_inset Formula $i$
\end_inset

 such that 
\begin_inset Formula $\mathcal{M}_{i}=0$
\end_inset

.
 If the agent population exceeds the predefined capacity,
 standard dynamic resizing strategies can be employed.
\end_layout

\begin_layout Standard
Conversely,
 agent deletion sets 
\begin_inset Formula $\mathcal{M}_{i}=0$
\end_inset

,
 marking the slot as available to host data of future agents as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Illustration-of-preallocated-memory-pool"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 This effectively hide the agent from the selection kernel without moving data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/preallocated_memorpool_creation_destruction.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of agent creation and destruction in preallocated memory pool with masking regime
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-preallocated-memory-pool"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For selection,
 the mask 
\begin_inset Formula $\mathcal{M}$
\end_inset

 is used to filter the active memory slots and retrieve only relevant distance computations (i.e those corresponding to existing agents).
\end_layout

\begin_layout Subsubsection
Comparison between GPU and Tree Selection
\end_layout

\begin_layout Standard
The choice of using a geospatial index or the parallelization enabled by a GPU depends on the number of features and the quantity of agents required for learning the function underlying the data which is highly correlated to its complexity.
\end_layout

\begin_layout Standard
To evaluate the impact of this structural shift,
 we benchmark neighborhood selection in Python using 
\emph on
PyTorch
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2019pytorch"
literal "false"

\end_inset

 for GPU accelerated computations and using 
\emph on
Rtree
\emph default
 package 
\begin_inset CommandInset citation
LatexCommand cite
key "gilliesRtreeSpatialIndexing"
literal "false"

\end_inset

 for efficient R-tree implementation.
 We compare the two selection approaches presented previously on a synthetic nearest neighbor selection task for variable amount of features and agents.
 The synthetic centroids are generated to form 100 clusters to simulate high density manifolds.
 As shown in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 in CELL instantiations like oCELL and kCELL,
 agents organize spatially according to the data encountered.
 In real-world cases,
 these data points are rarely uniformly distributed.
 Indeed,
 uniform distribution could overestimate the volume of search.
 Using clustered centroid distribution allows a fairer comparison for R-trees whose main strength is to prune empty space.
\end_layout

\begin_layout Standard
From a set of 1000 query points,
 the time to find the 5-nearest neighbors is measured and averaged across 3 cycles.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 exposes a heatmap of the relative execution time difference in percentage expressed as
\begin_inset Formula 
\[
\Delta_{t}=\frac{\Delta_{\text{GPU}}-\Delta_{\text{R-tree}}}{\Delta_{\text{R-tree}}}\times100
\]

\end_inset

 where 
\begin_inset Formula $\Delta_{\text{GPU}}$
\end_inset

 and 
\begin_inset Formula $\Delta_{\text{R-tree}}$
\end_inset

 the execution time of a nearest neighbor query averaged over 3 cycles.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Binary-winner-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows which strategy has obtained lowest execution time in each studied configuration.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Spatial Indexing:
 explain how the expert lookup is accelerated by KD-tree,
 grid-based indexing,
 or other structures.
\end_layout

\begin_layout Plain Layout
GPU Parallelization:
 show batching of local predictions for multiple states/actions.
\end_layout

\begin_layout Plain Layout
Optionally include a profiling experiment:
 inference time vs number of experts/states.
\end_layout

\begin_layout Plain Layout
Highlight differentiability:
 why it is essential for gradient-based MPC/SQP.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/benchmark/relative_time_diff_rtree_gpu_comprison_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Relative Execution Time Difference Heatmap
\begin_inset CommandInset label
LatexCommand label
name "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/benchmark/binary_perf_diff_rtree_gpu_comprison_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Winner Binary Heatmap
\begin_inset CommandInset label
LatexCommand label
name "fig:Binary-winner-R-tree-GPU"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of the execution times of GPU and R-tree on various 
\begin_inset Formula $\left\{ n,N\right\} $
\end_inset

 configurations for a clustered distribution of synthetic centroids.
\begin_inset CommandInset label
LatexCommand label
name "fig:Comparison-R-tree-GPU-agent-selection"

\end_inset

 contains a heatmap of the relative execution time difference between the two strategies (
\begin_inset Formula $\Delta_{t}$
\end_inset

).
 Shades of yellow correspond to 
\begin_inset Formula $\Delta_{t}>0$
\end_inset

,
 i.e to R-tree being faster.
 Conversely,
 shades of blue correspond to 
\begin_inset Formula $\Delta_{t}<0$
\end_inset

,
 i.e to GPU being faster.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 contains a binary heatmap clearly showing in which configuration which strategy was faster.
 White cells corresponds to configurations in which R-tree was faster and black cells correspond to configurations in which GPU was faster.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The benchmarking results show that R-tree maintains a competitive edge in low-dimensional regimes (
\begin_inset Formula $n\leq5$
\end_inset

).
 This is an expected result as R-trees struggles in higher dimensions due to the curse of dimensionality.
 In higher dimensional regimes the distinction between nearest and farthest points becomes meaningless and pruning becomes ineffective 
\begin_inset CommandInset citation
LatexCommand cite
key "kouiroukidis2011effects"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
However,
 the performances of the R-tree compared to GPU does not seem monotonic.
 In Figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Binary-winner-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we notice a non linear phase transition area (looking like a 
\begin_inset Quotes eld
\end_inset

semi-banana
\begin_inset Quotes erd
\end_inset

) that extends from 
\begin_inset Formula $N=2500$
\end_inset

 centroids and 
\begin_inset Formula $n=70$
\end_inset

 features to 
\begin_inset Formula $N=20000$
\end_inset

 and 
\begin_inset Formula $n=50$
\end_inset

.
 Within this region,
 R-tree is competitive or faster than GPU.
\end_layout

\begin_layout Standard
As shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Winner-binary-heatmap-uniform"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the competitive advantage of R-trees within the non linear phase transition area fades when the centroids are uniformly distributed.
 In this case the R-trees are almost never faster than GPU computation.
 It shows that the structure of data needs to be analyzed beforehand to make sure R-tree indexing is a pertinent indexing option.
 This is an expected result because R-trees are particularly adapted to prune large empty spaces.
 The uniform distribution of centroids does not exhibit exploitable structures for the R-tree.
 This is not an issue for the GPU based nearest neighbor computations that is a brute force approach that does not rely on structure.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/benchmark/binary_perf_diff_rtree_gpu_comprison_uniform_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Winner binary heatmap with uniformly distributed synthetic centroids
\begin_inset CommandInset label
LatexCommand label
name "fig:Winner-binary-heatmap-uniform"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
These observations indicate that the performance of nearest neighbor selection with R-trees compared to using GPUs is better in low dimensional regimes (
\begin_inset Formula $n\leq5$
\end_inset

) and depends heavily on the underlying data structures when the number of dimensions increases (
\begin_inset Formula $n\geq5$
\end_inset

) due to the curse of dimensionality.
\end_layout

\begin_layout Standard
From an engineering standpoint,
 GPU-based selection provides a more predictable and stable latency profile,
 independent of data distribution.
 While R-tree indexing can provide large gains in very specific sparse regimes,
 its performance is highly sensitive to the latent structure of the learned model (i.e the distribution of agents).
\end_layout

\begin_layout Standard
In an online learning setting for adaptive control in a MPC scheme without prior knowledge of the dynamics of the environment,
 the data distribution is not known in advance and may evolve over time.
 For this reason,
 the GPU-based brute-force selection is preferred for its 
\emph on
deterministic latency
\emph default
 and 
\emph on
hardware scalability
\emph default
.
 Indeed,
 GPU execution time scales predictably with 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $N$
\end_inset

,
 whereas R-tree latency exhibits high variance depending on tree depth and splits overlap.
 Moreover,
 GPUs naturally handles batch queries as a single high-throughput operation,
 which can be deemed useful for population-based optimization.
\end_layout

\begin_layout Standard
The implementation strategies discussed in this section address the primary computational bottleneck of kCELL for use in a MPC scheme,
 namely the repeated selection and evaluation of local experts under strict real-time constraints.
 By leveraging either spatial indexing or GPU brute force selection,
 kCELL can be integrated into population-based trajectory optimizers while maintaining predictable inference and learning latency.
\end_layout

\begin_layout Standard
However,
 computational efficiency alone is not sufficient for kCELL to be deployed with gradient-based optimizers that could potentially handle hard constraints.
 Such approaches require predictive models to admit local linearizations.
\end_layout

\begin_layout Subsection
Differentiability and Local Linearization for Gradient-Based MPC
\begin_inset CommandInset label
LatexCommand label
name "subsec:MPC-and-Local-Linearization"

\end_inset


\end_layout

\begin_layout Standard
Fast and scalable inference in kCELL is essential for its integration into real-time MPC frameworks,
 especially when using population-based or gradient-based trajectory optimization methods that rely on repeated model evaluations.
\end_layout

\begin_layout Standard
However,
 computational efficiency alone is insufficient when MPC formulation rely on gradient-based optimization methods that exploit local structures to enforce hard constraints.
 Such approaches require predictive models that admit reliable local linearizations of the learned system dynamics.
\end_layout

\begin_layout Standard
In this section,
 we show that kCELL naturally provides local affine approximations of the dynamics that are directly compatible with gradient-based optimization approaches such as Sequential Quadratic Programming (SQP).
\end_layout

\begin_layout Subsubsection
Differentiability in CELL instantiations
\end_layout

\begin_layout Standard
In CELL instantiations,
 online learning is performed by maintaining a set of self-organizing spatialized agents that map the target function locally (cf Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 A context agent is denoted as
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i},f_{i}\right\} 
\]

\end_inset

where 
\begin_inset Formula $\phi_{i}:\mathbb{R}^{n}\mapsto\left]0,1\right]$
\end_inset

 is an activation function that maps features to a level of expertise for predicting a given input and  
\begin_inset Formula $f_{i}:\mathbb{R}^{n}\mapsto\mathbb{R}^{m}$
\end_inset

 is local internal prediction function that maps features to target outputs.
\end_layout

\begin_layout Standard
In CELL instantiations,
 the global prediction is obtained by aggregating the predictions of agents,
 leveraging activation and prediction functions through an aggregation function.
 If the activation function,
 the prediction function and the aggregation function are differentiable,
 then,
 by standard composition rule,
 the global prediction function of the system is differentiable.
\end_layout

\begin_layout Standard
For kCELL,
 we consider a RBF kernel as the activation function,
 an affine function as the prediction function and a weighted average as the aggregation function.
 The final prediction is obtained by 
\begin_inset Formula 
\begin{equation}
f\left(x\right)=\frac{\sum_{i}\phi_{i}\left(x\right)f_{i}\left(x\right)}{\sum_{i}\phi_{i}\left(x\right)}=\sum_{i}w_{i}\left(x\right)f_{i}\left(x\right)
\end{equation}

\end_inset

where 
\begin_inset Formula $w_{i}\left(x\right)$
\end_inset

 are the normalized weights such as 
\begin_inset Formula $\sum_{i}w_{i}\left(x\right)=1$
\end_inset

.
\end_layout

\begin_layout Standard
As all the involved functions are differentiable with respect to 
\begin_inset Formula $x$
\end_inset

,
 the derivative of the prediction function of the system if given by
\begin_inset Formula 
\begin{equation}
\frac{\partial f}{\partial x}\left(x\right)=\sum_{i}\left(\frac{\partial w_{i}}{\partial x}\left(x\right)f_{i}\left(x\right)+w_{i}\left(x\right)\frac{\partial f_{i}}{\partial x}\left(x\right)\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This property makes kCELL usable in gradient-based nonlinear optimization frameworks.
 However,
 we argue that a principled approach to linearization can be leveraged by exploiting kCELL's internal structure.
 In typical model-based control,
 non-linear dynamics are lienarized via a first-order Taylor expansion to fit the requirements of convex optimization 
\begin_inset CommandInset citation
LatexCommand cite
key "rawlings2017model"
literal "false"

\end_inset

.
 However,
 when the predictive model is already an ensemble of local linear structures,
 applying a Taylor expansion becomes conceptually redundant.
 For this reason,
 we propose to bypass standard differentiation in favor of the structural local linearization capabilities of kCELL.
\end_layout

\begin_layout Subsubsection
Local Linearization
\end_layout

\begin_layout Standard
In kCELL,
 the spatial organization of agents and their linear internal models allows to extract local affine models without computing full Jacobians or Taylor expansions.
\end_layout

\begin_layout Standard
In MPC,
 the predictive model predicts the next state 
\begin_inset Formula $s_{t+1}$
\end_inset

 from 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

 where 
\begin_inset Formula $s_{t}$
\end_inset

 is the current state of the system and 
\begin_inset Formula $u_{t}$
\end_inset

 is the action to take.
 Assuming agents have linear internal models 
\begin_inset Formula $f_{i}\left(x_{t}\right)=A_{i}s_{t}+B_{i}u_{t}+c_{i}$
\end_inset

,
 the local affine model around a query point 
\begin_inset Formula $x_{t}$
\end_inset

 is given by
\begin_inset Formula 
\begin{eqnarray}
A\left(x_{t}\right)s+B\left(x_{t}\right)u+c\left(x_{t}\right) & = & \sum_{i}w_{i}\left(x_{t}\right)f_{i}\left(x_{t}\right)\\
 & = & \sum_{i}w_{i}\left(x_{t}\right)\left(A_{i}s_{t}+B_{i}u_{t}+c_{i}\right)\\
 & = & \underbrace{\sum_{i}w_{i}\left(x_{t}\right)A_{i}}_{A\left(x_{t}\right)}s_{t}+\underbrace{\sum_{i}w_{i}\left(x_{t}\right)B_{i}}_{B\left(x_{t}\right)}u_{t}+\underbrace{\sum_{i}w_{i}\left(x_{t}\right)c_{i}}_{c\left(x_{t}\right)}\label{eq:kcell-local-linear-model}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
This approach offers a significant advanatge for control because it preserves the dynamics as learned by the model in the first place.
 
\end_layout

\begin_layout Subsubsection
Sequential Quadratic Programming (SQP)
\end_layout

\begin_layout Standard
Sequential Quadratic Programming (SQP) is a local optimization method designed for solving nonlinear constrained problems.
 The optimization problem to solve is a nonlinear program formulated as
\begin_inset Formula 
\begin{align*}
\min_{u_{0:T-1}}\,\,\, & J\left(s_{0:T},u_{0:T-1}\right)\\
\text{s.t.\,\,\, } & s_{t+1}=f\left(s_{t},u_{t}\right)\\
 & h\left(s_{t},u_{t}\right)\leq0\\
 & g\left(s_{t},u_{t}\right)=0
\end{align*}

\end_inset

where 
\begin_inset Formula $J:\mathbb{R}^{n\times T}\mapsto\mathbb{R}$
\end_inset

 is the cost function,
 
\begin_inset Formula $f$
\end_inset

 the dynamic function describing the system,
 
\begin_inset Formula $h$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 correspond respectively to the supplementary inequality and equality constraints.
\end_layout

\begin_layout Standard
At each iteration,
 the original nonlinear program is approximated by a Quadratic Program (QP) in which the objective is quadratic and the dynamics and constraints are linearized around a reference trajectory
\begin_inset Formula 
\begin{align*}
\min_{u_{0:T-1}}\,\,\, & \sum_{t=0}^{T-1}\left(s_{t}^{\top}Q_{t}s_{t}+q_{t}^{\top}s_{t}+u_{t}^{\top}R_{t}u_{t}+r_{t}^{\top}u_{t}\right)\\
\text{s.t.\,\,\, } & s_{t+1}=A_{t}s_{t}+B_{t}u_{t}+c_{t}\\
 & h_{\text{lin}}\left(s_{t},u_{t}\right)\leq0\\
 & g_{\text{lin}}\left(s_{t},u_{t}\right)=0
\end{align*}

\end_inset

where 
\begin_inset Formula $A_{t}$
\end_inset

,
 
\begin_inset Formula $B_{t}$
\end_inset

 and 
\begin_inset Formula $c_{t}$
\end_inset

 define the locally linearized dynamics obtained from a first-order Taylor expansion,
 
\begin_inset Formula $h_{\text{lin}}$
\end_inset

 and 
\begin_inset Formula $g_{\text{lin}}$
\end_inset

 correspond respectively to the linearized inequality and equality constraints obtained from a first-order Taylor expansion,
 the matrices 
\begin_inset Formula $Q_{t}$
\end_inset

,
 
\begin_inset Formula $R_{t}$
\end_inset

 and vectors 
\begin_inset Formula $q_{t}$
\end_inset

,
 
\begin_inset Formula $r_{t}$
\end_inset

 are obtained from a second-order Taylor expansion of the original cost 
\begin_inset Formula $J$
\end_inset

 around the reference trajectory 
\begin_inset Formula $\tau_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
Solving this QP yields a new trajectory 
\begin_inset Formula $\tau_{t+1}$
\end_inset

 than is used to compute a descent direction 
\begin_inset Formula $\tau_{t+1}-\tau_{t}$
\end_inset

.
 Since both SQP and kCELL rely on locally valid approximations of the dynamics,
 the update step must be restricted to remain within the region where the linearization is accurate.
 To this end,
 a line search 
\begin_inset CommandInset citation
LatexCommand cite
key "grippo1986nonmonotone"
literal "false"

\end_inset

 or trust-region strategy 
\begin_inset CommandInset citation
LatexCommand cite
key "conn2000trust,schulman2015trust"
literal "false"

\end_inset

 is typically employed to determine an appropriate step size that keeps linearization error contained and ensures sufficient cost decrease.
 This mechanism guarantees stable convergence when optimization trajectories with learned dynamics.
 The process is repeated until convergence.
\end_layout

\begin_layout Standard
Due to its spatialized agent-based structure,
 kCELL provides naturally the linearized dynamics needed for the local QP.
 As shown in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:kcell-local-linear-model"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 for a query point 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 the local affine model
\begin_inset Formula 
\[
s_{t+1}\approx\underbrace{A\left(x_{t}\right)}_{A_{t}}s_{t}+\underbrace{B\left(x_{t}\right)}_{B_{t}}u_{t}+\underbrace{c\left(x_{t}\right)}_{c_{t}}
\]

\end_inset

provides exactly the matrices needed for the linearized dynamics in the QP.
 This way the approximated QP subproblem is fully compliant with the dynamics initially learned by the model,
 without having to build a proxy through differentiation and Taylor expansion.
 Consequently,
 SQP-based MPC provides a principled and efficient way to exploit kCELL's local structure while being able to enforce hard constraints.
\end_layout

\begin_layout Standard
In this section we discussed about the integration of kCELL into real-time MPC pipelines by exploiting both its computational and structural properties.
 First the differentiable and modular nature of kCELL enables highly parallel trajectory unfolding,
 making population-based optimizer tractable through GPU based implmentations.
 This approach is particularly adapted for large-scale trajectory sampling and global solution exploration.
 Then,
 we showed that kCELL's agent-based structure provides both differentiability and explicit local affine models of the learned dynamicsk for gradientt-based MPC.
 This property naturally allow the use of SQP,
 which exploits local linear models to efficiently enforce hard constraints and produce smooth control trajectories.
 Ultimately,
 we showed that using a kCELL predictive dynamics model,
 both population-based and gradient-based optimization schemes could be leveraged.
\end_layout

\begin_layout Standard
Beyond computational efficiency,
 kCELL exposes introspection signals such as distance-based competence and local model disagreement that quantify the reliability of the predictions along candidate trajectories.
 in the remainder of this chapter,
 we explore the use of these introspection signals to improve control in terms of exploration and exploitation under operational constraints.
\end_layout

\begin_layout Section
Exploration MPC with kCELL
\begin_inset CommandInset label
LatexCommand label
name "sec:Exploration-MPC"

\end_inset


\end_layout

\begin_layout Standard
The integration of kCELL into SQP framework provides a solid and efficient way of exploiting current model knowledge.
 However,
 the performances of any model-based controller is bounded by the quality of the learned dynamics.
 In settings where no prior knowledge of the system is available,
 the controller must balance the minization of the task cost with the need to collect informative data in unknownn or poorly modeled regions of the state-action space.
\end_layout

\begin_layout Standard
Conventional exploration methods typically depend on heuristic noise processes (e.g Ornstein-Uhlenbeck noise 
\begin_inset CommandInset citation
LatexCommand cite
key "uhlenbeck1930theory"
literal "false"

\end_inset

) or on uncertainty-based mechanisms derived from auxiliary models,
 such bayesian posterior variances in Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "srinivas2009gaussian,ruiz2015general"
literal "false"

\end_inset

,
 intrinsic motivation signals in Curiosity-driven exploration 
\begin_inset CommandInset citation
LatexCommand cite
key "pathak2017curiosity"
literal "false"

\end_inset

,
 or novelty scores learned through Random Network Distillation 
\begin_inset CommandInset citation
LatexCommand cite
key "burda2018exploration"
literal "false"

\end_inset

.
 While effective in many situations,
 these approaches quantify uncertainty through probabilistic inference or learned proxies that are determined by model design choices,
 whereas kCELL exposes uncertainty as a structural and geometric property of its spatialized local learning architecture.
\end_layout

\begin_layout Standard
kCELL's spatialized agent-based architecture provides two distinct introspection signals that can be directly embedded into the MPC objective function to drive exploration of unknown states:
 distance-based competence and local model disagreement.
 
\end_layout

\begin_layout Standard
Distance-based competence quantifies how far a state-action pair lies from regions that are sufficiently covered by agents,
 providing a geometrical grounded measure of feature space epistemic uncertainty.
 Local model disagreement captures variability in the predicted dynamics across neighboring agents,
 yielding a local estimate of predictive uncertainty.
 Because kCELL operates in an online learning regime,
 these introspection quantities evolve through constant interaction with the environment and can be evaluated at every MPC iteration without retraining,
 posterior computations,
 or auxiliary optimization procedures.
\end_layout

\begin_layout Standard
Exploration can therefore be formulated as a deterministic,
 introspection-based regularization of the control objective,
 leading to the following augmented cost function
\begin_inset Formula 
\[
J\left(s_{t},u_{t}\right)=\alpha J_{\text{task}}\left(s_{t},u_{t}\right)+\lambda J_{\text{explore}}\left(s_{t},u_{t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $J_{\text{task}}$
\end_inset

 is the task-related cost function,
 
\begin_inset Formula $J_{\text{explore}}$
\end_inset

 the exploration penalty and  
\begin_inset Formula $\alpha\in\mathbb{R},\,\lambda\in\mathbb{R}$
\end_inset

 the adjustment weights to trade-off task exploitation and exploration.
\end_layout

\begin_layout Subsection
Distance-based Competence
\begin_inset CommandInset label
LatexCommand label
name "subsec:Distance-based-Competence"

\end_inset


\end_layout

\begin_layout Standard
Unlike opaque black-box models,
 kCELL provides an explicit measure of its degree of knowledge about specific regions of the feature space through the spatial distribution of agents.
 To encourage exploration,
 the model must acquire data that lie outside the currently covered regions,
 i.e outside regions that have been sufficiently visited.
 The degree of knowledge associated with a state-action pair can be quantified by evaluating the Mahalanobis distance between the pair and the closest agents.
\end_layout

\begin_layout Standard
The objective is to deliberately drive the state-action trajectories away from the currently covered regions of the feature space to collect informative samples in poorly modeled areas.
 To achieve this,
 we introduce a distance-based penalty term 
\begin_inset Formula $p_{\text{dist}}\left(x_{t}\right)$
\end_inset

 that augments the MPC cost function by promoting exploration of unknown regions such as
\begin_inset Formula 
\begin{eqnarray}
p_{\text{dist}}\left(x_{t}\right) & = & -\sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)\left(\left(x_{t}-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x_{t}-\mu_{i}\right)\right)\\
 & = & -\sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)d\left(\mathcal{A}_{i},x_{t}\right)^{2}
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 
\begin_inset Formula $D_{\text{closest}}$
\end_inset

is the set of the 
\begin_inset Formula $k$
\end_inset

-closest agents,
 
\begin_inset Formula $\mu_{i}$
\end_inset

 and 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 are the parameters of their activation function,
 
\begin_inset Formula $w_{i}\left(x_{t}\right)=\frac{\phi_{i}\left(x_{t}\right)}{\sum_{j}\phi_{j}\left(x_{t}\right)}$
\end_inset

 are the weights depending on the activation of each agent on 
\begin_inset Formula $x_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
Because the penalty is negative,
 minimizing the augmented MPC objective encourages trajectories that maximize the distance to the currently well-covered regions.
 in this context,
 
\begin_inset Formula $p_{\text{dist}}\ll0$
\end_inset

 means that 
\begin_inset Formula $x_{t}$
\end_inset

 is currently not supported by the agents' training data.
 Conversely,
 
\begin_inset Formula $p_{\text{dist}}\approx0$
\end_inset

 indicates that 
\begin_inset Formula $x_{t}$
\end_inset

 is close to a well-covered (known) region of feature space and is therefore likely to be already included in the current knowledge base.
\end_layout

\begin_layout Subsection
Local Disagreement
\begin_inset CommandInset label
LatexCommand label
name "subsec:Local-Disagreement"

\end_inset


\end_layout

\begin_layout Standard
In regions where multiple agents are close in feature space,
 the variance between their individual predictions serves as a proxy for local predictive inconsistency.
 High disagreement suggests that the local dynamics are either stochastic,
 noisy or that the model has not yet converged to a stable local representation.
\end_layout

\begin_layout Standard
The objective is to drive the state-action trajectories towards regions exhibiting high predictive disagreement to force the model to discover new areas or to converge in already known region of feature space.
 This mechanism is functionally analogous to uncertainty-driven exploration strategies proposed in 
\begin_inset CommandInset citation
LatexCommand cite
key "srinivas2009gaussian,ruiz2015general,pathak2017curiosity,burda2018exploration"
literal "false"

\end_inset

 while remaining fully intrinsic to the kCELL architecture.
 
\end_layout

\begin_layout Standard
To achieve this,
 we introduce a disagreement-based penalty term 
\begin_inset Formula $p_{\text{disagree}}\left(x_{t}\right)$
\end_inset

 that augments the MPC cost function by promoting exploration of highly uncertain regions of feature space,
 such as
\begin_inset Formula 
\begin{eqnarray}
p_{\text{disagree}}\left(x_{t}\right) & = & -\sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)\left\Vert f\left(x_{t}\right)-f_{i}\left(x_{t}\right)\right\Vert ^{2}
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 
\begin_inset Formula $D_{\text{closest}}$
\end_inset

is the set of the 
\begin_inset Formula $k$
\end_inset

-closest agents,
 
\begin_inset Formula $f\left(x_{t}\right)$
\end_inset

 is the global prediction of the system obtained by aggregating the predictions of the closest agents,
 
\begin_inset Formula $f_{i}\left(x_{t}\right)$
\end_inset

 is the prediction of the 
\begin_inset Formula $i$
\end_inset

-th agent,
 
\begin_inset Formula $w_{i}\left(x_{t}\right)=\frac{\phi_{i}\left(x_{t}\right)}{\sum_{j}\phi_{j}\left(x_{t}\right)}$
\end_inset

 are the weights depending on the activation of each agent on 
\begin_inset Formula $x_{t}$
\end_inset

.
\end_layout

\begin_layout Subsection
Comparative Study
\begin_inset CommandInset label
LatexCommand label
name "subsec:Exploration-Comparative-Study"

\end_inset


\end_layout

\begin_layout Standard
This section evaluates the effectiveness of the proposed introspection-driven exploration strategies based on distance-based competence and local model disagreement.
 The objective is to assess whether embedding these signals into the MPC objective leads to improved coverage of feature space in an online learning setup,
 compared to random uninform or purely exploitative exploration strategies.
\end_layout

\begin_layout Subsubsection
Experimental Protocol
\end_layout

\begin_layout Standard
This experiment is conducted on the classical Pendulum control task available in gymnasium reinforcement learning library 
\begin_inset CommandInset citation
LatexCommand cite
key "towers2024gymnasium"
literal "false"

\end_inset

,
 which exhibits nonlinear dynamics and presents a nontrivial exploration challenge.
 
\end_layout

\begin_layout Standard
States are composed of the 
\begin_inset Formula $x,y$
\end_inset

 2D-coordinates of the tip of the pendulum and of 
\begin_inset Formula $\dot{\theta}$
\end_inset

 the angular velocity.
 For convenience reasons,
 in subsequent figures,
 states are also represented by 
\begin_inset Formula $\theta$
\end_inset

,
 the angle and 
\begin_inset Formula $\dot{\theta}$
\end_inset

 to allow for 2D representations.
 
\end_layout

\begin_layout Standard
The pendulum is initialized at the bottom equilibrium with zero angular velocity (
\begin_inset Formula $\left\{ \theta=\pi,\,\dot{\theta}=0\right\} $
\end_inset

) at the beginning of each episode.
 No initial state randomization is applied.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert graph presenting the pendulum with polar coordinates and xy coordinates
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This way,
 high energy states are harder to reach,
 making the exploration harder for uninformed random strategies.
 The cost function to minimize to solve the task is the following
\begin_inset Formula 
\begin{equation}
\min_{u_{0:T}}\sum_{t=0}^{T}\left(\left(s_{t}-s_{\text{ref}}\right)^{\top}Q\left(s_{t}-s_{\text{ref}}\right)+u_{t}^{\top}Ru_{t}\right)+\left(\left(s_{T+1}-s_{\text{ref}}\right)^{\top}Q\left(s_{T+1}-s_{\text{ref}}\right)\right)
\end{equation}

\end_inset

with 
\begin_inset Formula $Q\in\mathbb{R}^{3\times3}$
\end_inset

,
 
\begin_inset Formula $R\in\mathbb{R}^{1\times1}$
\end_inset

 and  
\begin_inset Formula $s_{\text{ref}}$
\end_inset

 the target state to reach for the pendulum which usually is the top neutral position.
\end_layout

\begin_layout Standard
The agent interacts with the environment for a total of 5000 time steps,
 divided into episodes of 500 steps.
 During interaction,
 a kCELL model is learned online from streaming data to predict the next state.
\end_layout

\begin_layout Standard
Trajectory optimization is performed using the Cross-Entropy Method (CEM) because this approach is stochastic.
 Using a population-based optimizer naturally introduces variability in candidate action sequecnes.
 This stochasticity is important in the early learning phase of kCELL,
 as it avoids situations where newly created agents would be initialized with near-zero action variance,
 which can greatly hurt local model learning.
\end_layout

\begin_layout Standard
Four exploration strategies are evaluated:
\end_layout

\begin_layout Enumerate
Distance intrinsic exploration,
 where the cost function to minimize is the distance-based competence penalty introduced in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Distance-based-Competence"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
Disagreement intrinsic exploration,
 where the cost function to minimize is the disagreement-based penalty introduced in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Local-Disagreement"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
Pure exploitation,
 where only the original task cost is minimized without any exploration regularization.
\end_layout

\begin_layout Enumerate
Uniform random exploration,
 where actions are sampled uniformly at random within admissible bounds.
\end_layout

\begin_layout Standard
For all exploration strategies,
 the same kCELL architecture,
 with same hyperparameters and interaction budget is learned.
 The metrics measured in subsequent sections are averaged over 5 seeds to eliminate part of the stochastic bias induced by using stochastic optimizer and random exploration strategies.
 All strategies share identical model architecture,
 hyperparameters and interaction budget ensuring that observed differences arise solely from the exploration strategy.
\end_layout

\begin_layout Subsubsection
Quantitative State-Space Coverage
\end_layout

\begin_layout Standard
To quantify the state exploration performance,
 the continuous state space is discretized into a regular grid of bins (50 bins per dimension).
 Each visited state is mapped to its corresponding bin,
 which is then marked as visited.
 State-space coverage is then defined as the ratio of visited bins to the total number of bins.
 The final coverage ratios are (averaged over 5 seeds),
 are reported in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Space-Coverage"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{0.95
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disagreement (ours)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Distance (ours)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Uniform
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Full Exploitation
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Coverage (in %)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\begin_inset Formula $\mathbf{58.6\pm5}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\begin_inset Formula $\mathbf{57.9\pm3}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $49.2\pm6$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $8\pm4$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Measured state space coverage ratio (in %) after 5000 exploration steps.
 Best scores are highlighted in bold.
 
\begin_inset CommandInset label
LatexCommand label
name "tab:Space-Coverage"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The results show that both introspection-driven strategies (distance-based competence and local disagreement) achieve significantly higher state-space coverage than the uninformed random uniform strategy under the same interaction budget:
 
\begin_inset Formula $\approx10\%$
\end_inset

 higher ratio for introspection-based strategies.
 Conversely,
 with pure exploitation strategy,
 where the controller optimizes only the task cost without any exploration regularization,
 results in the lowest coverage.
 This indicates that in the absence of prior knowledge of the dynamics,
 exploitation (i.e optimizing the task objective) alone is insufficient to drive the system toward diverse and informative regions of the state space.
\end_layout

\begin_layout Standard
Furthermore,
 The distance-based and disagreement-based strategies achieve comparable final coverage levels,
 indicating that both introspection signals are effective at promoting exploration beyond the regions initially supported by the data.
\end_layout

\begin_layout Subsubsection
Evolution of Coverage during Exploration
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-the-coverage"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolution of state-space coverage over time averaged over 5 seeds.
 The two introspection-driven strategies consistently dominate the random uniform baseline.
 Pure exploitation seems to remain confined to a narrow subset of states and fails to significantly increase coverage.
\end_layout

\begin_layout Standard
Both introspection-driven strategies show comparable growth in coverage over time.
 Minor differences in variability across seeds are observed but the mean coverage remains similar.
 This suggests that both strategies effectively promote exploration.
 Any apparent differences should be interpreted cautiously as they may not be statistically significant.
\end_layout

\begin_layout Standard
Overall,
 these results confirm that embedding introspection signals directly into the MPC objective yields an exploration advantage over uninformed stochastic action sampling.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/coverage_evolution_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the measured state space coverage ratio during exploration phase.
 
\emph on
x
\emph default
-axis corresponds to the number of steps and 
\emph on
y
\emph default
-axis corresponds to the measured state space coverage ratio.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-the-coverage"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Spatial Distribution of Visited States
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Obtained-space-coverage"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents heatmaps of visited states in the (
\begin_inset Formula $\theta,\,\dot{\theta}$
\end_inset

) space after the exploration phase.
 For all strategies,
 states corresponding to low angular velocities and angles that are close to the starting configuration (
\begin_inset Formula $\theta\approx\pi$
\end_inset

) are visited more frequently,
 reflecting the energy barrier associated with reaching high energy states associated with throwing the pendulum tip all the way to the top.
\end_layout

\begin_layout Standard
Clear differences emerge between strategies.
 Both distance-based and disagreement-based explorations achieve substantially broader coverage,
 with frequent visits to high-energy states corresponding to near-upright pendulum configurations (
\begin_inset Formula $\theta\approx0$
\end_inset

 or 
\begin_inset Formula $2\pi$
\end_inset

) and large angular velocities.
 In contrast,
 the random uniform strategy exhibits sparse and uneven coverage,
 with large regions remaining unvisited (especially in high energy regions).
 Pure exploitation remains almost entirely confined near the starting state.
 It consistently fails to overcome the energy barrier required to explore the upper half of the state space.
\end_layout

\begin_layout Standard
These observations highlight the limitations of uninformed random exploration in structured dynamical systems and demonstrate that introspection driven objectives allow the controller to deliberately seek out to reach informative regions of that are otherwise difficult to reach.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/coverage_heatmap_2x2_notitle_5k.png
	lyxscale 15
	width 95col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Obtained space coverage for the exploration strategies considered.
 
\emph on
Top-left
\emph default
 corresponds to Disagreement strategy;
 
\emph on
Top-right
\emph default
 corresponds to Distance strategy,
 
\emph on
Bottom-left
\emph default
 corresponds to Random Uniform strategy;
 and 
\emph on
Bottom-right
\emph default
 corresponds to Full Exploitation strategy.
 The more yellow,
 the more the cell has been visited across the different seeds,
 conversely for blue colored cells.
 
\emph on
y
\emph default
-axis corresponds to the angle and 
\emph on
x
\emph default
-axis corresponds to angular velocity.
\begin_inset CommandInset label
LatexCommand label
name "fig:Obtained-space-coverage"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Activation Patterns and Local Geometry
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation Patterns"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the spatial organization of kCELL agents after the exploration phase.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-XY-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows agent activations projected onto the Cartesian coordinates of the pendulum tip.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 displays activations in the (
\begin_inset Formula $\theta,\,\dot{\theta}$
\end_inset

) space.
\end_layout

\begin_layout Standard
For the distance-based and disagreement-based strategises,
 agent activations cover the entire circular manifold corresponding to the pendulum's reachable positions,
 indicating that even high-energy and rarely visited states are locally modeled by dedicated agents.
 In contrast,
 with the random uniform and pure exploitation strategies,
 agent activations are concentrated in the lower-energy regions of the state space.
\end_layout

\begin_layout Standard
A broader diversity in agent sizes can be observed for the introspection-driven strategies.
 This is most likely due to kCELL agent creation mechanism,
 which creates agents from a minimum number of samples to ensure thet local models are quickly reliable.
 In high-velocity regimes or during abrupt torque changes such as strong braking events,
 state transitions are more widely distributed,
 leading to larger initial covariance estimates.
 These larger agents are not pathological artifacts but instead reflect an specific experience of data,
 here corresponding to regions of high local variability.
\end_layout

\begin_layout Standard
For example,
 in the (
\begin_inset Formula $\theta,\,\dot{\theta}$
\end_inset

) projection,
 some agents appear elongated along one dimension especially for the Distance-based strategy.
 Analysis of their covariance matrices reveals that these agents correspond to sharp directional changes in the dynamics,
 typically induced by large control intpus applied against the direction of motion.
 As such,
 agent geometry seems to provide an interpretable signature of local dynamical regimes encountered during exploration.
 The Distance-based strategy seeming to have more of these king of agents could be due to a more agressive exploration strategy that prioritizes more extreme action variations.
\end_layout

\begin_layout Standard
These activation patterns demonstrate that kCELL does not cover the state space uniformly but organizes local models in a manner that reflects the underlying geometry and variability of the dynamics encountered during exploration.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/activation_patterns_xy_notitle_5k.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Activation-Patterns-XY-Pendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/activation_patterns_angle_angular_velocity_5k_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Activation Patterns"

\end_inset

 Visualization of the activation patterns of agents for all considered strategies.
 Starting from the top,
 
\begin_inset Formula $1^{st}$
\end_inset

 plot corresponds to the Disagreement strategy;
 
\begin_inset Formula $2^{nd}$
\end_inset

 plot corresponds to the Distance strategy,
 
\begin_inset Formula $3^{rd}$
\end_inset

 plot corresponds to the Random Uniform Strategy and finally 
\begin_inset Formula $4^{th}$
\end_inset

 plot corresponds to the Full Exploitation strategy.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-XY-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the activation patterns of agents projected in the space of 2D coordinates of the tip of the pendulum (
\begin_inset Formula $x=\cos\left(\theta\right)$
\end_inset

 and 
\begin_inset Formula $y=\sin\left(\theta\right)$
\end_inset

).
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the activation patterns of agents projected in the space of Angle (
\emph on
y
\emph default
-axis) and Angular Velocity (
\emph on
x
\emph default
-axis).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Population Dynamics
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-agent-population-pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolutions of the number of agents during exploration.
 Both introspection-driven strategies lead to a substantially larger number of agents than the random uniform and pure exploration baselines.
 This increase is positively correlated with the observed improvement in state-space coverage.
\end_layout

\begin_layout Standard
While both introspection-driven strategies generate more agents overall,
 the disagreement-based strategy exhibits higher variability in agent population across the 5 considered seeds,
 which is consistent with the higher sensitivity of disagreement to local modeling inconsistencies.
 The more the space is covered,
 the more the local models can conflict locally and drive exploration to them for consolidation.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/nb_agents_evolution_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-agent-population-pendulum"

\end_inset

Evolution of agent population for the four considered strategies average over 5 seeds.
 
\emph on
y
\emph default
-axis corresponds to the number of agents and 
\emph on
x
\emph default
-axis corresponds to the number of exploration steps.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Prediction Accuracy and Sample Efficiency
\end_layout

\begin_layout Standard
To assess whether introspection-driven exploration strategies translate into better models,
 we evaluate the predictive accuracy of kCELL after the exploration phase.
 For each exploration strategy,
 the learned model is evaluated on an exhaustive test set crafted specifically to cover a large portion of the state-action space.
 Model performance is quantified using the root mean squared error (RMSE) between predicted and ground-truth next states.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RMSE-after-exploration"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 presents a bar plot that reports the average RMSE across five seeds for the four exploration strategies.
\end_layout

\begin_layout Standard
Both introspection-driven strategies achieve substantially lower prediction error than the random uniform and pure exploitation baselines.
 In contrast,
 no statistically significant difference in RMSE is observed between the distance-based and disagreement-based strategies.
\end_layout

\begin_layout Standard
These results indicate that introspection-driven exploration improves the sample efficiency of online model learning in kCELL.
 While the two introspection signals lead to slightly different exploration dynamics,
 they results in comparable models in terms of predictive quality under the same interaction budget.
 This suggests that the shallow performance differences observed in state-space coverage are not likely associated with systematic differences in model accuracy under the considered interaction budget and evaluation protocol.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/RMSE_bar_no_title_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RMSE-after-exploration"

\end_inset

RMSE averaged over 5 seeds.
 
\emph on
y
\emph default
-axis is the RMSE and 
\emph on
x
\emph default
-axis ticks corresponds to the corresponding exploration strategy.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Global Action Distribution
\end_layout

\begin_layout Standard
Although distance-based and disagreement-based strategies yield comparable coverage and predictive accuracy,
 minor differences in exploration dynamics were observed in coverage variability and in agent population statistics across seeds.
 Those variations are subtle and may reflect stochastic effects of the optimizer rather than systematic differences.
 To investigate the general behavior of the controller under introspection-driven exploration objectives,
 we analyzed the distribution of actions taken during exploration.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Actions-KDE-after-exploration"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents kernel density estimates of the applied control inputs.
\end_layout

\begin_layout Standard
The resulting action distributions are very similar for both introspection-driven strategies.
 Three dominant modes can be observed centered around saturated control actions (-2,
 2) and near-zero actions.
 This multimodal structure contrasts with the random uniform baseline.
 It indicates that both introspection-driven strategies induce structured non-uniform action profiles.
 The presence of repeated extreme actions suggests that introspection-driven objectives actively promote saturated actions in order to reach higher energy states rather than relying on diffuse stochastic perturbations.
\end_layout

\begin_layout Standard
These results suggest that the observed similarities in coverage and model accuracy are more likely attributable to how these signals interact with local geometry and agent creation rather than fundamentally different global action sampling behaviors.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/actions_KDE_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Actions-KDE-after-exploration"

\end_inset

KDE density over actions taken during exploration for each considered exploration strategy.
 
\emph on
y
\emph default
-axis is the KDE density and 
\emph on
x
\emph default
-axis ticks corresponds to the actions (in pendulum it corresponds to the applied torque).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Discussion
\end_layout

\begin_layout Standard
The experimental results presented in this section demonstrate that introspection-driven exploration strategies based on kCELL online modeling improve exploration efficiency in model-based control settings without prior knowledge of the system dynamics.
 By embedding distance-based competence and local model disagreement directly into the MPC objective,
 the controller is able to consistently escape well-modeled regions and acquire informative data in unknown regions of the state-action space.
\end_layout

\begin_layout Standard
Coverage metrics and spatial visualizations show that both introspection-driven strategies lead to a better coverage than uninformed random uniform exploration and pure exploitation.
 Introspection-driven strategies are able to overcome the energy barrier induced by the pendulum environment.
 High energy configurations are repeatedly visited despite being hard to reach for uninformed strategies.
 These results confirm that effective exploration cannot be achieved through randomly uniform actions alone,
 but instead requires additional motivations like model knowledge or uncertainty.
\end_layout

\begin_layout Standard
The analysis of global action distributions confirms that both introspection-driven strategies induce structured multimodal action profiles that facilitate exploration of high-energy states.
 The similarities observed in these distributions suggest that the two strategies behave comparably interms of global action patterns.
 Differences in coverage or agent population arise primarily from interactions with local agent geometry rather than fundamentally different action sampling.
\end_layout

\begin_layout Standard
At the agent level,
 activation patterns and population dynamics provide insights into the underlying mechanisms of introspection-driven exploration strategies.
 Increased agent creation correlates strongly with improved coverage.
 This indicates that exploration emerges from the interaction between the introspection objective and kCELL's agent creation process.
 Furthermore,
 agent geometry and size variability reflect local properties of the dynamics.
 For example,
 for high-velocity regimes,
 created agents tend to be larger or for sharp directional changes,
 agents displays a high variance on the action dimension.
 Each agent represents a singular experience of data.
 This highlights one of the key advantage of kCELL,
 which is its interpretability.
 Indeed,
 uncertainty and model structure are not hidden within opaque parameters but instead manifest explicitly through the spatial organization of agents.
\end_layout

\begin_layout Standard
Finally,
 the observed improvements in predictive accuracy confirm that introspection-driven exploration translates into concrete benefits for online model learning.
 Under a fixed interaction budget,
 broader and more structured exploration leads to more accurate learning dynamics.
 It reinforces the link between exploration strategy,
 model quality and downstream control performance.
\end_layout

\begin_layout Standard
Overall,
 kCELL's architecture allows to extract introspection signals that can be leveraged successfully to build efficient uncertainty-aware exploration mechanisms without prior knowledge about the dynamics of the environment.
 Those mechanisms do not rely on external stochastic processes or auxiliary uncertainty models.
\end_layout

\begin_layout Subsubsection
Limitations
\end_layout

\begin_layout Standard
While the results demonstrate the effectiveness of introspection-driven exploration with kCELL,
 several limitations still stand and need to be acknowledged.
\end_layout

\begin_layout Standard
kCELL was introduced to address the overoptimistic spatial representations of oCELL (cf.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) that originated from the use of orthotope based spatialization.
 While allowing more degrees of freedom and a better representative power,
 using Gaussian-based spatialization introduces its own set of constraints.
 Agents are spatialized using RBF kernels parameterized by the mean and covariance estimated from local ingested data.
 As a result,
 agent creation requires a minimum diversity level to avoid ill-conditioned covariance estimates.
 In practice,
 this makes early exploration phases or low-variability action regimes potentially problematic.
 On the other hand,
 while population-based optimizers such as CEM introduce stochasticity that partially mitigates this issue by inducing action variability,
 excessive dispersion of actions can lead to overly extended agents and interpolation errors.
 This effect can be observed in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 through some agents that appear elongated (especially for distance-based strategy) due to too spread out actions.
 These agents still represent valid local experiences but such behavior may pose challenges when extending the approach to more complex control environments.
\end_layout

\begin_layout Standard
The Gaussian assumption underlying agent spatialization restricts the ability of kCELL to faithfully represent complex or multimodal feature manifolds that cannot be represented by a single Gaussian kernel.
 The agent population can approximate such structures through multiple overlapping agents,
 but this approximation remains indirect.
 Extending the spatialization mechanism beyond Gaussian assumptions,
 for example by using kernel density estimates or mixture-based representations,
 could allow kCELL to better capture complex feature geometries.
 
\end_layout

\begin_layout Standard
The experimental evaluation is restricted to a low-dimensional control problem (3 state dimensions and 1 action dimension).
 The pendulum environment captures nontrivial exploration challenges such as energy barriers.
 However,
 scalability to higher-dimensional systems remains an open question for kCELL.
 In such settings,
 agent management,
 coverage estimation and computational overhead may require additional mechanisms such as dimensionality reduction (which we explore in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
Finally,
 this study considers distance-based competence and local disagreement as independent exploration objectives.
 A combined approach was not explored,
 primarily because thses introspection signals operate on very different scales and have distinct geometrical interpretations.
 Investigating principled combinations or adaptive weighting schemes between distance-based and disagreement-based objectives could reveal complementary effects and lead to more exhaustive exploration strategies.
\end_layout

\begin_layout Standard
Beyond exploration,
 introspection signals extracted from kCELL naturally lead to the design of conservative control strategies under learned dynamics.
 While exploring exploits these signals to deliberately seek poorly modeled regions,
 the same quantities can be repurposed during exploitation to bias the controller toward states where the model is locally reliable.
 In this setting,
 introspection costs no longer acts as penalties but as a confidence-aware bonuses that encourage trajectoires to remain close to existing agents,
 i.e close to the current knwoledge of the model.
\end_layout

\begin_layout Section
Conservative MPC with kCELL
\begin_inset CommandInset label
LatexCommand label
name "sec:Conservative-MPC"

\end_inset


\end_layout

\begin_layout Standard
Exploration strategies relying on kCELL intrinsic multiagent structure have shown successful to drive exploration in an unknown environment,
 leading to better predictive learned dynamic models than when exploring with uninformed random strategies.
\end_layout

\begin_layout Standard
To achieve safe control with learned models,
 i.e reliability of controllers,
 the problem of compounding errors and uncertainty in the model predictions need to be addressed at exploitation time 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

.
 With inexact dynamic models,
 small errors on the first horizon steps leads to massive errors over time.
 Compounding errors are deeply linked to epistemic uncertainty (lack of knowledge about the underlying true dynamics).
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

,
 the authors discuss using Gaussian Processes (GPs) 
\begin_inset CommandInset citation
LatexCommand cite
key "williams1995gaussian"
literal "false"

\end_inset

 or Bayesian Neural Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "blundell2015weight"
literal "false"

\end_inset

 to quantify the prediction uncertainty and take it into account in optimization to obtain safe conservative control policies.
\end_layout

\begin_layout Standard
kCELL's spatialized agent-based architecture provides valuable introspection signals that can serve as proxies for epistemic uncertainty.
 Those introspection signals can be directly embedded into the MPC objective to regularize the behavior of the resulting policy by keeping the explored states at optimization time into the knowledge landscape of the model,
 avoiding wandering into unknown states that would induce large error compounding effects.
\end_layout

\begin_layout Standard
In this chapter we focus specifically on distance-based competence introspection signals that quantify how far a state lies from regions that are sufficiently covered by agents.
 It provides a geometrically grounded measure of epistemic uncertainty.
\end_layout

\begin_layout Standard
To bias the policy toward a more conservative knowledge-aware regime,
 an introspection-based regularization of the control objective is defined,
 leading to the following augmented cost function
\begin_inset Formula 
\[
J\left(s_{t},u_{t}\right)=\alpha J_{\text{task}}\left(s_{t},u_{t}\right)+\lambda J_{\text{conservative}}\left(s_{t},u_{t}\right)
\]

\end_inset

where 
\begin_inset Formula $J_{\text{task}}$
\end_inset

 is the task-related cost function,
 
\begin_inset Formula $J_{\text{conservative}}$
\end_inset

 the conservative regularization term and  
\begin_inset Formula $\alpha\in\mathbb{R},\,\lambda\in\mathbb{R}$
\end_inset

 the adjustment weights to trade-off task exploitation and conservatism.
 In this context we define a conservative policy,
 as a policy that is biased toward minimizing epistemic uncertainty.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Mention the fact that in results,
 we observe that getting closer to the knowledge base of the model = less compounding errors => solid argument in favor of the local expertise hypothesis.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Define reliability
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
We use regularization to increase the confidence we can have in the model at optimization time => this is required for safety / reliability of the controller (cf paper Safe Control Review) => we advance toward safety
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Distance-based Conservatism
\begin_inset CommandInset label
LatexCommand label
name "subsec:Distance-based-Conservatism"

\end_inset


\end_layout

\begin_layout Standard
Unlike opaque black-box models,
 kCELL provides an explicit measure of its degree of knowledge about specific regions of the feature space through the spatial distribution of agents.
 To encourage conservatism,
 the controller must keep evaluated solutions and state trajectories close to the covered regions of the feature space.
 In kCELL,
 the degree of knowledge associated with an input 
\begin_inset Formula $x_{t}$
\end_inset

 can be quantified by evaluating the Mahalanobis distance between 
\begin_inset Formula $x_{t}$
\end_inset

 and the closest agents.
\end_layout

\begin_layout Standard
In kCELL one of the structural hypothesis is that agents are local experts on the function to approximate and that the closer an input is to the center of an agent,
 the most probable the prediction will be accurate.
 Thus,
 the objective is to deliberately drive the trajectories close to the currently covered regions,
 that is to say,
 closer to the center of agents.
\end_layout

\begin_layout Standard
To achieve this,
 we introduce a distance-based regularization term 
\begin_inset Formula $q_{\text{dist}}\left(x_{t}\right)$
\end_inset

 that augments the MPC cost function by promoting conservative behaviors such as
\begin_inset Formula 
\begin{eqnarray}
q_{\text{dist}}\left(x_{t}\right) & = & \sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)\left(\left(x_{t}-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x_{t}-\mu_{i}\right)\right)\\
 & = & \sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)d\left(\mathcal{A}_{i},x_{t}\right)^{2}
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 
\begin_inset Formula $D_{\text{closest}}$
\end_inset

is the set of the 
\begin_inset Formula $k$
\end_inset

-closest agents,
 
\begin_inset Formula $\mu_{i}$
\end_inset

 and 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 are the parameters of their activation function,
 
\begin_inset Formula $w_{i}\left(x_{t}\right)=\frac{\phi_{i}\left(x_{t}\right)}{\sum_{j}\phi_{j}\left(x_{t}\right)}$
\end_inset

 are the weights depending on the activation of each agent on 
\begin_inset Formula $x_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
Because the penalty is positive,
 minimizing the augmented MPC objective encourages trajectories that minimize the distance to the currently well-covered regions (in constrast to what is done for exploration in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Distance-based-Competence"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 in this context,
 
\begin_inset Formula $q_{\text{dist}}\gg0$
\end_inset

 means that 
\begin_inset Formula $x_{t}$
\end_inset

 is currently not supported by the agents' training data.
 Conversely,
 
\begin_inset Formula $q_{\text{dist}}\approx0$
\end_inset

 indicates that 
\begin_inset Formula $x_{t}$
\end_inset

 is close to a well-covered (known) region of feature space and is therefore likely to have been encountered during training.
 As 
\begin_inset Formula $q_{\text{dist}}$
\end_inset

 is convex,
 it can easily be embedded for optimization with fast conic solvers like OSQP 
\begin_inset CommandInset citation
LatexCommand cite
key "stellato2020osqp"
literal "false"

\end_inset

 within the context of Sequential Quadratic Programming (SQP) optimization framework.
\end_layout

\begin_layout Subsection
Comparative Study
\end_layout

\begin_layout Standard
This section evaluates the effectiveness of the proposed introspection-driven regularization term based on distance to agents in a learned kCELL system through a low-dimensional experiment.
 The objective is to assess whether embedding this regularization term into the MPC objective yields better known trajectories,
 less compounding errors and if there is a tradeoff between conservativeness and task resolution performance.
\end_layout

\begin_layout Subsubsection
Experimental Protocol
\end_layout

\begin_layout Standard
This experiment evaluates the impact of introspection-driven conservative regularization on the reliability of trajectory optimization using a kCELL learned dynamics model within a MPC scheme.
 The objective is to assess whether considering the spatialization of agents of a kCELL model during optimization reduces extrapolation errors and improves robustness of long-horizon predictions.
\end_layout

\begin_layout Standard
The experiment is conducted on the classical Pendulum control task available in gymnasium reinforcement learning library 
\begin_inset CommandInset citation
LatexCommand cite
key "towers2024gymnasium"
literal "false"

\end_inset

 which exhibits nonlinear dynamics.
 States are composed of the 
\begin_inset Formula $x,\,y$
\end_inset

 2D-coordinates of the tip of the pendulum and of 
\begin_inset Formula $\dot{\theta}$
\end_inset

 the angular velocity.
\end_layout

\begin_layout Standard
A kCELL model is learned online from streaming interaction data.
 The population of linear agent predictors is spatialized in the state space (not including actions).
 This design choice is motivated by empirical observations on the pendulum task.
 Indeed,
 spatializing agents jointly over state and action dimensions leads to slower stabilization of agent population,
 whereas state-only spatialization resulted in faster convergence of local models and more stable agent coverage.
 Given the low-dimensional action space and the smooth dynamics,
 state-based spatialization provides a favorable tradeoff between model predictive accuracy and sample efficiency.
\end_layout

\begin_layout Standard
To ensure a sufficient coverage of the state space,
 an informed finetuned stochastic exploration policy based on Ornstein-Uhlenbeck (OU) noise is used to interact with the simulation environment to collect learning data.
 This exploration phase to build a kCELL model is conducted for a fixed interaction budget of 30k steps.
 The learned dynamics model is frozen and used subsequently for evaluation.
 No further learning occurs during evaluation,
 ensuring that observed effects are attributable to the optimization strategy rather than continued model adaptation.
\end_layout

\begin_layout Standard
Control actions are obtained using a MPC scheme.
 Action sequences are optimized over a finite horizon using the learned kCELL dynamics.
 Trajectory optimization is performed using SQP with OSQP conic solver to solve the local Quadratic Programs at each iteration.
 Using SQP,
 a gradient-based optimizer,
 allows to isolate the effect of the proposed regularization without introducing stochastic variability which is inherent to population-based optimization methods.
\end_layout

\begin_layout Standard
The baseline optimization objective,
 i.e the cost function to minimize to solve the task is the following
\begin_inset Formula 
\begin{equation}
\min_{u_{0:T}}\sum_{t=0}^{T}\left(\left(s_{t}-s_{\text{ref}}\right)^{\top}Q\left(s_{t}-s_{\text{ref}}\right)+u_{t}^{\top}Ru_{t}\right)+\left(\left(s_{T+1}-s_{\text{ref}}\right)^{\top}Q\left(s_{T+1}-s_{\text{ref}}\right)\right)
\end{equation}

\end_inset

with 
\begin_inset Formula $Q\in\mathbb{R}^{3\times3}$
\end_inset

,
 
\begin_inset Formula $R\in\mathbb{R}^{1\times1}$
\end_inset

 and  
\begin_inset Formula $s_{\text{ref}}$
\end_inset

 the target state to reach for the pendulum which usually is the top neutral position.
\end_layout

\begin_layout Standard
To this objective,
 an additional conservative regularization term 
\begin_inset Formula $q_{\text{dist}}$
\end_inset

 is introduced (cf Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Distance-based-Conservatism"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 This regularization term is weighted by a coefficient 
\begin_inset Formula $\lambda\geq0$
\end_inset

,
 penalizing predicted trajectories that run accross low coverage regions of the state space,
 envouraging solutions that remain within areas well covered by the agent.
 The goal is to stay close to what the model knows.
\end_layout

\begin_layout Standard
The evaluation is conducted for multiple values of 
\begin_inset Formula $\lambda$
\end_inset

.
 We refer to the unregularized case 
\begin_inset Formula $\lambda=0$
\end_inset

 as the baseline.
 To evaluate robustness and reliability independently of exploration stochasticity,
 control performance is assessed from an exhaustive set of initial states sampled over a grid in the state space.
 For each initial state,
 the predictions produced by kCELL with the found solution are compared against the ground-truth trajectory.
 This allows direct measurement of prediction error against the true dynamics,
 also allowing to assess the compounding effects on a given horizon.
 All evaluations are performed using identical MPC horizons (
\begin_inset Formula $T=20$
\end_inset

),
 cost function,
 solver parameters and constraints across regularization settings.
\end_layout

\begin_layout Subsubsection
Validation of Regularization Behavior
\end_layout

\begin_layout Standard
To validate the behavior of the regularization term,
 we measure the mean agent activation along optimized trajectories.
 Activation of agents serves as a proxy for epistemic uncertainty by measuring the distance to the closest experts in state space.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Boxplot-Mean-Activation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents boxplots of the mean agent activation for each considered values of 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Standard
As 
\begin_inset Formula $\lambda$
\end_inset

 increases,
 we observe a clear increase in mean agent activation indicating that the optimizer progressively favors trajectories that remain closer to the centers of kCELL agents,
 i.e within regions that are well supported by training data.
 This behavior is consistent with the expected behavior of the regularization term 
\begin_inset Formula $q_{\text{dist}}$
\end_inset

.
 The optimization landscape is effectively reshaped.
\end_layout

\begin_layout Standard
In addition to that,
 increasing 
\begin_inset Formula $\lambda$
\end_inset

 also yields a noticeable reduction in the spread of the activation distributions across initial conditions.
 This reduced variability indicates that under stronger regularization trajectories initialized in different regions are increasingly constrained to remain within similarly well-supported regions.
 This effect suggests that the regularization not only increases overall conservatism but also homogenizes the level of model support encountered along optimized trajectories.
\end_layout

\begin_layout Standard
These results validate the behavior of the introspection-driven regularization mechanism.
 The regularizer acts as intended by increasing the proximity of optimized trajectories to kCELL agent centers and reduces variability in model competence across initial conditions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/boxplot_mean_activation_vs_reg_coeff.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Boxplot-Mean-Activation"

\end_inset

 Boxplots of the mean activation over optimized trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the mean activation over optimized trajectories and 
\emph on
x
\emph default
-axis corresponsd to values of 
\begin_inset Formula $\lambda$
\end_inset

.
 The blue curve corresponds to the global mean and the orange bars correspond to the median value.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Impact on Prediction Accuracy
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Boxplot-Pred-Error"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents boxplots of the mean absolute error over trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 For each value of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

,
 along each optimized rollout,
 the predicted state transitions produced by kCELL are compared against ground-truth trajectories.
 Prediction error is computed and aggregated over the horizon.
\end_layout

\begin_layout Standard
As the regularization coefficient increases,
 a downward shift of the error distributions can be observed.
 Higher values of 
\begin_inset Formula $\lambda$
\end_inset

 correspond to lower median and mean prediction errors indicating that trajectories optimized under strong regularization are predicted more accurately on average by the learned model.
 This behavior is consistent with the core hypothesis of kCELL that stipulates that regions of high agent activation correspond to areas where local linear models provide the most reliable approximations of the true dynamics.
\end_layout

\begin_layout Standard
This reduction in prediction error does not arise from any modification of the learned kCELL model itself which remains fixed during evaluation.
 Instead,
 it is a direct consequent of the optimizer preferentially selecting trajectories that remain within regions of the state space that are well supported by training data.
 Thus,
 the regularization acts as a mechanism for smarter model usage rather than model improvement.
 By penalizing trajectories that lie too much in lowly covered regions,
 the optimizer performs a form of constrained optimization where the constraint is the validity of the local linear approximation.
\end_layout

\begin_layout Standard
In addition to that,
 the downward shift in mean absolute error distributions for increasing values of 
\begin_inset Formula $\lambda$
\end_inset

 is accompanied to a decrease in the spread of the error distributions.
 This indicates that large mean prediction errors become progressively less frequent as regularization strength increases.
 This suggests that distance-based regularization not only improves average prediction accuracy but also reduces the occurence of extreme prediction failures across considered initial conditions.
 This effect is particularly relevant in terms of reliability of the model as it seems to successfully prevent to some extent,
 the controller to exploit faulty out of distribution trajectories.
\end_layout

\begin_layout Standard
Overall,
 these results confirm that the spatial organization of agents in a kCELL model encodes meaningful information about local model reliability.
 This information can be effectively exploited during trajectory optimization.
 By encouraging trajectories to remain within regions of high agent coverage,
 the proposed regularization yields more accurate and more consistent predictions.
 This way it improves the reliability of model-based control with learned dynamics.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/boxplot_mean_absolute_error.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Boxplot-Pred-Error"

\end_inset

Boxplots of the mean absolute error over optimized trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the mean absolute error over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to values of 
\begin_inset Formula $\lambda$
\end_inset

.
 The blue curve corresponds to the global mean and the orange bars correspond to the median value.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Impact on Compounding Errors
\end_layout

\begin_layout Standard
One of the main limitations of learned dynamics models in model-based control is their susceptibility to error accumulation over long prediction horizons.
 Even small local inaccuracies can compound across successive rollout steps rapidly degrading the prediction quality and optimization results in the process.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pred-Error-vs-Horizon-Steps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolution of the mean absolute prediction error over the prediction horizon for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Standard
In the absence of regularization,
 for the baseline,
 the prediction error increases rapidly with the horizon length reflecting the compounding effects of model errors in multi-step rollouts.
 This behavior highlights represents a challenge in standard MPC schemes based on learned dynamics models when operating with out of distribution data 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
As 
\begin_inset Formula $\lambda$
\end_inset

 values increase,
 the rate at which prediction error grows with the horizon steps is substantially reduced.
 Stronger regularization leads to consistently lower prediction errors especially for more distant horizon steps.
 This confirms that the primary benefit of the proposed regularization lies in mitigating compounding errors rather than improving one-step prediction accuracy.
\end_layout

\begin_layout Standard
Overall,
 these results show that this introspection-based regularization term improves the reliability of long-horizon predictions in MPC.
 By maintaining the trajectory within highly covered regions,
 the error propagation is dampened,
 preventing the exponential divergence typically observed in the unregularized case over the horizon.
 It reduces the myopic behavior induced by error-prone rollouts and enhances the practical usability of kCELL learned dynamics models for more reliable control policies.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/mean_prediction_error_per_horizon_step.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Pred-Error-vs-Horizon-Steps"

\end_inset

Evolution of the mean absolute error over the prediction horizon for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the mean absolute error over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to the horizon steps.
 Each colored curve corresponds to a given value of 
\begin_inset Formula $\lambda$
\end_inset

.
 The 
\begin_inset Formula $\lambda=0$
\end_inset

 curve corresponds to the unregularized baseline case.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Cost-Accuracy Tradeoff
\end_layout

\begin_layout Standard
While the introspection-based regularization term improves the reliability of predictions in a model-based control setting,
 such conservatism is expected to impact global task solving performance.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Boxplot-Cum-Cost-with-Baseline"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 show boxplots of the cumulative task cost over trajectories for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
 As 
\begin_inset Formula $\lambda$
\end_inset

 increases,
 the mean cumulative cost slightly increases compared to the unregularized baseline (
\begin_inset Formula $\lambda=0$
\end_inset

).
 This indicates that the controller increasingly sacrifices task optimality in order to remain within regions of the state space that are well supported by the learned kCELL model.
 In addition to that,
 the spread of the cost distributions decreases with stronger regularization.
 This suggests that conservative behavior leads to more uniform,
 less optimal,
 performances across initial conditions.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Mean-Cum-Cost-vs-Horizon-Steps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolution of the mean cumulative cost over the horizon steps for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
 Higher regularization coefficiens 
\begin_inset Formula $\lambda$
\end_inset

 resulted in higher accumulated costs compared to the baseline.
 This effect is more pronounced for longer horizons.
 It indicates that conservative trajectory selection restricts the optimizer's ability to exploit agressive control strategies that rely extensively on extrapolation in predictions.
\end_layout

\begin_layout Standard
To explicitely relate predictive performance to task performance,
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pareto-Error-vs-Cost"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a scatter plot of mean absolute prediction error over cumulative cost for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
 By interpolating a cubic polynomial on those points,
 a nonlinear relationship can be observed between the prediction error and cumulative costs.
 Indeed,
 trajectories associated with lower prediction errors tend to incur higher costs.
 The interpolated curve exhibits a steep initial decrease in cost as prediction error increases,
 followed by a more gradual regime.
\end_layout

\begin_layout Standard
Overall,
 for this specific control task,
 these results reveal an explicit reliability-performance tradeoff induced by the introspection-based regularization term we introduced.
 Stronger regularization improves prediction accuracy and reduces error accumulation at the expense of control optimality.
 The shape of the tradeoff shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pareto-Error-vs-Cost"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 suggests that it is possible to find intermediate values of the regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

 that yields substantial gains in predictive accuracy for a limited increase in cost.
 Further works on different control tasks should be carried on to find a practical tuning mechanism for the conservative coefficient.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/boxplot_cost.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Boxplot-Cum-Cost-with-Baseline"

\end_inset

Boxplots of the cumulative costs over optimized trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the cumulated cost over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to values of 
\begin_inset Formula $\lambda$
\end_inset

.
 The blue curve corresponds to the global mean and the orange bars correspond to the median value.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/cost_diff_per_horizon_step.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Mean-Cum-Cost-vs-Horizon-Steps"

\end_inset

Evolution of the cumulative cost over the prediction horizon for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the cumulative cost over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to the horizon steps.
 Each colored curve corresponds to a given value of 
\begin_inset Formula $\lambda$
\end_inset

.
 The 
\begin_inset Formula $\lambda=0$
\end_inset

 curve corresponds to the unregularized baseline case.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/pareto_cost_vs_error.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Pareto-Error-vs-Cost"

\end_inset

Visualization of cumulative cost against mean absolute error.
 
\emph on
y
\emph default
-axis corresponds to the cumulative costs and 
\emph on
x
\emph default
-axis corresponds to the mean absolute errors over trajectories.
 Each colored point is associated to a value of 
\begin_inset Formula $\lambda$
\end_inset

.
 The greyed out line corresponds to a cubic interpolation.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Discussion
\end_layout

\begin_layout Standard
This experiment shows that the spatial organization of agents in kCELL can be directly exploited during trajectory optimization to improve the reliability of model-based control with a learned kCELL model.
 A distance-based regularization term derived from agent coverage is embedded into the MPC objective and it effectively bias the optimizer toward regions of the state space where the learned dynamics are supported by training data.
\end_layout

\begin_layout Standard
The results show that this regularization method leads to trajectories that remain closer to agent centers,
 reduced prediction errors and attenuated error compounding over horizon steps.
 These effects are observed without modifying the learned kCELL model.
 The improvement arises solely from how the model is exploited by the optimizer,
 rather than from improved accuracy that would be obtained by continuous learning.
 The proposed regularization mechanism does not attempt to make the model more accurate.
 Instead,
 it exploits epistemic awareness to make the better off of it.
\end_layout

\begin_layout Standard
Moreover,
 these results provide empirical support for the local expertise hypothesis that represents the core of kCELL.
 A correlation between activation of agents and reduced prediction error can be observed.
 It validates the assumption that local linear models are more and more reliable the closest the features are to their center.
 The regularization mechanism transforms this hypothesis into a control-relevant advanatage.
\end_layout

\begin_layout Standard
By increasing the regularization coefficient,
 the reduction in the growth rate of prediction error across the horizon steps improves largely the longer the horizon.
 In this case,
 it seems that the main effect of this introspection-based regularization approach lies in mitigatin erorr compounding effects.
 The regularization term prevents the optimizer from relying too much on aggressive extrapolated trajectories.
 This way,
 the controller looks to avoid MPC instabilities that arise from inaccurate predictions and misguided optimization.
 The pendulum environment is forgiving,
 because due to inertia,
 an unregularized MPC controller can recover from mistakes.
 However,
 in more complex control environments with less smooth dynamics this might not be the case and a regularization strategy could prove useful.
\end_layout

\begin_layout Standard
At the same time,
 theresults show a tradeoff between predictive accuracy and task performance in term of cumulated costs.
 Increasing conservatism leads to higher cumulative costs and lower predictive error.
 This behavior is expected and results directly from enforcing knowledge-aware regularization to the controller.
 The regularization acts as a soft feasibility constraint on the validity of the model,
 considering that unknown regions are somewhat unfeasible or dangerous.
 This is similar to trust-region methods in nonlinear optimization 
\begin_inset CommandInset citation
LatexCommand cite
key "conn2000trust,schulman2015trust"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pareto-Error-vs-Cost"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 showed that this tradeoff seems nonlinear.
 Reductions in prediction error can be obtained for relatively small increases in cost,
 suggesting that intermediate regularization strengths may offer a practical compromise between safety and performance.
 This observation is relevant for real-world applications where safety is required.
 In these cases,
 slight suboptimality is acceptable in exchange for improve reliability and reduced risk of catastrophic failure.
\end_layout

\begin_layout Standard
Overall,
 this study shows that kCELL's interpretability properties can be embedded into optimization pipelines.
 The proposed regularization mechanism consistures a principle way to translate structural transparency into conservative control behavior.
 This approach is a little step further towards reliable (i.e safe) model-based control based on learned dynamics models.
\end_layout

\begin_layout Subsubsection
Limitations
\end_layout

\begin_layout Standard
The comparative study that we conducted as well as the proposed introspection-based regularization mechanism exhibit some limitations that should be acknowledged.
\end_layout

\begin_layout Standard
In the presented experiments,
 proximity to agent centers correlates well with prediction accuracy.
 However,
 the distance-based competence measure used in this study is only a proxy for epistemic uncertainty.
 It is not a calibrated uncertainty estimate.
 As such,
 this regularization approach should be interpreted as a heuristic for risk reduction rather than a formal safety guarantee.
 Its effectiveness deeply depends on the structure and distribution of agents.
 No guarantees can be provided at the moment if the agent coverage is insufficient or poorly aligned with the true dynamics of the system.
\end_layout

\begin_layout Standard
The experiment has been conducted on a low-dimensional dynamical system (the pendulum) with smooth dynamics.
 As pointed out in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Discussions-and-Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 in low dimensional case,
 Mahalanobis distances (that are used for regularization) are not too distorted and remain meaningful.
 In higher dimensional cases the agent coverage might become more sparse.
 The impact of dimensionality on the effectiveness of the proposed regularization has not been studied in this chapter and remains an important limitation.
 This regularization approach might require additional mechanisms to remain effective.
\end_layout

\begin_layout Standard
We made the choice of spatializing agents only in the state space for convenience reasons to stabilize faster the agent population at learning time.
 This choice limits expressiveness of agents regarding actions.
 While this design choice is appropriate for the pendulum control task,
 it may not generalize to other dynamical systems.
 In such cases,
 regularization in joint state-action space could be required.
\end_layout

\begin_layout Standard
Another limitation relates to the density and sparsity of agent population.
 The conducted experiment rely on a single learned kCELL model trained with a fixed exploration budget.
 The effect of the sparsity of agent population on the conservative regularization behavior has not beed studied.
 Training multiple models with varying agent densities would be necessary to better characterize how coverage quality impacts the reliability gains.
\end_layout

\begin_layout Standard
In this work we show that it might be possible to find a value for the regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

 that could represent a satisfying tradeoff between performance loss and increased predictive accuracy.
 However,
 we do not provide a principled way to tune the 
\begin_inset Formula $\lambda$
\end_inset

 regularization coefficient.
 It must be done manually depending on the task nature and on the scale of task cost.
 Further investigations across different control environments are needed to extract practical insights and rules to chose the value of 
\begin_inset Formula $\lambda$
\end_inset

 depending on the problem characteristics as well as performance and predictive accuracy requirements.
\end_layout

\begin_layout Standard
Finally,
 the proposed approach improves the reliability of the controller but does not ensure safety.
 The regularization reduces the likelihood of failure due to prediction errors by discouraging extrapolation but it does not prevent it entirely.
\end_layout

\begin_layout Section
Towards Safe Explainable Control under Hard Constraints 
\begin_inset CommandInset label
LatexCommand label
name "sec:Explainable-Control-(LQR)"

\end_inset


\end_layout

\begin_layout Chapter
Scalable Non-Linear CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Scalable-Non-Linear-CELL"

\end_inset


\end_layout

\begin_layout Standard
In chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we presented an ensemble learning algorithm to solve continuous supervised learning tasks.
 Then,
 in chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we demonstrated how to use our approach to continuously model the dynamics of a system in order to solve a constrained control task.
 Through our experiments,
 we have noticed that,
 when the state and action dimensions increased,
 the concept of neighborhood as we have defined it loses its consistency and informativeness due to the dilation of distances in the feature space 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
A justifier avec une petite xp  la fin du chapitre 3
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
Indeed,
 when the number of features increases,
 it is much rarer for an agent to be considered a neighbor of a new point.
 Therefore,
 the amoung of data required for training is much greater and  the number of agents created grows rapidly.
 Thus,
 we identify a need to limit the growth in the number of agents to increase sample efficiency and limit redundancy in the knowledge base.
 Until now,
 to mitigate this problem,
 we needed to rely on hard-to-tune hyperparameters to define the initial size of agents on each feature 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3 ou papier PRIMA
\end_layout

\end_inset

 or on locality hypothesis on consecutive points among a given trajectory to identify relevant closest agents 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3
\end_layout

\end_inset

.
 In this chapter,
 we present SGP-CELL a novel approach based on Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "williams1995gaussian"
literal "false"

\end_inset

 effectively tailored for scalable online learning.
 Our contributions are threefold:
\end_layout

\begin_layout Itemize
we propose a new spatialization approach for context agents based on Principal Component Analysis (PCA) 
\begin_inset CommandInset citation
LatexCommand cite
key "jolliffe2011principal"
literal "false"

\end_inset

 to robustify neighborhoods in larger feature spaces.
\end_layout

\begin_layout Itemize
we introduce a new learning process for individual agents based on model selection and greedy objective minimization.
\end_layout

\begin_layout Itemize
we demonstrate the performances and sample efficiency of SGP-CELL compared to a Sparse Gaussian Process baseline on a forward dynamics modeling task.
\end_layout

\begin_layout Section
Related Works
\end_layout

\begin_layout Standard
Gaussian Processes (GP) are non-parametric Bayesian approaches to solve regression tasks while modeling uncertainty in predictions.
 GPs have been successful in robotics to model inverse or forward dynamics of a system to solve safe non linear control problems 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
+ de REF ?
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "berkenkamp2015safe"
literal "false"

\end_inset

.
 However,
 GP have a high computational cost with a learning complexity of 
\begin_inset Formula $O\left(kN^{3}\right)$
\end_inset

 with 
\begin_inset Formula $N$
\end_inset

 the number of training points and 
\begin_inset Formula $k$
\end_inset

 the number of optimization steps to find optimal kernel parameters,
 which results from the inversion of the covariance matrix 
\begin_inset Formula $K$
\end_inset

.
 This makes GPs no able to handle large datasets.
\end_layout

\begin_layout Standard
Approximation methods like Sparse Gaussian Processes (SGP) alleviate this scaling issue.
 Instead of using the whole training dataset to build the model,
 a set of 
\begin_inset Formula $M$
\end_inset

 inducing points (with 
\begin_inset Formula $N\gg M$
\end_inset

) are selected to represent the whole dataset.
 The inducing points allow for a cheaper low-rank representation for approximating the posterior distribution lowering the complexity to 
\begin_inset Formula $O\left(NM^{2}\right)$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "snelson2005sparse,naish2007generalized"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Other works have extended SGP with Variational Inference to further enhance scalability with stochastic minibatch optimization to handle large datasets,
 improve generalization and reduce overfitting 
\begin_inset CommandInset citation
LatexCommand cite
key "titsias2009variational,bauer2016understanding"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
For
\end_layout

\begin_layout Subsection
Gaussian Process Regression
\end_layout

\begin_layout Subsection
Online Gaussian Processes
\end_layout

\begin_layout Section
SGP-CELL
\end_layout

\begin_layout Subsection
Scaling Neighborhoods
\end_layout

\begin_layout Subsection
Non-Linear Local Modeling
\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Section
Practical Design Guidelines
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add formalism for the whole CELL family
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Based on our experience designing our multiagent systems based on context agents for supervised learning,
 we present in this section comprehensive overview of common obstacles that must be overcome for such a system to work properly,
 allowing the emergence of learning.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
feedback (
\begin_inset Formula $\Delta$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
kCELL features
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion and limitations
\end_layout

\begin_layout Chapter
Speed Recommendation:
 Industrial Use Cases
\end_layout

\begin_layout Standard
The enforcement of the EU General Safety Regulation has accelerated the adoption of Intelligent Speed Assistance (ISA) systems in new vehicles,
 emphasizing the need for reliable embedded speed recommendations.
 Unlike classical speed control approaches that are centered on vehicle dynamics modeling,
 speed recommendation requires reasoning that considers the driver in the loop,
 introducing behavioral variability and acceptance constraints.
 Designing deployable systems further demands attention to safety compliance,
 homologation requirements,
 robustness under sensor failure and potential impacts on energy consumption.
 In this chapter,
 we discuss these challenges and outline design principles for building speed recommendation systems suitable for real-world deployment and propose search directions to advance the field toward operational intelligent speed recommendation solutions.
\end_layout

\begin_layout Chapter
Conclusion and Future Works
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "manuscript"
options "plain"
encoding "default"

\end_inset


\end_layout

\end_body
\end_document
