#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\use_default_options true
\begin_modules
theorems-ams
\end_modules
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement class
\float_alignment class
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008080
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Chapter
Related Works
\end_layout

\begin_layout Standard
This chapter provides a comprehensive review of the literature on speed recommendation systems.
 We decompose the problem into two sub-problems:
 a 
\emph on
modeling problem
\emph default
,
 which involves continuously estimating vehicle dynamics under driver-specific influence to enable personalized and realistic speed recommendations;
 and a 
\emph on
control problem
\emph default
,
 which leverages the learned model to optimize speed profiles with respect to predefined objectives and operational constraints.
 To establish a rigorous foundation and position our approach within the field,
 we examine state-of-the-art methods across three relevant domains:
 speed control and recommendation,
 online machine learning,
 and optimal control.
\end_layout

\begin_layout Section
Speed Recommendation and Speed Control
\end_layout

\begin_layout Section
Online Machine Learning
\end_layout

\begin_layout Section
Optimal Control
\end_layout

\begin_layout Section
Positioning
\end_layout

\begin_layout Chapter
Context Ensemble Local Learning (CELL)
\begin_inset CommandInset label
LatexCommand label
name "chap:Context-Ensemble-Local"

\end_inset


\end_layout

\begin_layout Standard
To achieve speed recommendation we need to model the behavior of a vehicle driven by a human driver in response to speed recommendation set points.
 Thus,
 we need a modeling algorithm able to perform online learning and learn efficiently seeing a data point once while having transparent and explainable inner workings.
 For that reason we explored the use of multiagent systems as a mean of solving supervised learning tasks.
 
\end_layout

\begin_layout Standard
As showed in 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 a supervised learning problem can be modeled as a multiagent system.
 This perspective offers several advantages,
 including design simplicity,
 transparency,
 and explainability properties that naturally emerge from the spatial organization of agents.
\end_layout

\begin_layout Standard
In this chapter we introduce CELL (Context Ensemble Local Learning),
 a family of multiagent systems designed for online learning dynamics of a complex environment.
 Our approach addresses online supervised learning through simple self-organization of multiple local expert agents paving the feature space.
 These agents are created and updated dynamically according to predefined learning rules.
 Each agent occupies a specific region in feature space,
 representing the area where it is most confident in the quality of its predictions.
 Contrary to previous works on this type of system 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 we introduce novelties regarding the explainability while exploring new cooperation mechanisms between agents and new spatialization approaches.
\end_layout

\begin_layout Standard
By leveraging the spatialization of local experts and the inherent transparency of the model,
 we derive unique informative explainability properties that provide valuable insights about the approximated function.
 Furthermore,
 we outline practical guidelines for scaling with the number of agents,
 keeping a bounded computational complexity.
\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Subsection
Multi-Agent Learning
\end_layout

\begin_layout Standard
Multi-agent systems (MAS) have gained popularity due to their ability to solve complex problems by breaking them down into simpler sub-problems that can be easily addressed by autonomous agents,
 whether interconnected or not 
\begin_inset CommandInset citation
LatexCommand cite
key "dorri2018multi"
literal "false"

\end_inset

.
 The interaction rules between agents or with the environment are defined by the system designer to achieve a specific objective.
 The use of MAS has proven effective in fields such as civil engineering 
\begin_inset CommandInset citation
LatexCommand cite
key "SHAMSHIRBAND20132105"
literal "false"

\end_inset

 or electrical engineering,
 particularly with issues related to smart grids 
\begin_inset CommandInset citation
LatexCommand cite
key "rohbogner2014design"
literal "false"

\end_inset

.
 In more recent years,
 reinforcement learning has been seriously considered to bypass the phase of designing rules that define agent behavior.
 Indeed,
 in Multi-Agent Reinforcement Learning (MARL),
 agents' behaviors are learned using reinforcement signals obtained by continuously interacting with an environment 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In this chapter,
 we present various iterations of CELL,
 a MAS that combines both approaches to tackle online supervised learning problems.
 Agents of the system update using both reinforcement learning signals and cooperation rules.
 Unlike MARL,
 our approach requires fewer environment interactions and focuses on specialized agents collaborating within a supervised learning framework,
 differing from MARL's dynamic interactions aiming to maximize cumulative rewards through adaptive strategies (
\emph on
competitive
\emph default
 or 
\emph on
cooperative
\emph default
) 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Ensemble Learning
\end_layout

\begin_layout Standard
To achieve more accurate predictions and provide better approximations of nonlinear functions,
 it is common to aggregate multiple models for making predictions.
\end_layout

\begin_layout Standard
Ensemble learning is based on the emergence of collective intelligence within a set of weak learners.
 A weak learner is a model whose performance is at least as good as a model making random predictions.
 During the learning process,
 a set of models (which may differ from one another) are trained in parallel or sequentially 
\begin_inset CommandInset citation
LatexCommand cite
key "polikarEnsembleLearning2012"
literal "false"

\end_inset

.
 The objective is to encourage diversity among the models so that they do not all capture the same patterns in the data 
\begin_inset CommandInset citation
LatexCommand cite
key "dietterichEnsembleMethodsMachine2000"
literal "false"

\end_inset

.
 An input is transmitted to all weak learners,
 each of which makes a prediction proposal.
 A heuristic is implemented to select one of the proposals or to weight each of them in order to construct the final prediction.
 We distinguish several major approaches in ensemble learning which are Boosting,
 Bagging and Stacking.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add figure to compare bagging,
 boosting and stacking
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visual comparison of bagging,
 boosting and stacking
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Bagging we train multiple models (usually homogeneous) in parallel on different subsets of the training data to introduce diversity,
 reduce variance and improve stability.
 Then the final prediction is obtained by averaging the predictions of the weak learners (regression) or by majority voting (classification).
 Unlike Bagging,
 in Boosting,
 we train the models sequentially.
 Each new model focuses on correcting the errors of the previous ones to reduce bias and improve accuracy.
 Then we obtain the final prediction from a weighted average of the predictions of the all the weak learners.
 Finally,
 we have Stacking that falls under meta-learning.
 We train in parallel a set of heterogeneous models and then we train a meta-model whose role will be to combine the predictions of each model to obtain the final output of the system,
 in order to capture complementary strengths of each learning algorithms involved in the learning process.
\end_layout

\begin_layout Standard
The family of systems we present in this chapter,
 CELL,
 falls within the ensemble learning framework and we could label it as a Bagging approach because we consider a set of weak learners as a collection of self-organizing cooperative agents.
 Each one of them is a local expert on the function to be approximated.
\end_layout

\begin_layout Section
oCELL:
 Multiagent Ensemble Learning with Orthotopes
\end_layout

\begin_layout Standard
In this section we describe the first variant of CELL that we name oCELL (orthotope CELL).
 We explore context agent based systems composed of multiple autonomous agents with their own capabilities and only local knowledge of the environment.
 Our system is based on the Self-Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to address an online supervised learning problem.
 We want to learn a function 
\begin_inset Formula $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$
\end_inset

 to map feature to target vectors from a stream of data.
 
\end_layout

\begin_layout Standard
oCELL processes a stream of data.
 Incoming points are routed to the system's primary components,
 which we call Context agents.
 These agents are created and updated dynamically according to predefined learning rules.
 Each Context agent occupies a specific region in feature space,
 representing the area where is is most confident in its predictions.
 This spatialization allows the agent to determine 
\emph on
when
\emph default
 it should make a prediction.
 To determine 
\emph on
what
\emph default
 to predict,
 each agent maintains a local machine learning model over the confidence region.
 
\end_layout

\begin_layout Standard
First,
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Context-Agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 we will introduce the inner workings of the agents in oCELL,
 describing how they are spatialized in feature space and how they predict.
 Then,
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Learning-Rules"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 we describe rules allowing self-organization and emergence of learning in the system.
 Next,
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Comparative-Study"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 we provide a comparative study to evaluate the performances of oCELL against other machine learning algorithms on a 2D toy experiment.
 Afterwards,
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 we study the introspection capabilities of oCELL,
 that is to say the explainability properties that emerges from the spatial organization of agents.
 Finally,
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 we outline the limitations of oCELL and suggest hints for research and improvements to be done in future works (some of which are tackled in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert description of subsequent section content
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Context Agents
\begin_inset CommandInset label
LatexCommand label
name "subsec:Context-Agents"

\end_inset


\end_layout

\begin_layout Standard
The main entities of oCELL are the Context agents.
 A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is characterized by an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

 such as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i}\left(x\right),f_{i}\left(x\right)\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
Each agent can refine the parameters of its internal activation and prediction function to adapt to its local surroundings depending on reinforcement signals it receives.
 To summarize,
 a Context agent can be considered as a local expert of the function to be approximated with its activation function telling it 
\emph on
when
\emph default
 it should predict and with its prediction function telling it 
\emph on
what
\emph default
 to predict.
 
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert description of subsequent section content
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Spatialization with Orthotopes
\end_layout

\begin_layout Standard
As we need a transparent and interpretable system,
 we chose to spatialize our Context agents using orthotopes.
 the use of orthotopes allows us to precisely evaluate how agents have organized themselves feature-wise while also allowing for simpler shape change mechanisms required for self-organisation of Context agents because we can act on each dimension individually.
\end_layout

\begin_layout Standard
Learning with orthotopes (often referred to as hyper-rectangles in literature) is an approach already explored in literature for supervised learning 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022,konstantinov2023interpretable"
literal "false"

\end_inset

.
 Usually,
 these approaches aim to partition the feature space into orthotopes to then model locally the function to approximate.
 For example,
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "konstantinov2023interpretable"
literal "false"

\end_inset

,
 the authors leverage a gradient boosting approach to learn the bounds of the orthotopes with each corresponding to a very simple base model (constant value),
 not suitable for online learning from a stream of data.
\end_layout

\begin_layout Standard
In terms of spatialization of agents,
 oCELL borrows a similar approach to 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 in which authors use SACL learning paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to solve a classification task from a stream of data by progressively paving the feature space with context agents.
 However,
 unlike 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 we address issues specifically related to regression problems such as a need for a smoother spatialization of agents.
\end_layout

\begin_layout Standard
In oCELL,
 each agent activation function's parameters correspond to a 
\begin_inset Formula $p$
\end_inset

-dimensional orthotope in the feature space.
 This orthotope si defined for each feature dimension 
\begin_inset Formula $j\in\left\{ 1,\dots,n\right\} $
\end_inset

 by a lower bound 
\begin_inset Formula $l_{j}$
\end_inset

 and an upper bound 
\begin_inset Formula $h_{j}$
\end_inset

 such as
\begin_inset Formula 
\[
\mathcal{H}_{i}=\left[l_{1},h_{1}\right]\times\dots\times\left[l_{n},h_{n}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
The volume 
\begin_inset Formula $v\left(\mathcal{A}_{i}\right)$
\end_inset

 of the orthotope associated to 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined by
\begin_inset Formula 
\[
v\left(\mathcal{A}_{i}\right)=\prod_{j=1}^{n}\left(h_{j}-l_{j}\right)
\]

\end_inset

Furthermore,
 an observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is considered as intersecting an orthotope if,
 for all feature 
\begin_inset Formula $j$
\end_inset

 we have 
\begin_inset Formula 
\[
l_{j}\leq x_{j}\leq h_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
Additionaly,
 an orthotope 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 intersects another orthotope 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

 if,
 for all feature 
\begin_inset Formula $j$
\end_inset

 we have
\begin_inset Formula 
\[
\max\left(l_{1,j},l_{2,j}\right)\leq\min\left(h_{1,j},h_{2,j}\right)
\]

\end_inset

with 
\begin_inset Formula $l_{1,j}$
\end_inset

,
\begin_inset Formula $l_{2,j}$
\end_inset

 and 
\begin_inset Formula $h_{1,j}$
\end_inset

,
\begin_inset Formula $h_{2,j}$
\end_inset

 respectively the lower and upper bounds of 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Agents in oCELL are constructed based on the assumption of uniformity of knowledge over their area of expertise,
 that is to say on the area delimited by the orthotope associated with them.
 We distinguish between activation and neighborhood.
 When an agent is activated by a point,
 it means it is confident in its expertise to predict for that point.
 When an agent is a neighbor of a point,
 it means it has doubts about its expertise to predict for that point.
 In other words,
 it's an agent that is a candidate to become an activated agent for that point.
 The way an agent updates itself differs depending on whether the agent is activated or a neighbor.
\end_layout

\begin_layout Definition
A Context Agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is considered activated by an observation 
\begin_inset Formula $x$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 intersects with the orthotope 
\begin_inset Formula $\mathcal{H}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{\mathcal{H}}:\mathbb{R}^{n}\mapsto\left\{ 0,1\right\} $
\end_inset

 of 
\begin_inset Formula $\mathcal{A}$
\end_inset

.
 In other words,
 we define the activation function of 
\begin_inset Formula $\mathcal{A}$
\end_inset

 as
\begin_inset Formula 
\[
\phi_{\mathcal{H}}\left(x\right)=\begin{cases}
1 & \text{if}\,\,\forall j,\,\,l_{j}\leq x_{j}\leq h_{j}\\
0 & \text{else}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
We define the neighborhood of an observation 
\begin_inset Formula $x$
\end_inset

 as an orthotope 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset

 centered on 
\begin_inset Formula $x$
\end_inset

.
 A 
\emph on
Context
\emph default
 Agent is considered a neighbor of 
\begin_inset Formula $x$
\end_inset

 if the orthotope 
\begin_inset Formula $\mathcal{H}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{\mathcal{H}}$
\end_inset

 of 
\begin_inset Formula $\mathcal{A}$
\end_inset

,
 intersects with 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset


\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add ref to equation of intersection between two orthotopes
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
For agents to self-organize,
 they need to be able to change form and move across feature space.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 authors defined spatialization rules such that overlap between agents would be minimized to avoid ambiguity in decision making to predict the class of a sample (for example agents could push each other).
 For a regression task,
 it can be more informative to average the predictions of several weak models to smooth the learned function.
 This property is all the more interesting because it would make our model easier to use in a non linear optimization process (cf section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Hard-Constraints"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 To smooth the learned function,
 we allow intersections between agents.
 An agent can therefore change its shape by contracting or expanding without worrying about where other agents are.
\end_layout

\begin_layout Definition
If a 
\emph on
Context
\emph default
 agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 expands (resp.
 contracts) by a factor 
\begin_inset Formula $\alpha$
\end_inset

 in the direction of an observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

,
 then the upper bounds 
\begin_inset Formula $h_{j}^{t}$
\end_inset

 and lower bounds 
\begin_inset Formula $l_{j}^{t}$
\end_inset

 of the associated orthotope are updated according to the following relationship:
\begin_inset Formula 
\begin{align}
h_{j}^{t+1} & =\begin{cases}
\left(h_{j}^{t}-l_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+l_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
h_{j}^{t} & \text{else}
\end{cases}\\
l_{j}^{t+1} & =\begin{cases}
\left(l_{j}^{t}-h_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+h_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
l_{j}^{t} & \text{else}
\end{cases}
\end{align}

\end_inset

with
\begin_inset Formula 
\[
\varepsilon=\begin{cases}
\left(1+\alpha\right) & \text{if expansion}\\
\left(1-\alpha\right) & \text{if retraction}
\end{cases}
\]

\end_inset

and 
\begin_inset Formula $k$
\end_inset

 the number of features such that 
\begin_inset Formula $l_{j}^{t}\leq x_{j}\leq h_{j}^{t}$
\end_inset

.
 Thus,
 the new volume of the orthotope associated with 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is given by the relation:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align}
v_{\mathcal{A}}^{t+1} & =\varepsilon v_{\mathcal{A}}^{t}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
To summarize,
 our agents are spatialized through their activation functions with orthotopes that define their 
\emph on
area of expertise
\emph default
 in feature space.
 Finally,
 each agent can update the parameters of its activation function,
 effectively expanding or retracting its associated orthotope.
 Intuitively,
 big agents could be considered as 
\emph on
generalists
\emph default
 and smaller agents could be considered as 
\emph on
specialists
\emph default
.
 Therefore,
 in a region of feature space that is more complex to model,
 we would expect to find many small agents,
 and conversely,
 in a region of space that is simpler to model.
 We note that this assumption is based on the use of a simple class of models for agents such as linear regression.
 In our subsequent examples and experiments,
 we will primarily use linear regressions as internal models for the agents.
 Indeed,
 these models are simple,
 explainable,
 and transparent in their inner workings.
\end_layout

\begin_layout Subsubsection
Neighborhood Prediction
\begin_inset CommandInset label
LatexCommand label
name "subsubsec:Neighborhood-Prediction"

\end_inset


\end_layout

\begin_layout Standard
Our goal is to solve a regression problem from a data stream.
 Specifically,
 we want to model the nonlinear dynamics of a complex system so that we can use the resulting model in an optimization pipeline for optimal control (cf chapter 
\begin_inset CommandInset ref
LatexCommand eqref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Usually,
 when performing control with a learned model,
 we want to have minimal noise in the gradients and a smooth learned function to avoid significantly disrupting the optimization process.
 Therefore,
 we choose to allow the system to involve mutliple agents in the final decision,
 unlike in previous works 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,dato2021apprentissage,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

 where only one agent was ultimately selected to make the prediction.
\end_layout

\begin_layout Standard
To obtain the prediction 
\begin_inset Formula $\hat{y}$
\end_inset

 from an observation 
\begin_inset Formula $x$
\end_inset

,
 we first need to select the agents that will make proposals on the value of 
\begin_inset Formula $\hat{y}$
\end_inset

.
 If some agents are neighbors of 
\begin_inset Formula $x$
\end_inset

,
 then they make proposals,
 instead,
 if 
\begin_inset Formula $x$
\end_inset

 has no neighbor,
 we select the 
\begin_inset Formula $k$
\end_inset

-closest agents instead.
 We proceed this way to avoid situations in which our model is not able to predict at all due to poor knowledge in the area around 
\begin_inset Formula $x$
\end_inset

.
 The final prediction is then given by the arithmetic mean of the proposals of selected agents such as
\begin_inset Formula 
\[
\hat{y}=\frac{1}{\left|D_{\text{selected}}\right|}\times\sum_{i\in D_{\text{selected}}}f_{i}\left(x\right)
\]

\end_inset

with 
\begin_inset Formula $D_{\text{selected}}$
\end_inset

the set of selected agents (neighbors or closest) and 
\begin_inset Formula $f_{i}\in\mathbb{R}^{m}$
\end_inset

 the internal function of the 
\begin_inset Formula $i$
\end_inset

-th agent.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert diagram to explain prediction
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of the prediction process with Context Agents
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Learning Rules
\begin_inset CommandInset label
LatexCommand label
name "subsec:Learning-Rules"

\end_inset


\end_layout

\begin_layout Standard
In CELL systems,
 we design the learning rules around a set of actions and conditions that trigger those actions to digest 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 that are fed to the system as a data stream.
 In context agent learning systems,
 the set of actions consists of actions that can be performed individually by agents such as updating their model or shape;
 and more meta-level actions such as destroying or creating new agents.
 In oCELL these actions are triggered by conditions that depend on the number of current neighbors or activated agents and a feedback value calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
To determine what an agent should do,
 we define the quality of the proposal 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

 
\begin_inset Formula $g:\mathbb{R}^{m}\times\mathbb{R}^{m}\mapsto\mathbb{R}$
\end_inset

 of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as
\begin_inset Formula 
\[
L_{\mathcal{A}_{i}}=g\left(\hat{y},y\right)
\]

\end_inset

 where 
\begin_inset Formula $g:\mathbb{R}^{m}\times\mathbb{R}^{m}\mapsto\mathbb{R}$
\end_inset

 is a distance measure between the proposal 
\begin_inset Formula $\hat{y}$
\end_inset

 and the true value 
\begin_inset Formula $y$
\end_inset

,
 that is to say the error.
 The largest 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

,
 the worse the quality of the proposal.
 For oCELL,
 we will use the squared error as the 
\begin_inset Formula $g$
\end_inset

 function but other types of error functions could be used instead.
 We define two thresholds 
\begin_inset Formula $\tau_{\text{good}}$
\end_inset

 and 
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset

 to define three regimes in the values of 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

:
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

 for 
\emph on
good
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

 for 
\emph on
inaccurate
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

 for 
\emph on
bad
\emph default
 predictions.
 This way,
 we can choose the desired degree of accuracy that we want oCELL to reach after training.
\end_layout

\begin_layout Paragraph
Inaccuracy
\end_layout

\begin_layout Standard
When we have 
\begin_inset Formula $N_{A}\geq1$
\end_inset

 activated agents for 
\begin_inset Formula $x_{new}$
\end_inset

,
 it means the area around 
\begin_inset Formula $x_{new}$
\end_inset

 is already known because it is covered by agents.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

,
 it means the prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 and it was right to declare itself as an expert on 
\begin_inset Formula $x_{new}$
\end_inset

.
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 will therefore seek to generalize in the direction of 
\begin_inset Formula $x_{new}$
\end_inset

 by extending its area of expertise.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 then the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
inaccurate
\emph default
 but it is still promising as a candidate to be activated,
 so it only refines its internal model and keeps its positions waiting for another signal to expand is needed.
 Then,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

,
 the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
bad,

\emph default
 meaning that it shouldn't have been activated.
 In reaction to that,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

will retract to get away from 
\begin_inset Formula $x_{new}$
\end_inset

.
 This rule represents the core of agents local self-organization.
 It allows the agents to move in feature space and refine their model as needed to exclude or include points to better model their close surroundings in feature space in response to feedbacks on the quality of their predictions.
\end_layout

\begin_layout Paragraph
Incompetence
\end_layout

\begin_layout Standard
When we have 
\begin_inset Formula $N_{A}=0$
\end_inset

 activated agents and 
\begin_inset Formula $N\geq1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of the closest agents are candidate on becoming activated on 
\begin_inset Formula $x_{new}$
\end_inset

.
 In this situation,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 i.e prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
,
 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 could be an expert on 
\begin_inset Formula $x_{new}$
\end_inset

 so it refines its model and expands towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 Otherwise,
 if no neighbor gives 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
 predictions,
 then we create a new agent centered on 
\begin_inset Formula $x_{new}$
\end_inset

.
 This rule allows oCELL to reuse the current knowledge and extend it as needed.
 It also aims to limit the creation of redundant agents.
\end_layout

\begin_layout Paragraph
Uselessness
\end_layout

\begin_layout Standard
In practice,
 we observe that it's necessary to have mechanisms for destroying agents within the system.
 Indeed,
 some agents may evolve to degenrate shapes if they receive too much negative feedbacks in a row.
 Theyr become far too small to be informative.
 These 
\emph on
dead
\emph default
 agents,
 that won't be activate ever again,
 are no longer useful in the system.
 Consequently,
 we detroy all agents whose volume falls below a certain threshold value 
\begin_inset Formula $\tau_{\text{vol}}$
\end_inset

.
\end_layout

\begin_layout Standard
Finally we present in Table 
\begin_inset CommandInset ref
LatexCommand eqref
reference "tab:Learning-rules-of-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 a summary of the learning rules that describe the behavior of agents in oCELL.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="4">
<features tabularvalignment="middle" tabularwidth="95col%">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model 
\begin_inset Newline newline
\end_inset

+ shape (expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\forall\mathcal{A}_{i},\,L_{\mathcal{A}_{i}}\notin\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(retract)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of oCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-oCELL"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert flowchart to explain learning
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Flowchart illustrating the learning process
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
So,
 oCELL relies on a set of hyperparameters that must be initialized before the training phase.
 These parameters have an influence on the convergence of the system.
 We have the prediction labeling thresholds 
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset

and 
\begin_inset Formula $\tau_{\text{good}}$
\end_inset

 that define the boundaries for classifying the predictions of agents.
 Those thresholds are crucial because they directly influence the rate at which each learning rule will fire.
 
\end_layout

\begin_layout Standard
Then we have the initial orthotope sizes that specify the feature-wise initial extent of the orthotope associated with a newly generated agent.
 This parameter is important in the sense that if an agent starts to small it will never reach other points and thus will be ignore or will add noise to its local surroundings at prediction.
\end_layout

\begin_layout Standard
Afterwards we have the volume variation coefficient 
\begin_inset Formula $\alpha$
\end_inset

 that dictates the rate at which an agent's shape is updated in terms of fraction of it's current volume.
\end_layout

\begin_layout Standard
Finally we have the agent pruning volume threshold which is used for the detection and destruction of agents deemed inactive or irrelevant based on their current orthotope volume.
\end_layout

\begin_layout Subsection
Comparative Study
\begin_inset CommandInset label
LatexCommand label
name "subsec:Comparative-Study"

\end_inset


\end_layout

\begin_layout Subsubsection
Data Generation
\end_layout

\begin_layout Subsubsection
Experiment
\end_layout

\begin_layout Subsection
Explainability
\begin_inset CommandInset label
LatexCommand label
name "subsec:Explainability-oCELL"

\end_inset


\end_layout

\begin_layout Subsection
Limitations
\begin_inset CommandInset label
LatexCommand label
name "subsec:Limitations"

\end_inset


\end_layout

\begin_layout Standard
We demonstrated the potential of oCELL to solve supervised learning problems.
 However,
 this approach still needs refinement and has limitations that we will address in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
One of the limitations of this approach lies in the neighborhood prediction system described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 Indeed we assumed in designing our system that an agent's level of knowledge about the function to be approximated is uniform across its area of expertise (i.e the orthotope associated to its activation function).
 Intuitively it might be more accurate to consider that an agent has a better expertise near its centroid,
 than on its edges.
 
\end_layout

\begin_layout Standard
Moreover,
 we also consider,
 when mutliple agents are involved in the prediction process that they have the same weight in the construction of the final prediction due to the arithmetic sum.
 Initially,
 we decided to proceed this way because of the knowledge uniformity assumption.
 However it would probably be more accurate to consider that when two agent make predictions,
 the one closest to the input point will has the smallest error due to the agent's spatial distribution.
 Thus,
 each agent involved in the prediction process should be weighted according to their level of expertise on the point
\end_layout

\begin_layout Standard
With oCELL,
 we attempted to calculate a weighted average of the agents' proposals to obtain the final prediction.
 The weights corresponded to the euclidean distance to centers of the agents involved.
 However,
 we found that this did not improve performances,
 likely because the euclidean distance to the centers do not account for the agent's shape.
 We therefore need to find a distance between an agent and the point that takes into account both the agent's centroid and its shape.
\end_layout

\begin_layout Standard
Another limitation lies in the spatialization of agents using orthotopes.
 Indeed,
 in some cases,
 the orthotopic representation may be limited and may not correspond to the reality of the points on which the agent learns.
 This can lead to covering entire areas that have never been seen,
 thus potentially generating false positives when we query the system about its knowledge of a point.
 We illustrate this in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Limitation orthotope agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 in which we compare side by side an overgeneralizing agent and a representative agent by visualizing their respective orthotopes (represented by a blue rectangle) and training data (represented by red dots).
 The overgeneralizing agent has its training data not covering the entirety of its associated orthotope unlike for the representative agent that seemingly has a training dataset that covers entirely it's associated orthotope.
 This example shows how crucial is the spatialization of agents and especially their base shape to best represent the local manifolds of features,
 avoid overgeneralization errors and avoid categorizing a point as known when it's not.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/sane_orthotope_agent.png
	lyxscale 40
	width 40col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Representative orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Representative-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/overgeneralized_orthotope_agent.png
	lyxscale 40
	width 40col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Overgeneralizing orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Overgeneralizing-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Side by side comparison of representative Context 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Representative-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 agent against a overgeneralizing Context agent 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Overgeneralizing-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 The blue rectangle corresponds to the orthotope associated to the activation function of the Context agent.
 Each red dot corresponds to a training point seen by the Context agent.
\begin_inset CommandInset label
LatexCommand label
name "fig:Limitation orthotope agents"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
oCELL has been designed for online machine learning.
 However,
 it does not exploit the relationships between successive points in a data stream.
 It considers each point to be independent,
 effectively limiting oCELL's convergence speed.
\end_layout

\begin_layout Standard
Finally,
 the last limitation we were able to identify is that some hyperparameters are difficult to tune.
 We are referring in particular to the initial size of the orthotopes associated with the new created agents,
 which requires setting a side length for each feature.
 In this regard,
 we can also refer to the error thresholds used to categorize a prediction as 
\emph on
good
\emph default
,
 
\emph on
bad
\emph default
 or 
\emph on
inaccurate
\emph default
.
\end_layout

\begin_layout Section
kCELL:
 Multiagent Ensemble Learning with Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "sec:kCELL"

\end_inset


\end_layout

\begin_layout Standard
We have extended Context agent learning to address regression tasks in the context of supervised learning.
 We showed that oCELL has competitive performances on a synthetic 2D benchmark dataset and exhibits interesting explainability properties.
 Indeed,
 we showed that we could extract measures of epistemic and aleatoric uncertainties in the predictions of the system as well as information about the variations of the underlying function from the shape and spatial organization of the 
\emph on
Context
\emph default
 agents in the feature space.
 These properties will be particularly useful when using this type of model in an optimization loop for safe optimal control.
\end_layout

\begin_layout Standard
However,
 oCELL has some limitations.
 Specifically,
 the spatialization of agents with orthotopes can sometimes produce erroneous representations of areas of expertise,
 leading to overestimations of their size and shape.
 In addition to that,
 the aggregation function used to compute predictions do not account for the shape and distance between the agents involved and the input.
 These limitations can sometimes lead to in-distribution interpolation problems and redundant agents.
 Furthermore,
 oCELL consider all points as independent and thus do not exploit the relationships between successive points,
 limiting its convergence speed in an online setting in which adaptativity is fairly important.
 Finally,
 some of oCELL's learning rules rely on hyperparameters that are difficult to tune (error thresholds and initial size of orthotope sides at agent creation).
\end_layout

\begin_layout Standard
To overcome these limitations,
 we introduce kCELL (kernel CELL),
 the second variant of CELL.
 In order to better represent the information we propose a spatialization approach based on RBF kernels inspired from what is done with RBF Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "lowe1988multivariable"
literal "false"

\end_inset

 or MoE (Mixture of Experts) 
\begin_inset CommandInset citation
LatexCommand cite
key "yukselTwentyYearsMixture2012"
literal "false"

\end_inset

 gating mechanisms.
 We also introduce a smoother aggregation function for inference to better represent the expertise of each agent involved in the prediction process taking inspiration from what is done for Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "seeger2004gaussian"
literal "false"

\end_inset

 in which the contribution of each point to the final prediction is weighted by a kernel value.
\end_layout

\begin_layout Subsection
Context Agents
\end_layout

\begin_layout Standard
As for oCELL 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Ref to definition of context agents in oCELL
\end_layout

\end_inset

,
 the main entities of kCELL are the Context agents.
 A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is characterized by an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

 such as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i}\left(x\right),f_{i}\left(x\right)\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
However,
 unlike in oCELL,
 the Context agents of kCELL are spatialized differently.
 In oCELL we use a binary activation (the point is inside or outside the associated orthotope) while in kCELL we use a RBF kernel as a continuous and smooth activation function to represent the area of expertise in feature space.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert description of subsequent section content
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kernel-Spatialization"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 contrary to using orthotopes we use a RBF kernel as the activation function to unlock more degrees of freedom to represent the areas of expertise 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add ref to illustration Figure
\end_layout

\end_inset

.
 This activation function is smooth and differentiable,
 making the system more optimization-friendly to be used for control tasks as a dynamics model.
 Therefore,
 an agent is spatialized by the mean 
\begin_inset Formula $\mu_{i}\in\mathbb{R}^{n}$
\end_inset

 and covariance matrix 
\begin_inset Formula $\Sigma_{i}\in\mathbb{R}^{n\times n}$
\end_inset

 of the distribution of its training points.
 Since this activation function has statistical significance,
 it is easier for us to define the neighborhood as a confidence interval whose confidence value we can adjust.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison between area of expertise oCELL vs kCELL
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Definition
The distance between a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 and a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined as the mahalanobis distance:
\begin_inset Formula 
\[
d\left(\mathcal{A}_{i},x\right)=D_{M}\left(\mu_{i},\Sigma_{i},x\right)=\sqrt{\left(x-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x-\mu_{i}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is considered as a neighbor of 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 is likely to belong to the training dataset of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 such as 
\begin_inset Formula 
\[
D_{M}\left(\mu_{i},\Sigma_{i},x\right)^{2}\leq\chi_{n,0.95}^{2}
\]

\end_inset

 where 
\begin_inset Formula $\chi_{n,0.95}^{2}$
\end_inset

 denotes the 
\begin_inset Formula $95$
\end_inset

th percentile of the chi-squared distribution with 
\begin_inset Formula $n$
\end_inset

 degrees of freedom.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The activation function 
\begin_inset Formula $\phi_{i}:\mathbb{R}^{n}\mapsto\left[0,1\right]$
\end_inset

 of a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 for a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is given by the RBF kernel value
\begin_inset Formula 
\[
\phi_{i}\left(\mathcal{A}_{i},x\right)=\exp\left(-\frac{d\left(\mathcal{A}_{i},x\right)}{2l^{2}}\right)
\]

\end_inset

with 
\begin_inset Formula $l$
\end_inset

 the lengthscale of the kernel.
\end_layout

\begin_layout Definition
The activation score of a point 
\begin_inset Formula $x$
\end_inset

 for a given agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 can be interpreted as the likelihood that the agent has previously been trained on points similar to 
\begin_inset Formula $x$
\end_inset

,
 and thus reflects the agent's degree of knowledge over the corresponding region of feature space.
 We can draw a parallel between this activation function based on RBF kernel and the coverage index 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert ref to coverage index in previous section
\end_layout

\end_inset

,
 an explainability metric that we derived from oCELL which is also linked to the degree of knowledge of a point.
 In kCELL,
 this explainability property related to the knowledge of a point emerges naturally from the definition of the system.
\end_layout

\begin_layout Definition
With kCELL we want to retain as few points as possible in memory to truly represent information through local models.
 As previously stated,
 the spatialization of each agent can be fully described by a mean 
\begin_inset Formula $\mu_{i}$
\end_inset

 and a covariance matrix 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 which are the parameters of the activation function 
\begin_inset Formula $\phi_{i}$
\end_inset

.
 Each time a point is ingested by agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

,
 we update its mean and covariance matrix using the Welford's algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "welford1962note"
literal "false"

\end_inset

 such as 
\begin_inset Formula 
\begin{eqnarray*}
\mu_{i\,|\,t+1} & = & \mu_{i\,|\,t}+\frac{x-\mu_{i\,|\,t}}{n+1}\\
\Sigma_{i\,|\,t+1} & = & \frac{1}{n}\left(\Sigma_{i\,|\,t+1}+\left(x-\mu_{i\,|\,t}\right)\left(x-\mu_{i\,|\,t+1}\right)^{\top}\right)
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $n$
\end_inset

 is the number of points ingested by the agent to update its shape.
 With this approach we express the shape change purely as a mean and covariance estimation problem.
\end_layout

\begin_layout Subsubsection
Soft-Weighted Prediction
\begin_inset CommandInset label
LatexCommand label
name "subsubsec:Soft-Weighted-Prediction"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 we get rid of the knowledge uniformity hypothesis of agents to better represent the knowledge of the system.
 Therefore the activation function of a context agent materializes its area of expertise through a smooth RBF kernel.
 The further a point is from the agent's centroid,
 the lower its activation value.
 This is because we assume that expertise is maximized at the agent's center.
 Agents with higher activation values contribute more heavily to the final output because they are more expert than others at predicting.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $S_{k}=\left\{ i|\mathcal{A}_{i}\,\text{is in the \ensuremath{k}-closest to}\,x\right\} $
\end_inset

 denote the index set of the 
\begin_inset Formula $k$
\end_inset

 nearest agents in feature space.
 The final prediction 
\begin_inset Formula $f\left(x\right)\in\mathbb{R}^{m}$
\end_inset

 of the system is then given by
\begin_inset Formula 
\[
f\left(x\right)=\sum_{i\in S_{k}}w_{i}\left(x\right)f_{i}\left(x\right)
\]

\end_inset

where the normalized contribution weights 
\begin_inset Formula $w_{i}\left(x\right)$
\end_inset

 are defined as
\begin_inset Formula 
\[
w_{i}\left(x\right)=\frac{\phi_{i}\left(x\right)}{\sum_{j\in S_{k}}\phi_{j}\left(x\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
This formulation ensures that each contributing agent's influence on the final prediction is proportional to its estimated competence.
\end_layout

\begin_layout Subsection
Learning Rules
\end_layout

\begin_layout Standard
As in oCELL,
 we design our learning rules around a set of actions and conditions that triggers those actions to digest 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 that are fed to the system sequentially as a data stream.
 In context agent learning systems,
 the set of actions consists of the actions that can be performed individually by agents such as updating their model or shape;
 and more meta-level actions such as destroying or creating new agents.
 These actions are triggered by conditions that generally depend on two factors:
 the number of current neighbors and a feedback value calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
When we have 
\begin_inset Formula $N>1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of those agents are theoretically considered as experts to predict for 
\begin_inset Formula $x_{new}$
\end_inset

.
 As the final prediction fo the system 
\begin_inset Formula $f\left(x\right)=\hat{y}$
\end_inset

 is computed from the proposals of all those agents,
 we need the agents to cooperate together locally to improve the local knowledge.
 We define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

,
 the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process,
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}=\frac{E_{-i}-E}{E}=\frac{\left|\hat{y}_{-i}-y_{new}\right|-\left|\hat{y}-y_{new}\right|}{\left|\hat{y}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E$
\end_inset

 is the prediction error,
 
\begin_inset Formula $E_{-i}=\left|\hat{y}_{-i}-y_{new}\right|$
\end_inset

 is the prediction error without considering the proposition of prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset

 then it means that removing agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 from the prediction group had a negative impact on the prediction error,
 meaning that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 has a positive contribution to reducing the error locally and conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset

.
 This value indicates for a given point,
 which agents are strong and which are weak in predicting for 
\begin_inset Formula $x_{new}$
\end_inset

.
 We can therefore consider that weak agents need to improve their local model,
 while strong agents are already good and need to strengthen their local anchoring at the given point.
 This update rule allows for the continuous improvement of the group locally by improving the weakest agents while keeping them mobile,
 thus allowing them to position themselves elsewhere if needed.
\end_layout

\begin_layout Standard
When we have only one agent (
\begin_inset Formula $N=1$
\end_inset

) that is neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

,
 we can't update it according to the same rules.
 Indeed,
 we can't compare its contribution to the error using other neighors (as if 
\begin_inset Formula $N>1$
\end_inset

).
 Therefore,
 we define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

,
 the relative error reduction compared to a baseline prediction given by a running short term linear predictor
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}^{\prime}=\frac{E_{base}-E_{i}}{E_{base}}=\frac{\left|y_{base}-y_{new}\right|-\left|\hat{y}_{i}-y_{new}\right|}{\left|y_{base}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E_{base}$
\end_inset

 is the prediction error of the short term linear predictor,
 
\begin_inset Formula $E_{i}=\left|\hat{y}_{i}-y_{new}\right|$
\end_inset

 is the prediction error of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 outperforms the short term linear predictor locally around 
\begin_inset Formula $x_{new}$
\end_inset

,
 giving indications that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 might be useful locally,
 and conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

.
 This value allows to estimate how expert the agent is relative to the short-term baseline.
 We can therefore consider that if the only neighbor agent is beaten by the baseline,
 then it probably shouldn't be a neighbor to this point.
 It should skip interacting this 
\begin_inset Formula $x_{new}$
\end_inset

 and 
\begin_inset Formula $y_{new}$
\end_inset

,
 waiting to reposition itself by ingesting new points,
 to be destroyed,
 or for another agent to become a neighbor in that area so they can improve together.
 Conversely,
 if it's better than the baseline,
 then it's a local expert whom we want to keep in that area since it represents the only knowledge we have about it.
 So,
 it should improve its local model and strengthen its local anchoring around 
\begin_inset Formula $x_{new}$
\end_inset

.
 This update rule allows single neighbors to specialize locally even when alone in an area.
\end_layout

\begin_layout Standard
Finally if no agent is considered a neighbor (
\begin_inset Formula $N=0$
\end_inset

),
 then we compute 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 since as in the case 
\begin_inset Formula $N=1$
\end_inset

,
 there is no neighbor to compare to.
 Thus,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

,
 it means that the neared agent is more relevant than the short term linear predictor.
 Therefore,
 it seems that this agent should encompass the point and become its neighbor by improving its model and extending its shape towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 On the other hand,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

,
 it means that even the nearest agent is not relevant for prediction and therefore the system probably has no knowledge of 
\begin_inset Formula $x_{new}$
\end_inset

 and should add it to its knowledge base by covering the space around it by creating a new agent initialized from a short term containing last points seen by the system.
\end_layout

\begin_layout Standard
Since we create agents,
 we need a mechanism to destroy then.
 An,
 agent might position poorly in the feature space or choose to ingest the wrong points making its model no longer representative of the covered area.
 Decision errors happen almost all the time when working in an online setting because we have no knowledge to what the future points will look like.
 We can only guess from local relationshop between successive points.
 If no destruction mechanism is introduced to mitigate the proliferation of agents,
 the number of agents will grow indefinitely and performances will be hurt by bad agents,
 preventing local specialization in the system and ultimately dragging down the predictive accuracy.
 
\end_layout

\begin_layout Standard
Therefore,
 we define instantaneous normalized confidence 
\begin_inset Formula $c_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

 of an agent as the various feedbacks received by the agent
\begin_inset Formula 
\[
c_{i}=\tanh\left(k\times\begin{cases}
\Delta_{\mathcal{A}_{i}} & \text{if}\,N>1\\
\Delta_{\mathcal{A}_{i}}^{\prime} & \text{else}
\end{cases}\right)
\]

\end_inset

where 
\begin_inset Formula $k$
\end_inset

 is the steepness of the 
\begin_inset Formula $\tanh$
\end_inset

 function.
\end_layout

\begin_layout Standard
Then we define 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

,
 the running confidence of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as the exponental moving average of successive instantaneous confidence values (i.e feedback values) received by the agent
\begin_inset Formula 
\[
\bar{C}_{\mathcal{A}_{i}\,|\,t+1}=\left(1-\lambda\right)\bar{C}_{\mathcal{A}_{i}\,|\,t}+\lambda c_{\mathcal{A}_{i}}
\]

\end_inset

where 
\begin_inset Formula $\lambda$
\end_inset

 the smoothing factor.
\end_layout

\begin_layout Standard
The confidence value 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}$
\end_inset

 is calculated for each agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 and updated each time 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

is selected as a neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

.
 It allows to track its performance over the course of successive updates.
 When 
\family roman
\series medium
\shape up
\size normal
\emph off
\nospellcheck off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}>0$
\end_inset

,
 it means that,
 on average,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is categorized as strong compared to other neighbors or the short-term baseline predictor,
 and conversely if 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}<0$
\end_inset

.
 Confidence this allows us to distinguish between agents that strengthen the system and those that degrade it.
 We deduce that an agent whose trust falls below a certain threshold 
\begin_inset Formula $\tau_{\text{confidence}}$
\end_inset

 should be destroyed to allow the emergence of new and more efficient local structures.
\end_layout

\begin_layout Standard
Finally,
 we present in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Learning-rules-of-kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 a summary of the learning rules that describe the behavior of context agents in kCELL.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N>1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of kCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-kCELL"

\end_inset

 where 
\begin_inset Formula $N$
\end_inset

 is the number of neighbors,
 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 the relative error reduction compared to a baseline prediction and 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
To visualize the result of a learning and local cooperation of agents,
 we use a 1-dimensional example.
 We generate a small synthetic dataset from the function 
\begin_inset Formula $f\left(x\right)=\sin\left(x\right)+\epsilon\mathcal{N}\left(0,1\right)$
\end_inset

 with 
\begin_inset Formula $\epsilon\in\mathbb{R}$
\end_inset

 the noise scaling factor.
 We simulate online learning by sequentially feeding the agent one 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 tuple at a time.
 Each point is only seen once during learning as this is an important property of an effective and rapid online learning algorithm especially useful in real time dynamics modeling.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1D-Visualization-of-local-coop"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a side-by-side visualization of the spatial organization of agents 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Spatial-organization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 against the result of aggregating their predictions 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Resulting-prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 We can observe that the agents overlap and do not fit perfectly across their entire area of expertise;
 at the edges of agents the fit seems to have more errors and conversely on the center.
 This is the expected behavior resulting from the assumption of non-uniformity in the knowledge within areas of expertise.
 Finally,
 we observe that the overall predictions approximate closely the function considering the noise added to the data.
 It demonstrates kCELL's ability to generalize effectively by interpolation.
 This highlights the usefulness of a weighted aggregation function as presented in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsubsec:Soft-Weighted-Prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/local_coop_1D_illustration/viz_agents_sin1D.png
	lyxscale 40
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Spatial organization
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Spatial-organization"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/local_coop_1D_illustration/viz_inference_sin1D.png
	lyxscale 45
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Resulting prediction
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Resulting-prediction"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of local cooperation of agents in predicting a noisy sinus function.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Spatial-organization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents the spatial organization of agents where is colored segment represents the mapping of an individual agent between feature space and output space.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Resulting-prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the resulting predictions obtained from the aggregation of agents local models,
 illustrating the interpolation capabilities of the model.
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Visualization-of-local-coop"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add algo and mention that we learn from a stream and that to initialize agents we use several successive points (to tackle limitation of oCELL which was to initialize agents with one point)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Adaptation to Non-Stationary Dynamics
\end_layout

\begin_layout Standard
In kCELL,
 the agents learn a function from a stream of data through local modeling and cooperation.
 In this section we present various experiments and case studies to demonstrate the capabilities of kCELL in terms of online adaptation and raw performances in online dynamics modeling.
\end_layout

\begin_layout Subsubsection
Experimental Protocol
\end_layout

\begin_layout Standard
To evaluate the capabilities of kCELL to adapt online to non-stationary dynamics,
 we conducted experiments on two MuJoCo 
\begin_inset CommandInset citation
LatexCommand cite
key "todorov2012mujoco"
literal "false"

\end_inset

 simulation environment:
 InvertedPendulum and Hopper.
 For each environment,
 datasets were collected under three gravitational acceleration values (
\emph on
default 
\emph default
gravity
\emph on
 
\emph default

\begin_inset Formula $g=9.81$
\end_inset

,
 
\emph on
low 
\emph default
gravity 
\begin_inset Formula $g=4$
\end_inset

 ,
 
\emph on
high
\emph default
 gravity 
\begin_inset Formula $g=20$
\end_inset

) using pretrained reinforcement learning agents trained with Soft-Actor-Critic (SAC) algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "haarnoja2018soft"
literal "false"

\end_inset

 (with stable-baselines3 implementation 
\begin_inset CommandInset citation
LatexCommand cite
key "stable-baselines3"
literal "false"

\end_inset

).
 Training data were streamed in the same order to simulate abrupt changes in the underlying system dynamics.
 The characteristics of the generated datasets are presented in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Characteristics-of-datasets"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
The environments were selected to contrast a low-dimensional setting (InvertedPendulum with 4-dimensional states and 1 action) with a higher-dimensional one (Hopper with 11-dimensional state and 3 actions).
 Mahalanobis distance values become larger the higher the number of dimensions.
 Thus we want to study the impact of increasing dimensionality on the spatialization of kCELL which was one of the main limiations of the comparative experiments conducted in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Comparative-Study"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 for oCELL.
 We also compare kCELL to Adaptive Hoeffding Trees 
\begin_inset CommandInset citation
LatexCommand cite
key "bifet2009adaptive"
literal "false"

\end_inset

 which is an efficient adaptive online learning method based on decision trees designed to handle concept drift.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Environment
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
State Size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nb Actions
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dynamic Changes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nb Learning Steps
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
InvertedPendulum
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g\in\left\{ 9.81,4,20\right\} $
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
30k
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hopper
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g\in\left\{ 9.81,4,20\right\} $
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50k
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Characteristics of datasets generated with different values of 
\begin_inset Formula $g$
\end_inset

.
 
\emph on
State Size
\emph default
 stands for the number of features in states,
 
\emph on
Nb Actions
\emph default
 stands for the number of continuous actions,
 
\emph on
Dynamic Changes
\emph default
 corresponds the set of 
\begin_inset Formula $g$
\end_inset

 values used to generate the datasets,
 
\emph on
Nb Learning Steps
\emph default
 corresponds to the budget in number of training steps used to train the RL agent used to generate each dataset (one RL Agent per dataset).
\begin_inset CommandInset label
LatexCommand label
name "tab:Characteristics-of-datasets"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Prediction Error Analysis
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the evolution of Mean Absolute Error (MAE) for kCELL and Adaptive Hoeffding Trees algorithms measured on the test sets associated with each value of 
\begin_inset Formula $g$
\end_inset

 for each environment.
 Across both environments,
 the MAE consistently decreases on the test set corresponding to the currently observed gravity value,
 indicating effective online adaptation to changes in dynamics (refer to semi-transparent red areas in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
For the InvertedPendulum environment,
 kCELL systematically outperforms Adaptive Hoeffding Trees when the training and testing gravity values coincide,
 exhibiting lower MAE throughout each stationary phase.
 This suggests that the local spatialized modeling strategy employed by kCELL allows more accurate approximation of the underlying dynamics in low-dimensional settings.
 For the Hopper environment,
 both approaches achieve comparable MAE across the different gravity regimes.
 However,
 we notice that the error curve of kCELL displays higher variance,
 reflecting the self organization mechanisms of agents (creation,
 destruction,
 updates).
 This could also be due to numerical out-of-distribution prediction instability of CELL approaches which is a known problem.
 Indeed,
 due to spatialization,
 kCELL is not designed to predict too far outside their domain of expertise leading to very low activation scores for far away points and potential numerical instabilities.
\end_layout

\begin_layout Standard
Finally,
 specifically for kCELL,
 we notice that for InvertedPendulum,
 transitions between gravity values lead to an increase in MAE on past test sets,
 seemingly reflecting partial forgetting of earlier dynamics.
 In contrast,
 for Hopper,
 kCELL exhibits stable MAE on previously encountered gravity values even after multiple regime changes,
 suggesting retiention of prior knowledge.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/mae_comparison_testsets_invertedpendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-mae-dynamic-changes-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/mae_comparison_testsets_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-mae-dynamic-changes-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of test error on each test dataset.
 Each horizontal plot shows the evolution of error on a test dataset (in order top to bottom:
 
\begin_inset Formula $g=9.81$
\end_inset

 (
\emph on
default
\emph default
),
 
\begin_inset Formula $g=4$
\end_inset

 (
\emph on
low gravity
\emph default
),
 
\begin_inset Formula $g=20$
\end_inset

 (
\emph on
high gravity
\emph default
).
 The semi-transparent red area corresponds to the training period in which the training and test sets corresponds to the same dynamic variations.
 The dotted vertical red lines corresponds to changes in dynamics i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the MAE over the corresponding training set.
 The blue curve corresponds to kCELL's MAE measurements.
 For example the top plot corresponds to the MAE calculated on test data for 
\begin_inset Formula $g=9.81$
\end_inset

 and red area corresponds to the training phase in which 
\begin_inset Formula $g=9.81$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-mae-dynamic-changes"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Structural Evolution of Agent Population
\end_layout

\begin_layout Standard
We analyze the evolution of agent population during training illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-nb-agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 As previously hinted by MAE analysis,
 we notice constrating dynamics in the population evolution during learning between the two environments.
 In InvertedPendulum (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 each gravity change induces a short-term surge in the number of agents,
 followed by a reduction and stabilization around a nominal value.
 This indicates a restructuring of the population,
 where novelty triggers agent creation and confidence-based mechanisms triggers destruction to eliminate less relevant agents.
\end_layout

\begin_layout Standard
In Hopper (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 the number of agents grows monotonically throughout training.
 Distinct growth regimes are observed for each gravity value with first a logaritmic growth (
\begin_inset Formula $g=9.81$
\end_inset

),
 second a seemingly linear growth (
\begin_inset Formula $g=4$
\end_inset

) and third a slight logarithmic growth (
\begin_inset Formula $g=20$
\end_inset

) with stabilization around 20k steps.
 This accumulation of agents suggests a continuous detection of local dynamics without systematic removal of existing agents.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/nb_agents_colored_zones_no_title_invertedpendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-nb-agents-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/nb_agents_colored_zones_no_title_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-nb-agents-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the number of agents in kCELL during learning.
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the number of agents in the system.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-nb-agents"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Age and Confidence Dynamics
\end_layout

\begin_layout Standard
The mean age of agents provides further insights on kCELL as presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-age"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 In InvertedPendulum,
 gravity changes coincide with abrupt drops in mean agent age.
 This means that the population becomes suddenly younger,
 which is consistent with the replacement of older agents by newly created ones following a shift in dynamics.
 This behavior aligns with a confidence-driven selection mechanism that favors agents specialized to the current dynamics.
\end_layout

\begin_layout Standard
In Hopper however,
 the mean agent age increases almost constantly,
 with only minor decreases follwoing the first gravity change and a slight slowdown after the second.
 This indicates that older agents persist over time and are not fully displaced by newer ones,
 despite agent creations.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/age_of_agents_w500_no_title_colored_inverted_pendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-age-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/age_of_agents_w500_no_title_colored_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-age-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the age of agents in kCELL during learning (smoothed with a window of 500 steps).
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the mean age of agents (in steps) in the system .
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-age"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Activation and Local Expertise
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-activations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 shows the evolution of the activation of closest agent during learning.
 In InvertedPendulum,
 each gravity change results in a sharp drop in activation,
 signaling a loss of relevance of existing local modals.
 Activation values subsequently recovers as new agents acquire expertise under the new dynamics.
\end_layout

\begin_layout Standard
In Hopper,
 activation levels differ across the different gravity regimes,
 with distinct nominal mean activation value observed for each values of gravity acceleration.
 Slight activation decreases are detectable immediately following changes in dynamics,
 these effects are less visible than in INvertedPendulum and partially blurred by higher variance regimes.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/max_activation_smooth_w500_colored_inverted_pendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-activations-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/max_activation_smooth_w500_colored_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-activations-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the maximum activation value of agents in kCELL during learning (smoothed with a window of 500 steps).
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the maximum activation value of agents.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-activations"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the higher-dimensional Hopper environment,
 agent persistence can be explained by two non-exclusive mechanisms.
 First,
 it is possible that agents trained under earlier gravity settings retain partial competence in overlapping regions of the state-action space.
 Those agents are then incrementally adapted as new data arrives leading to multi-regime reuse.
 In this case the growth of agents can be explained mainly by the modeling complexity introduced by the change in dynamics.
 Second,
 high-dimensional effects may reduce the sensitivity of the Mahalanobis distance,
 yielding sparse activation of older agents that prevents both their meaningful adaption and confidence degradation.
 In this case,
 those agents can be considered as frozen because they are too tightly tied to previously visited regions that do not overlap with newly discovered ones after dynamic changes.
\end_layout

\begin_layout Standard
To disambiguate whether agent persistence in the Hopper environment arises from adaptive reuse or from limited cross-regime activation,
 we analyzed the activation patterns of the final agent population obtained after full training.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-of-activations-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a heatmap of agent activations for all training samples,
 where columns correspond to agents sorted by age (from oldest to youngest) and rows correspond to training data points (in order) aggregated into bins.
 The resulting heatmap exhibits distinct block patterns,
 with older agents primarily activated for samples from the earliest dataset and progressively younger agents ddominating activation for later datasets.
 We can also observe that the shape of the number of agents curve (presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) appears in the heatmap drawn by points where agents are the most active.
 This organization further indicates that agents remain selectively active for the dynamics under which they were trained and created rather than becoming inactive or obsolete.
\end_layout

\begin_layout Standard
Complementary,
 we provide a two-dimensional UMAP 
\begin_inset CommandInset citation
LatexCommand cite
key "mcinnes2018umap"
literal "false"

\end_inset

 projection of the training data in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:UMAP-of-training-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 with samples colored according to their corresponding gravity regime.
 The projection reveals a clear separation between training datasets,
 suggesting that changes in dynamics induce distinct regions in the state-action space.
 This structural separation provides a plausible explanation for the coexistence of multiple generations of agents.
 Because data from different dynamics regimes occupy largely disjoint regions,
 agents specialized to earlier dynamics remain relevant for their corresponding subspaces without interfering with those created for later regimes.
\end_layout

\begin_layout Standard
These analyses support the claim that agent retention in the Hopper environment is primarily driven by regime-specific specialization in a high-dimensional space,
 rather than by passive survival due to insufficient confidence updates that would prevent the destruction process.
 While Mahalanobis distance may lose discriminative power in higher dimensional spaces,
 the observed seperation of state-action distributions enables kCELL to maintain multiple local experts corresponding to different dynamics.
 This results in stable prediction performance across successive dynamics changes.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/agents_activation_heatmap_no_title_w300.png
	lyxscale 30
	width 70col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Heatmap of final Agents Activations on Training Datasets.
 
\begin_inset Formula $y$
\end_inset

-axis correspond to the training data (in order) aggregated into bins of size 300 (from top to bottom) and 
\begin_inset Formula $x$
\end_inset

-axis corresponds to agents ids sorted from the oldest to the youngest (left to right).
 The dotted horizontal red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The colors corresponds to activation levels of agents over each aggregated training data bins with yellow meaning high activation and blue meaning low activation.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Heatmap-of-activations-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/train_umap_without_agents.png
	lyxscale 30
	width 70col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of UMAP projection of Training data where each point is colored depending on the training dataset it comes from (blue for 
\begin_inset Formula $g=9.81$
\end_inset

;
 yellow for 
\begin_inset Formula $g=4$
\end_inset

;
 pink for 
\begin_inset Formula $g=20$
\end_inset

)
\begin_inset CommandInset label
LatexCommand label
name "fig:UMAP-of-training-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Discussion
\end_layout

\begin_layout Standard
The results presented suggest that kCELL is able to adapt to non-stationary dynamics through a combination of local specialization and structural plasticity with behaviors that depend strongly on the dimensionality and geometry of the feature space.
 In both environments,
 kCELL succesfully reduces prediction error on the currently observed dynamics demonstrating effective online adaptation without explicit task or concept drift detection modules.
 Compared to a Hoeffding Adaptive Tree baseline,
 kCELL achieves lower MAE for the low-dimensional InvertedPendulum environment when training and testing distributions coincide.
 It also achieves comparable performances for the higher-dimensional Hopper environment although with increased variability due to its structural adaptivity.
\end_layout

\begin_layout Standard
For the InvertedPendulum environment,
 changes in dynamics induced a rapid loss of relevance of agents trained on previous dynamics leading to their destruction or adjustment.
 This is reflected by sharp drops in agent activation,
 decreases in mean agent age,
 temporary surges in the number of agents followed by a stabilization and the observed increase in MAE on previously encountered dynamics.
 These indicate a population renewal process driven by confidence degradation and agent replacement.
 In this setting,
 partial forgetting emerges as a natural consequence of the overlap between the geometry of different dynamics and reflects appropriate structural adaptation rather than failure of retention.
\end_layout

\begin_layout Standard
In contrast,
 the Hopper environment exhibits persistent agent populations and stable prediction performance across successive dynamics changes.
 Although the number of agents grows monotonically,
 confidence-based destruction prevents the survival of agents that negatively impact prediction accuracy.
 The absence of population turnover is therefore not attributable to ineffective agent pruning.
 Analysis of agent activations reveals a structured specialization pattern.
 The activation heatmap of the final agent population shows distinct blocks associated with different training phases.
 Older agents are selectively activated for earlier gravity regimes and younger agents for later ones.
 This organization indicates retention of regime-specific expertise rather than passive persistence of obsolete models.
 Indeed,
 the agents do not know when a new dynamics change might occur and which dynamics will replace the current one.
\end_layout

\begin_layout Standard
This interpretation is further supported by the UMAP analysis of the training data,
 which reveals clear separation between datasets generated with different gravity values.
 The existence fo well-separated regions in the state-action space provides a plausible explanation for the coexistence of multiple generations of agents without destructive interference.
 Thus,
 in this case,
 high dimensionality enables to allocate distinct subsets of agents to different dynamics.
 Although Mahalanobis distance may lose discriminative precision as dimensionality increases,
 for this experiment with 11-dimensional states and 3-dimensional actions (resulting in a 14-dimensional input vector),
 the geometric separation induced by gravity changes appears sufficient to maintain effective specialization.
\end_layout

\begin_layout Standard
Overall,
 the results suggest that kCELL implicitly adjusts the tradeoff between forgetting and retention based on the structure of the data distribution rather than relying on explicit task boundaries.
 In low-dimensional spaces,
 adaptation is achieved through agent replacement and partial forgetting,
 while in higher-dimensional settings with separable regimes,
 the system favors retention and specialization.
 These results highlight both the strength and current limitations of kCELL.
 It paves the way for future works on the use of more robust distance metrics and activation mechanisms to account for high-dimensional geometry.
\end_layout

\begin_layout Standard
Finally,
 we highlight the ability to analyze kCELL through the spatial organization and activation patterns of agents as a key advantage in terms of interpretability.
 Introspection of agent properties allows to identify which regions of the state-action space correspond to different dynamics,
 to understand how the model responds to non-stationary conditions and to debug or reinfe learning mechanisms.
 This relates the properties we presented in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 showing that despite the design differences with oCELL,
 some related properties remain.
\end_layout

\begin_layout Subsection
Online Stationary Modeling
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on SARCOS + D4RL + KUKA to test raw performances with river-ml algorithms
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Comparative Study of CELL Variants
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Comparison of paving for robot in maze / or pendulum between oCELL and kCELL
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on SARCOS + D4RL to test raw performances
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on number of neighbors and mahalanobis distances in various dimensions,
 and mention agent growth and problems of dimensionality
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Section
Parallelization and Differentiability
\end_layout

\begin_layout Subsection
Spatial Indexing
\end_layout

\begin_layout Subsection
Differentiable Programming Frameworks
\end_layout

\begin_layout Subsection
GPU-based parallelized updates
\end_layout

\begin_layout Chapter
Solving Control Tasks with CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Solving-Control-Tasks"

\end_inset


\end_layout

\begin_layout Standard
We introduced CELL (Context Ensemble Local Learning),
 an online machine learning framework.
 In this chapter,
 we demonstrate the use of CELL for solving complex control tasks without prior knowledge of system dynamics.
 CELL continuously learns the dynamics and is used as the predictive model within a Model Predictive Control (MPC) scheme.
\end_layout

\begin_layout Standard
For safe control tasks with hard operational constraints,
 we show that CELL's inherent local linearization enables a seamless integration with traditional non linear optimization methods such as Sequential Quadratic Programming.
 Moreover,
 the spatial organization of local experts provides a knowledge map of the model,
 allowing the control of the optimization process conservativeness to explore poorly modeled states or stay in well modeled regions.
 Building on this property,
 we propose a novel interpretability approach based on Linear Quadratic Regulator (LQR) to analyze and quantify the impact of constraints on the optimization objective,
 establishing a baseline for unconstrained performance.
\end_layout

\begin_layout Section
Model Predictive Control
\end_layout

\begin_layout Section
Constrained Optimization
\end_layout

\begin_layout Subsection
Soft Constraints
\end_layout

\begin_layout Subsection
Hard Constraints
\begin_inset CommandInset label
LatexCommand label
name "subsec:Hard-Constraints"

\end_inset


\end_layout

\begin_layout Section
Robust MPC (Uncertainty Handling)
\end_layout

\begin_layout Section
Explainable Control (LQR Explainer)
\end_layout

\begin_layout Chapter
Scalable Non-Linear CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Scalable-Non-Linear-CELL"

\end_inset


\end_layout

\begin_layout Standard
In chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we presented an ensemble learning algorithm to solve continuous supervised learning tasks.
 Then,
 in chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we demonstrated how to use our approach to continuously model the dynamics of a system in order to solve a constrained control task.
 Through our experiments,
 we have noticed that,
 when the state and action dimensions increased,
 the concept of neighborhood as we have defined it loses its consistency and informativeness due to the dilation of distances in the feature space 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
A justifier avec une petite xp  la fin du chapitre 3
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
Indeed,
 when the number of features increases,
 it is much rarer for an agent to be considered a neighbor of a new point.
 Therefore,
 the amoung of data required for training is much greater,
 and the number of agents created grows rapidly.
 Thus,
 we identify a need to limit the growth in the number of agents to increase sample efficiency and limit redundancy in the knowledge base.
 Until now,
 to mitigate this problem,
 we needed to rely on hard-to-tune hyperparameters to define the initial size of agents on each feature 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3 ou papier PRIMA
\end_layout

\end_inset

 or on locality hypothesis on consecutive points among a given trajectory to identify relevant closest agents 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3
\end_layout

\end_inset

.
 In this chapter,
 we present SGP-CELL a novel approach based on Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "williams1995gaussian"
literal "false"

\end_inset

 effectively tailored for scalable online learning.
 Our contributions are threefold:
\end_layout

\begin_layout Itemize
we propose a new spatialization approach for context agents based on Principal Component Analysis (PCA) 
\begin_inset CommandInset citation
LatexCommand cite
key "jolliffe2011principal"
literal "false"

\end_inset

 to robustify neighborhoods in larger feature spaces.
\end_layout

\begin_layout Itemize
we introduce a new learning process for individual agents based on model selection and greedy objective minimization.
\end_layout

\begin_layout Itemize
we demonstrate the performances and sample efficiency of SGP-CELL compared to a Sparse Gaussian Process baseline on a forward dynamics modeling task.
\end_layout

\begin_layout Section
Related Works
\end_layout

\begin_layout Standard
Gaussian Processes (GP) are non-parametric Bayesian approaches to solve regression tasks while modeling uncertainty in predictions.
 GPs have been successful in robotics to model inverse or forward dynamics of a system to solve safe non linear control problems 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
+ de REF ?
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "berkenkamp2015safe"
literal "false"

\end_inset

.
 However,
 GP have a high computational cost with a learning complexity of 
\begin_inset Formula $O\left(kN^{3}\right)$
\end_inset

 with 
\begin_inset Formula $N$
\end_inset

 the number of training points and 
\begin_inset Formula $k$
\end_inset

 the number of optimization steps to find optimal kernel parameters,
 which results from the inversion of the covariance matrix 
\begin_inset Formula $K$
\end_inset

.
 This makes GPs no able to handle large datasets.
\end_layout

\begin_layout Standard
Approximation methods like Sparse Gaussian Processes (SGP) alleviate this scaling issue.
 Instead of using the whole training dataset to build the model,
 a set of 
\begin_inset Formula $M$
\end_inset

 inducing points (with 
\begin_inset Formula $N\gg M$
\end_inset

) are selected to represent the whole dataset.
 The inducing points allow for a cheaper low-rank representation for approximating the posterior distribution lowering the complexity to 
\begin_inset Formula $O\left(NM^{2}\right)$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "snelson2005sparse,naish2007generalized"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Other works have extended SGP with Variational Inference to further enhance scalability with stochastic minibatch optimization to handle large datasets,
 improve generalization and reduce overfitting 
\begin_inset CommandInset citation
LatexCommand cite
key "titsias2009variational,bauer2016understanding"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
For
\end_layout

\begin_layout Subsection
Gaussian Process Regression
\end_layout

\begin_layout Subsection
Online Gaussian Processes
\end_layout

\begin_layout Section
SGP-CELL
\end_layout

\begin_layout Subsection
Scaling Neighborhoods
\end_layout

\begin_layout Subsection
Non-Linear Local Modeling
\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Section
Practical Design Guidelines
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add formalism for the whole CELL family
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Based on our experience designing our multiagent systems based on context agents for supervised learning,
 we present in this section comprehensive overview of common obstacles that must be overcome for such a system to work properly,
 allowing the emergence of learning.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
feedback (
\begin_inset Formula $\Delta$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
kCELL features
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion and limitations
\end_layout

\begin_layout Chapter
Speed Recommendation:
 Industrial Use Cases
\end_layout

\begin_layout Standard
The enforcement of the EU General Safety Regulation has accelerated the adoption of Intelligent Speed Assistance (ISA) systems in new vehicles,
 emphasizing the need for reliable embedded speed recommendations.
 Unlike classical speed control approaches that are centered on vehicle dynamics modeling,
 speed recommendation requires reasoning that considers the driver in the loop,
 introducing behavioral variability and acceptance constraints.
 Designing deployable systems further demands attention to safety compliance,
 homologation requirements,
 robustness under sensor failure and potential impacts on energy consumption.
 In this chapter,
 we discuss these challenges and outline design principles for building speed recommendation systems suitable for real-world deployment and propose search directions to advance the field toward operational intelligent speed recommendation solutions.
\end_layout

\begin_layout Chapter
Conclusion and Future Works
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "manuscript"
options "plain"
encoding "default"

\end_inset


\end_layout

\end_body
\end_document
