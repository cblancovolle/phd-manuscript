#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\use_default_options true
\begin_modules
theorems-ams
\end_modules
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement class
\float_alignment class
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008080
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Chapter
Related Works
\end_layout

\begin_layout Standard
This chapter provides a comprehensive review of the literature on speed recommendation systems.
 We decompose the problem into two sub-problems:
 a 
\emph on
modeling problem
\emph default
,
 which involves continuously estimating vehicle dynamics under driver-specific influence to enable personalized and realistic speed recommendations;
 and a 
\emph on
control problem
\emph default
,
 which leverages the learned model to optimize speed profiles with respect to predefined objectives and operational constraints.
 To establish a rigorous foundation and position our approach within the field,
 we examine state-of-the-art methods across three relevant domains:
 speed control and recommendation,
 online machine learning,
 and optimal control.
\end_layout

\begin_layout Section
Speed Recommendation and Speed Control
\end_layout

\begin_layout Section
Online Machine Learning
\end_layout

\begin_layout Section
Optimal Control
\end_layout

\begin_layout Section
Positioning
\end_layout

\begin_layout Chapter
Context Ensemble Local Learning (CELL)
\begin_inset CommandInset label
LatexCommand label
name "chap:Context-Ensemble-Local"

\end_inset


\end_layout

\begin_layout Standard
To achieve speed recommendation we need to model the behavior of a vehicle driven by a human driver in response to speed recommendation set points.
 Thus,
 we need a modeling algorithm able to perform online learning and learn efficiently seeing a data point once while having transparent and explainable inner workings.
 For that reason we explored the use of multiagent systems as a mean of solving supervised learning tasks.
 
\end_layout

\begin_layout Standard
As showed in 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 a supervised learning problem can be modeled as a multiagent system.
 This perspective offers several advantages,
 including design simplicity,
 transparency,
 and explainability properties that naturally emerge from the spatial organization of agents.
\end_layout

\begin_layout Standard
In this chapter we introduce CELL (Context Ensemble Local Learning),
 a family of mutliagent systems designed for online learning dynamics of a complex environment.
 Our approach addresses online supervised learning through simple self-organization of multiple local expert agents paving the feature space.
 These agents are created and updated dynamically according to predefined learning rules.
 Each agent occupies a specific region in feature space,
 representing the area where it is most confident in the quality of its predictions.
 Contrary to previous works on this type of system 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 we introduce novelties regarding the explainability while exploring new cooperation mechanisms between agents and new spatialization approaches.
\end_layout

\begin_layout Standard
By leveraging the spatialization of local experts and the inherent transparency of the model,
 we derive unique informative explainability properties that provide valuable insights about the approximated function.
 Furthermore,
 we outline practical guidelines for scaling with the number of agents,
 keeping a bounded computational complexity.
\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Subsection
Multi-Agent Learning
\end_layout

\begin_layout Standard
Multi-agent systems (MAS) have gained popularity due to their ability to solve complex problems by breaking them down into simpler sub-problems that can be easily addressed by autonomous agents,
 whether interconnected or not 
\begin_inset CommandInset citation
LatexCommand cite
key "dorri2018multi"
literal "false"

\end_inset

.
 The interaction rules between agents or with the environment are defined by the system designer to achieve a specific objective.
 The use of MAS has proven effective in fields such as civil engineering 
\begin_inset CommandInset citation
LatexCommand cite
key "SHAMSHIRBAND20132105"
literal "false"

\end_inset

 or eletrical engineering,
 particularly with issues related to smart grids 
\begin_inset CommandInset citation
LatexCommand cite
key "rohbogner2014design"
literal "false"

\end_inset

.
 In more recent years,
 reinforcement learning has been seriously considered to bypass the phase of designing rules that define agent behavior.
 Indeed,
 in Multi-Agent Reinforcement Learning (MARL),
 agents' behaviors are learned using reinforcement signals obtained by continuously interacting with an environment 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In this chapter,
 we present various iterations of CELL,
 a MAS that combines both approaches to tackle online supervised learning problems.
 Agents of the system update using both reinforcement learning signals and cooperation rules.
 Unlike MARL,
 our approach requires fewer environment interactions and focuses on specialized agents collaborating within a supervised learning framework,
 differing from MARL's dynamic interactions aiming to maximize cumulative rewards through adaptive strategies (
\emph on
competitive
\emph default
 or 
\emph on
cooperative
\emph default
) 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Ensemble Learning
\end_layout

\begin_layout Standard
To achieve more accurate predictions and provide better approximations of nonlinear functions,
 it is common to aggregate multiple models for making predictions.
\end_layout

\begin_layout Standard
Ensemble learning is based on the emergence of collective intelligence within a set of weak learners.
 A weak learner is a model whose performance is at least as good as a model making random predictions.
 During the learning process,
 a set of models (which may differ from one another) are trained in parallel or sequentially 
\begin_inset CommandInset citation
LatexCommand cite
key "polikarEnsembleLearning2012"
literal "false"

\end_inset

.
 The objective is to encourage diversity among the models so that they do not all capture the same patterns in the data 
\begin_inset CommandInset citation
LatexCommand cite
key "dietterichEnsembleMethodsMachine2000"
literal "false"

\end_inset

.
 An input is transmitted to all weak learners,
 each of which makes a prediction proposal.
 A heuristic is implemented to select one of the proposals or to weight each of them in order to construct the final prediction.
 We distinguish several major approaches in ensemble learning which are Boosting,
 Bagging and Stacking.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add figure to compare bagging,
 boosting and stacking
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visual comparison of bagging,
 boosting and stacking
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Bagging we train multiple models (usually homogeneous) in parallel on different subsets of the training data to introduce diversity,
 reduce variance and improve stability.
 Then the final prediction is obtained by averaging the predictions of the weak learners (regression) or by majority voting (classification).
 Unlike Bagging,
 in Boosting,
 we train the models sequentially.
 Each new model focuses on correcting the errors of the previous ones to reduce bias and improve accuracy.
 Then we obtain the final prediction from a weighted average of the predictions of the all the weak learners.
 Finally,
 we have Stacking that falls under meta-learning.
 We train in parallel a set of heterogeneous models and then we train a meta-model whose role will be to combine the predictions of each model to obtain the final output fo the system,
 in order to capture complementary strengths of each learning algorithms involved in the learning process.
\end_layout

\begin_layout Standard
The family of systems we present in this chapter,
 CELL,
 falls within the ensemble learning framework and we could label it as a Bagging approach because we consider a set of weak learners as a collection of self-organizing cooperative agents.
 Each one of them is a local expert on the function to be approximated.
\end_layout

\begin_layout Section
oCELL:
 Multiagent Ensemble Learning with Orthotopes
\end_layout

\begin_layout Standard
In this section we describe the first variant of CELL that we name oCELL (orthotope CELL).
 We explore context agent based systems composed of multiple autonomous agents with their own capabilities and only local knowledge of the environment.
 Our system is based on the Self-Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to address an online supervised learning problem.
 We want to learn a function 
\begin_inset Formula $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$
\end_inset

 to map feature to target vectors from a stream of data.
 
\end_layout

\begin_layout Standard
oCELL processes a stream of data.
 Incoming points are routed to the system's primary components,
 which we call Context agents.
 These agents are created and updated dynamically according to predefined learning rules.
 Each Context agent occupies a specific region in feature space,
 representing the area where is is most confident in its predictions.
 This spatialization allows the agent to determine 
\emph on
when
\emph default
 it should make a prediction.
 To determine 
\emph on
what
\emph default
 to predict,
 each agent maintains a local machine learning model over the confidence region.
 
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert description of subsequent section content
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Context Agents
\end_layout

\begin_layout Standard
The main entities of oCELL are the Context agents.
 A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is characterized by an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

 such as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i}\left(x\right),f_{i}\left(x\right)\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
Each agent can refine the parameters of its internal activation and prediction function to adapt to its local surroundings depending on reinforcement signals it receives.
 To summarize,
 a Context agent can be considered as a local expert of the function to be approximated with its activation function telling it 
\emph on
when
\emph default
 it should predict and with its prediction function telling it 
\emph on
what
\emph default
 to predict.
 
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert description of subsequent section content
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Spatialization with Orthotopes
\end_layout

\begin_layout Standard
As we need a transparent and interpretable system,
 we chose to spatialize our Context agents using orthotopes.
 the use of orthotopes allows us to precisely evaluate how agents have organized themselves feature-wise while also allowing for simpler shape change mechanisms required for self-organisation of Context agents because we can act on each dimension individually.
\end_layout

\begin_layout Standard
Learning with orthotopes (often referred to as hyper-rectangles in literature) is an approach already explored in literature for supervised learning 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022,konstantinov2023interpretable"
literal "false"

\end_inset

.
 Usually,
 these approaches aim to partition the feature space into orthotopes to then model locally the function to approximate.
 For example,
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "konstantinov2023interpretable"
literal "false"

\end_inset

,
 the authors leverage a gradient boosting approach to learn the bounds of the orthotopes with each corresponding to a very simple base model (constant value),
 not suitable for online learning from a stream of data.
\end_layout

\begin_layout Standard
In terms of spatialization of agents,
 oCELL borrows a similar approach to 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 in which authors use SACL learning paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to solve a classification task from a stream of data by progressively paving the feature space with context agents.
 However,
 unlike 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 we address issues specifically related to regression problems such as a need for a smoother spatialization of agents.
\end_layout

\begin_layout Standard
In oCELL,
 each agent activation function's parameters correspond to a 
\begin_inset Formula $p$
\end_inset

-dimensional orthotope in the feature space.
 This orthotope si defined for each feature dimension 
\begin_inset Formula $j\in\left\{ 1,\dots,n\right\} $
\end_inset

 by a lower bound 
\begin_inset Formula $l_{j}$
\end_inset

 and an upper bound 
\begin_inset Formula $h_{j}$
\end_inset

 such as
\begin_inset Formula 
\[
\mathcal{H}_{i}=\left[l_{1},h_{1}\right]\times\dots\times\left[l_{n},h_{n}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
The volume 
\begin_inset Formula $v\left(\mathcal{A}_{i}\right)$
\end_inset

 of the orthotope associated to 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined by
\begin_inset Formula 
\[
v\left(\mathcal{A}_{i}\right)=\prod_{j=1}^{n}\left(h_{j}-l_{j}\right)
\]

\end_inset

Furthermore,
 an observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is considered as intersecting an hyperrectangle if,
 for all feature 
\begin_inset Formula $j$
\end_inset

 we have 
\begin_inset Formula 
\[
l_{j}\leq x_{j}\leq h_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
Additionaly,
 an orthotope 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 intersects another orthotope 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

 if,
 for all feature 
\begin_inset Formula $j$
\end_inset

 we have
\begin_inset Formula 
\[
\max\left(l_{1,j},l_{2,j}\right)\leq\min\left(h_{1,j},h_{2,j}\right)
\]

\end_inset

with 
\begin_inset Formula $l_{1,j}$
\end_inset

,
\begin_inset Formula $l_{2,j}$
\end_inset

 and 
\begin_inset Formula $h_{1,j}$
\end_inset

,
\begin_inset Formula $h_{2,j}$
\end_inset

 respectively the lower and upper bounds of 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Agents in oCELL are constructed based on the assumption of uniformity of knowledge over their area of expertise,
 that is to say on the area delimited by the orthotope associated with them.
 We distinguish between activation and neighborhood.
 When an agent is activated by a point,
 it means it is confident in its expertise to predict for that point.
 When an agent is a neighbor of a point,
 it means it has doubts about its expertise to predict for that point.
 In other words,
 it's an agent that is a candidate to become an activated agent for that point.
 The way an agent updates itself differs depending on whether the agent is activated or a neighbor.
\end_layout

\begin_layout Definition
A Context Agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is considered activated by an observation 
\begin_inset Formula $x$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 intersects with the orthotope 
\begin_inset Formula $\mathcal{H}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{\mathcal{H}}:\mathbb{R}^{n}\mapsto\left\{ 0,1\right\} $
\end_inset

 of 
\begin_inset Formula $\mathcal{A}$
\end_inset

.
 In other words,
 we define the activation function of 
\begin_inset Formula $\mathcal{A}$
\end_inset

 as
\begin_inset Formula 
\[
\phi_{\mathcal{H}}\left(x\right)=\begin{cases}
1 & \text{if}\,\,\forall j,\,\,l_{j}\leq x_{j}\leq h_{j}\\
0 & \text{else}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
We define the neighborhood of an observation 
\begin_inset Formula $x$
\end_inset

 as an orthotope 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset

 centered on 
\begin_inset Formula $x$
\end_inset

.
 A 
\emph on
Context
\emph default
 Agent is considered a neighbor of 
\begin_inset Formula $x$
\end_inset

 if the orthotope 
\begin_inset Formula $\mathcal{H}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{\mathcal{H}}$
\end_inset

 of 
\begin_inset Formula $\mathcal{A}$
\end_inset

,
 intersects with 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset


\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add ref to equation of intersection between two orthotopes
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
For agents to self-organize,
 they need to be able to change form and move across feature space.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 authors defined spatialization rules such that overlap between agents would be minimized to avoid ambiguity in decision making to predict the class of a sample (for example agents could push each other).
 For a regression task,
 it can be more informative to average the predictions of several weak models to smooth the learned function.
 This property is all the more interesting because it would make our model easier to use in a non linear optimization process (cf section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Hard-Constraints"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 To smooth the learned function,
 we allow intersections between agents.
 An agent can therefore change its shape by contracting or expanding without worrying about where other agents are.
\end_layout

\begin_layout Definition
If a 
\emph on
Context
\emph default
 agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 expands (resp.
 contracts) by a factor 
\begin_inset Formula $\alpha$
\end_inset

 in the direction of an observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

,
 then the upper bounds 
\begin_inset Formula $h_{j}^{t}$
\end_inset

 and lower bounds 
\begin_inset Formula $l_{j}^{t}$
\end_inset

 of the associated hyperrectangle are updated according to the following relationship:
\begin_inset Formula 
\begin{align}
h_{j}^{t+1} & =\begin{cases}
\left(h_{j}^{t}-l_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+l_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
h_{j}^{t} & \text{else}
\end{cases}\\
l_{j}^{t+1} & =\begin{cases}
\left(l_{j}^{t}-h_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+h_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
l_{j}^{t} & \text{else}
\end{cases}
\end{align}

\end_inset

with
\begin_inset Formula 
\[
\varepsilon=\begin{cases}
\left(1+\alpha\right) & \text{if expansion}\\
\left(1-\alpha\right) & \text{if retraction}
\end{cases}
\]

\end_inset

and 
\begin_inset Formula $k$
\end_inset

 the number of features such that 
\begin_inset Formula $l_{j}^{t}\leq x_{j}\leq h_{j}^{t}$
\end_inset

.
 Thus,
 the new volume of the hyperrectangle associated with 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is given by the relation:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align}
v_{\mathcal{A}}^{t+1} & =\varepsilon v_{\mathcal{A}}^{t}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
To summarize,
 our agents are spatialized through their activation functions with orthotopes that define their 
\emph on
area of expertise
\emph default
 in feature space.
 Finally,
 each agent can update the parameters of its activation function,
 effectively expanding or retracting its associated orthotope.
 Intuitively,
 big agents could be considered as 
\emph on
generalists
\emph default
 and smaller agents could be considered as 
\emph on
specialists
\emph default
.
 Therefore,
 in a region of feature space that is more complex to model,
 we would expect to find many small agents,
 and conversely,
 in a region of space that is simpler to model.
 We note that this assumption is based on the use of a simple class of models for agents such as linear regression.
 In our subsequent examples and experiments,
 we will primarily use linear regressions as internal models for the agents.
 Indeed,
 these models are simple,
 explainable,
 and transparent in their inner workings.
\end_layout

\begin_layout Subsubsection
Neighborhood Prediction
\begin_inset CommandInset label
LatexCommand label
name "subsubsec:Neighborhood-Prediction"

\end_inset


\end_layout

\begin_layout Standard
Our goal is to solve a regression problem from a data stream.
 Specifically,
 we want to model the nonlinear dynamics of a complex system so that we can use the resulting model in an optimization pipeline for optimal control (cf chapter 
\begin_inset CommandInset ref
LatexCommand eqref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Usually,
 when performing control with a learned model,
 we want to have minimal noise in the gradients and a smooth learned function to avoid significantly disrupting the optimization process.
 Therefore,
 we choose to allow the system to involve mutliple agents in the final decision,
 unlike in previous works 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,dato2021apprentissage,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

 where only one agent was ultimately selected to make the prediction.
\end_layout

\begin_layout Standard
To obtain the prediction 
\begin_inset Formula $\hat{y}$
\end_inset

 from an observation 
\begin_inset Formula $x$
\end_inset

,
 we first need to select the agents that will make proposals on the value of 
\begin_inset Formula $\hat{y}$
\end_inset

.
 If some agents are neighbors of 
\begin_inset Formula $x$
\end_inset

,
 then they make proposals,
 instead,
 if 
\begin_inset Formula $x$
\end_inset

 has no neighbor,
 we select the 
\begin_inset Formula $k$
\end_inset

-closest agents instead.
 We proceed this way to avoid situations in which our model is not able to predict at all due to poor knowledge in the area around 
\begin_inset Formula $x$
\end_inset

.
 The final prediction is then given by the arithmetic mean of the proposals of selected agents such as
\begin_inset Formula 
\[
\hat{y}=\frac{1}{\left|D_{\text{selected}}\right|}\times\sum_{i\in D_{\text{selected}}}f_{i}\left(x\right)
\]

\end_inset

with 
\begin_inset Formula $D_{\text{selected}}$
\end_inset

the set of selected agents (neighbors or closest) and 
\begin_inset Formula $f_{i}\in\mathbb{R}^{m}$
\end_inset

 the internal function of the 
\begin_inset Formula $i$
\end_inset

-th agent.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert diagram to explain prediction
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of the prediction process with Context Agents
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Learning Rules
\end_layout

\begin_layout Standard
In CELL systems,
 we design the learning rules around a set of actions and conditions that trigger those actions to digest 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 that are fed to the system as a data stream.
 In context agent learning systems,
 the set of actions consists of actions that can be performed individually by agents such as updating their model or shape;
 and more meta-level actions such as destroying or creating new agents.
 In oCELL these actions are triggered by conditions that depend on the number of current neighbors or activated agents and a feedback value calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
To determine what an agent should do,
 we define the quality of the proposal 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

 
\begin_inset Formula $g:\mathbb{R}^{m}\times\mathbb{R}^{m}\mapsto\mathbb{R}$
\end_inset

 of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as
\begin_inset Formula 
\[
L_{\mathcal{A}_{i}}=g\left(\hat{y},y\right)
\]

\end_inset

 where 
\begin_inset Formula $g:\mathbb{R}^{m}\times\mathbb{R}^{m}\mapsto\mathbb{R}$
\end_inset

 is a distance measure between the proposal 
\begin_inset Formula $\hat{y}$
\end_inset

 and the true value 
\begin_inset Formula $y$
\end_inset

,
 that is to say the error.
 The largest 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

,
 the worse the quality of the proposal.
 For oCELL,
 we will use the squared error as the 
\begin_inset Formula $g$
\end_inset

 function but other types of error functions could be used instead.
 We define two thresholds 
\begin_inset Formula $\tau_{\text{good}}$
\end_inset

 and 
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset

 to define three regimes in the values of 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

:
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

 for 
\emph on
good
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

 for 
\emph on
inaccurate
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

 for 
\emph on
bad
\emph default
 predictions.
 This way,
 we can choose the desired degree of accuracy that we want oCELL to reach after training.
\end_layout

\begin_layout Paragraph
Inaccuracy
\end_layout

\begin_layout Standard
When we have 
\begin_inset Formula $N_{A}\geq1$
\end_inset

 activated agents for 
\begin_inset Formula $x_{new}$
\end_inset

,
 it means the area around 
\begin_inset Formula $x_{new}$
\end_inset

 is already known because it is covered by agents.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

,
 it means the prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 and it was right to declare itself as an expert on 
\begin_inset Formula $x_{new}$
\end_inset

.
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 will therefore seek to generalize in the direction of 
\begin_inset Formula $x_{new}$
\end_inset

 by extending its area of expertise.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 then the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
inaccurate
\emph default
 but it is still promising as a candidate to be activated,
 so it only refines its internal model and keeps its positions waiting for another signal to expand is needed.
 Then,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

,
 the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
bad,

\emph default
 meaning that it shouldn't have been activated.
 In reaction to that,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

will retract to get away from 
\begin_inset Formula $x_{new}$
\end_inset

.
 This rule represents the core of agents local self-organization.
 It allows the agents to move in feature space and refine their model as needed to exclude or include points to better model their close surroundings in feature space in response to feedbacks on the quality of their predictions.
\end_layout

\begin_layout Paragraph
Incompetence
\end_layout

\begin_layout Standard
When we have 
\begin_inset Formula $N_{A}=0$
\end_inset

 activated agents and 
\begin_inset Formula $N\geq1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of the closest agents are candidate on becoming activated on 
\begin_inset Formula $x_{new}$
\end_inset

.
 In this situation,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 i.e prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
,
 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 could be an expert on 
\begin_inset Formula $x_{new}$
\end_inset

 so it refines its model and expands towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 Otherwise,
 if no neighbor gives 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
 predictions,
 then we create a new agent centered on 
\begin_inset Formula $x_{new}$
\end_inset

.
 This rule allows oCELL to reuse the current knowledge and extend it as needed.
 It also aims to limit the creation of redundant agents.
\end_layout

\begin_layout Paragraph
Uselessness
\end_layout

\begin_layout Standard
In practice,
 we observe that it's necessary to have mechanisms for destroying agents within the system.
 Indeed,
 some agents may evolve to degenrate shapes if they receive too much negative feedbacks in a row.
 Theyr become far too small to be informative.
 These 
\emph on
dead
\emph default
 agents,
 that won't be activate ever again,
 are no longer useful in the system.
 Consequently,
 we detroy all agents whose volume falls below a certain threshold value 
\begin_inset Formula $\tau_{\text{vol}}$
\end_inset

.
\end_layout

\begin_layout Standard
Finally we present in Table 
\begin_inset CommandInset ref
LatexCommand eqref
reference "tab:Learning-rules-of-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 a summary of the learning rules that describe the behavior of agents in oCELL.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="4">
<features tabularvalignment="middle" tabularwidth="95col%">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model 
\begin_inset Newline newline
\end_inset

+ shape (expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\forall\mathcal{A}_{i},\,L_{\mathcal{A}_{i}}\notin\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(retract)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of oCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-oCELL"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert flowchart to explain learning
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Flowchart illustrating the learning process
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Comparative Study
\end_layout

\begin_layout Subsubsection
Data Generation
\end_layout

\begin_layout Subsubsection
Experiment
\end_layout

\begin_layout Subsection
Explainability
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Standard
We demonstrated the potential of oCELL to solve supervised learning problems.
 However,
 this approach still needs refinement and has limitations that we will address in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
One of the limitations of this approach lies in the neighborhood prediction system described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 Indeed we assumed in designing our system that an agent's level of knowledge about the function to be approximated is uniform across its area of expertise (i.e the orthotope associated to its activation function).
 Intuitively it might be more accurate to consider that an agent has a better expertise near its centroid,
 than on its edges.
 
\end_layout

\begin_layout Standard
Moreover,
 we also consider,
 when mutliple agents are involved in the prediction process that they have the same weight in the construction of the final prediction due to the arithmetic sum.
 Initially,
 we decided to proceed this way because of the knowledge uniformity assumption.
 However it would probably be more accurate to consider that when two agent make predictions,
 the one closest to the input point will has the smallest error due to the agent's spatial distribution.
 Thus,
 each agent involved in the prediction process should be weighted according to their level of expertise on the point
\end_layout

\begin_layout Standard
With oCELL,
 we attempted to calculate a weighted average of the agents' proposals to obtain the final prediction.
 The weights corresponded to the euclidean distance to centers of the agents involved.
 However,
 we found that this did not improve performances,
 likely because the euclidean distance to the centers do not account for the agent's shape.
 We therefore need to find a distance between an agent and the point that takes into account both the agent's centroid and its shape.
\end_layout

\begin_layout Standard
Another limitation lies in the spatialization of agents using orthotopes.
 Indeed,
 in some cases,
 the orthotopic representation may be limited and may not correspond to the reality of the points on which the agent learns.
 This can lead to covering entire areas that have never been seen,
 thus potentially generating false positives when we query the system about its knowledge of a point.
 We illustrate this in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Limitation orthotope agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 in which we compare side by side an overgeneralizing agent and a representative agent by visualizing their respective orthotopes (represented by a blue rectangle) and training data (represented by red dots).
 The overgeneralizing agent has its training data not covering the entirety of its associated orthotope unlike for the representative agent that seemingly has a training dataset that covers entirely it's associated orthotope.
 This example shows how crucial is the spatialization of agents and especially their base shape to best represent the local manifolds of features,
 avoid overgeneralization errors and avoid categorizing a point as known when it's not.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/sane_orthotope_agent.png
	width 40col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Representative orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Representative-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/overgeneralized_orthotope_agent.png
	width 40col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Overgeneralizing orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Overgeneralizing-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Side by side comparison of representative Context 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Representative-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 agent against a overgeneralizing Context agent 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Overgeneralizing-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 The blue rectangle corresponds to the orthotope associated to the activation function of the Context agent.
 Each red dot corresponds to a training point seen by the Context agent.
\begin_inset CommandInset label
LatexCommand label
name "fig:Limitation orthotope agents"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
oCELL has been designed for online machine learning.
 However,
 it does not exploit the relationships between successive points in a data stream.
 It considers each point to be independent,
 effectively limiting oCELL's convergence speed.
\end_layout

\begin_layout Standard
Finally,
 the last limitation we were able to identify is that some hyperparameters are difficult to tune.
 We are referring in particular to the initial size of the orthotopes associated with the new created agents,
 which requires setting a side length for each feature.
 In this regard,
 we can also refer to the error thresholds used to categorize a prediction as 
\emph on
good
\emph default
,
 
\emph on
bad
\emph default
 or 
\emph on
inaccurate
\emph default
.
\end_layout

\begin_layout Section
kCELL:
 Multiagent Ensemble Learning with Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "sec:kCELL"

\end_inset


\end_layout

\begin_layout Standard
We have extended Context agent learning to address regression tasks in the context of supervised learning.
 We showed that oCELL has competitive performances on a synthetic 2D benchmark dataset and exhibits interesting explainability properties.
 Indeed,
 we showed that we could extract measures of epistemic and aleatoric uncertainties in the predictions of the system as well as information about the variations of the underlying function from the shape and spatial organization of the 
\emph on
Context
\emph default
 agents in the feature space.
 These properties will be particularly useful when using this type of model in an optimization loop for safe optimal control.
\end_layout

\begin_layout Standard
However,
 oCELL has some limitations.
 Specifically,
 the spatialization of agents with orthotopes can sometimes produce erroneous representations of areas of expertise,
 leading to overestimations of their size and shape.
 In addition to that,
 the aggregation function used to compute predictions do not account for the shape and distance between the agents involved and the input.
 These limitations can sometimes lead to in-distribution interpolation problems and redundant agents.
 Furthermore,
 oCELL consider all points as independent and thus do not exploit the relationships between successive points,
 limiting its convergence speed in an online setting in which adaptativity is fairly important.
 Finally,
 some of oCELL's learning rules rely on hyperparameters that are difficult to tune (error thresholds and initial size of orthotope sides at agent creation).
\end_layout

\begin_layout Standard
To overcome these limitations,
 we introduce kCELL (kernel CELL),
 the second variant of CELL.
 In order to better represent the information we propose a spatialization approach based on RBF kernels inspired from what is done with RBF Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "lowe1988multivariable"
literal "false"

\end_inset

 or MoE (Mixture of Experts) 
\begin_inset CommandInset citation
LatexCommand cite
key "yukselTwentyYearsMixture2012"
literal "false"

\end_inset

 gating mechanisms.
 We also introduce a smoother aggregation function for inference to better represent the expertise of each agent involved in the prediction process taking inspiration from what is done for Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "seeger2004gaussian"
literal "false"

\end_inset

 in which the contribution of each point to the final prediction is weighted by a kernel value.
\end_layout

\begin_layout Subsection
Context Agents
\end_layout

\begin_layout Standard
As for oCELL 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Ref to definition of context agents in oCELL
\end_layout

\end_inset

,
 the main entities of kCELL are the Context agents.
 A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is characterized by an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

 such as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i}\left(x\right),f_{i}\left(x\right)\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
However,
 unlike in oCELL,
 the Context agents of kCELL are spatialized differently.
 In oCELL we use a binary activation (the point is inside or outside the associated orthotope) while in kCELL we use a RBF kernel as a continuous and smooth activation function to represent the area of expertise in feature space.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert description of subsequent section content
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kernel-Spatialization"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 contrary to using orthotopes we use a RBF kernel as the activation function to unlock more degrees of freedom to represent the areas of expertise 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add ref to illustration Figure
\end_layout

\end_inset

.
 This activation function is smooth and differentiable,
 making the system more optimization-friendly to be used for control tasks as a dynamics model.
 Therefore,
 an agent is spatialized by the mean 
\begin_inset Formula $\mu_{i}\in\mathbb{R}^{n}$
\end_inset

 and covariance matrix 
\begin_inset Formula $\Sigma_{i}\in\mathbb{R}^{n\times n}$
\end_inset

 of the distribution of its training points.
 Since this activation function has statistical significance,
 it is easier for us to define the neighborhood as a confidence interval whose confidence value we can adjust.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison between area of expertise oCELL vs kCELL
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Definition
The distance between a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 and a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined as the mahalanobis distance:
\begin_inset Formula 
\[
d\left(\mathcal{A}_{i},x\right)=D_{M}\left(\mu_{i},\Sigma_{i},x\right)=\sqrt{\left(x-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x-\mu_{i}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is considered as a neighbor of 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 is likely to belong to the training dataset of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 such as 
\begin_inset Formula 
\[
D_{M}\left(\mu_{i},\Sigma_{i},x\right)^{2}\leq\chi_{n,0.95}^{2}
\]

\end_inset

 where 
\begin_inset Formula $\chi_{n,0.95}^{2}$
\end_inset

 denotes the 
\begin_inset Formula $95$
\end_inset

th percentile of the chi-squared distribution with 
\begin_inset Formula $n$
\end_inset

 degrees of freedom.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The activation function 
\begin_inset Formula $\phi_{i}:\mathbb{R}^{n}\mapsto\left[0,1\right]$
\end_inset

 of a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 for a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is given by the RBF kernel value
\begin_inset Formula 
\[
\phi_{i}\left(\mathcal{A}_{i},x\right)=\exp\left(-\frac{d\left(\mathcal{A}_{i},x\right)}{2l^{2}}\right)
\]

\end_inset

with 
\begin_inset Formula $l$
\end_inset

 the lengthscale of the kernel.
\end_layout

\begin_layout Definition
The activation score of a point 
\begin_inset Formula $x$
\end_inset

 for a given agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 can be interpreted as the likelihood that the agent has previously been trained on points similar to 
\begin_inset Formula $x$
\end_inset

,
 and thus reflects the agent's degree of knowledge over the corresponding region of feature space.
 We can draw a parallel between this activation function based on RBF kernel and the coverage index 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert ref to coverage index in previous section
\end_layout

\end_inset

,
 an explainability metric that we derived from oCELL which is also linked to the degree of knowledge of a point.
 In kCELL,
 this explainability property related to the knowledge of a point emerges naturally from the definition of the system.
\end_layout

\begin_layout Definition
With kCELL we want to retain as few points as possible in memory to truly represent information through local models.
 As previously stated,
 the spatialization of each agent can be fully described by a mean 
\begin_inset Formula $\mu_{i}$
\end_inset

 and a covariance matrix 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 which are the parameters of the activation function 
\begin_inset Formula $\phi_{i}$
\end_inset

.
 Each time a point is ingested by agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

,
 we update its mean and covariance matrix using the Welford's algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "welford1962note"
literal "false"

\end_inset

 such as 
\begin_inset Formula 
\begin{eqnarray*}
\mu_{i\,|\,t+1} & = & \mu_{i\,|\,t}+\frac{x-\mu_{i\,|\,t}}{n+1}\\
\Sigma_{i\,|\,t+1} & = & \frac{1}{n}\left(\Sigma_{i\,|\,t+1}+\left(x-\mu_{i\,|\,t}\right)\left(x-\mu_{i\,|\,t+1}\right)^{\top}\right)
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $n$
\end_inset

 is the number of points ingested by the agent to update its shape.
 With this approach we express the shape change purely as a mean and covariance estimation problem.
\end_layout

\begin_layout Subsubsection
Soft-Weighted Prediction
\end_layout

\begin_layout Standard
In kCELL,
 we get rid of the knowledge uniformity hypothesis of agents to better represent the knowledge of the system.
 Therefore the activation function of a context agent materializes its area of expertise through a smooth RBF kernel.
 The further a point is from the agent's centroid,
 the lower its activation value.
 This is because we assume that expertise is maximized at the agent's center.
 Agents with higher activation values contribute more heavily to the final output because they are more expert than others at predicting.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $S_{k}=\left\{ i|\mathcal{A}_{i}\,\text{is in the \ensuremath{k}-closest to}\,x\right\} $
\end_inset

 denote the index set of the 
\begin_inset Formula $k$
\end_inset

 nearest agents in feature space.
 The final prediction 
\begin_inset Formula $f\left(x\right)\in\mathbb{R}^{m}$
\end_inset

 of the system is then given by
\begin_inset Formula 
\[
f\left(x\right)=\sum_{i\in S_{k}}w_{i}\left(x\right)f_{i}\left(x\right)
\]

\end_inset

where the normalized contribution weights 
\begin_inset Formula $w_{i}\left(x\right)$
\end_inset

 are defined as
\begin_inset Formula 
\[
w_{i}\left(x\right)=\frac{\phi_{i}\left(x\right)}{\sum_{j\in S_{k}}\phi_{j}\left(x\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
This formulation ensures that each contributing agent's influence on the final prediction is proportional to its estimated competence.
\end_layout

\begin_layout Subsection
Learning Rules
\end_layout

\begin_layout Standard
As in oCELL,
 we design our learning rules around a set of actions and conditions that triggers those actions to digest 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 that are fed to the system sequentially as a data stream.
 In context agent learning systems,
 the set of actions consists of the actions that can be performed individually by agents such as updating their model or shape;
 and more meta-level actions such as destroying or creating new agents.
 These actions are triggered by conditions that generally depend on two factors:
 the number of current neighbors and a feedback value calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
When we have 
\begin_inset Formula $N>1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of those agents are theoretically considered as experts to predict for 
\begin_inset Formula $x_{new}$
\end_inset

.
 As the final prediction fo the system 
\begin_inset Formula $f\left(x\right)=\hat{y}$
\end_inset

 is computed from the proposals of all those agents,
 we need the agents to cooperate together locally to improve the local knowledge.
 We define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

,
 the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process,
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}=\frac{E_{-i}-E}{E}=\frac{\left|\hat{y}_{-i}-y_{new}\right|-\left|\hat{y}-y_{new}\right|}{\left|\hat{y}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E$
\end_inset

 is the prediction error,
 
\begin_inset Formula $E_{-i}=\left|\hat{y}_{-i}-y_{new}\right|$
\end_inset

 is the prediction error without considering the proposition of prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset

 then it means that removing agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 from the prediction group had a negative impact on the prediction error,
 meaning that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 has a positive contribution to reducing the error locally and conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset

.
 This value indicates for a given point,
 which agents are strong and which are weak in predicting for 
\begin_inset Formula $x_{new}$
\end_inset

.
 We can therefore consider that weak agents need to improve their local model,
 while strong agents are already good and need to strengthen their local anchoring at the given point.
 This update rule allows for the continuous improvement of the group locally by improving the weakest agents while keeping them mobile,
 thus allowing them to position themselves elsewhere if needed.
\end_layout

\begin_layout Standard
When we have only one agent (
\begin_inset Formula $N=1$
\end_inset

) that is neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

,
 we can't update it according to the same rules.
 Indeed,
 we can't compare its contribution to the error using other neighors (as if 
\begin_inset Formula $N>1$
\end_inset

).
 Therefore,
 we define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

,
 the relative error reduction compared to a baseline prediction given by a running short term linear predictor
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}^{\prime}=\frac{E_{base}-E_{i}}{E_{base}}=\frac{\left|y_{base}-y_{new}\right|-\left|\hat{y}_{i}-y_{new}\right|}{\left|y_{base}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E_{base}$
\end_inset

 is the prediction error of the short term linear predictor,
 
\begin_inset Formula $E_{i}=\left|\hat{y}_{i}-y_{new}\right|$
\end_inset

 is the prediction error of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 outperforms the short term linear predictor locally around 
\begin_inset Formula $x_{new}$
\end_inset

,
 giving indications that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 might be useful locally,
 and conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

.
 This value allows to estimate how expert the agent is relative to the short-term baseline.
 We can therefore consider that if the only neighbor agent is beaten by the baseline,
 then it probably shouldn't be a neighbor to this point.
 It should skip interacting this 
\begin_inset Formula $x_{new}$
\end_inset

 and 
\begin_inset Formula $y_{new}$
\end_inset

,
 waiting to reposition itself by ingesting new points,
 to be destroyed,
 or for another agent to become a neighbor in that area so they can improve together.
 Conversely,
 if it's better than the baseline,
 then it's a local expert whom we want to keep in that area since it represents the only knowledge we have about it.
 So,
 it should improve its local model and strengthen its local anchoring around 
\begin_inset Formula $x_{new}$
\end_inset

.
 This update rule allows single neighbors to specialize locally even when alone in an area.
\end_layout

\begin_layout Standard
Finally if no agent is considered a neighbor (
\begin_inset Formula $N=0$
\end_inset

),
 then we compute 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 since as in the case 
\begin_inset Formula $N=1$
\end_inset

,
 there is no neighbor to compare to.
 Thus,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

,
 it means that the neared agent is more relevant than the short term linear predictor.
 Therefore,
 it seems that this agent should encompass the point and become its neighbor by improving its model and extending its shape towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 On the other hand,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

,
 it means that even the nearest agent is not relevant for prediction and therefore the system probably has no knowledge of 
\begin_inset Formula $x_{new}$
\end_inset

 and should add it to its knowledge base by covering the space around it by creating a new agent initialized from a short term containing last points seen by the system.
\end_layout

\begin_layout Standard
Since we create agents,
 we need a mechanism to destroy then.
 An,
 agent might position poorly in the feature space or choose to ingest the wrong points making its model no longer representative of the covered area.
 Decision errors happen almost all the time when working in an online setting because we have no knowledge to what the future points will look like.
 We can only guess from local relationshop between successive points.
 If no destruction mechanism is introduced to mitigate the proliferation of agents,
 the number of agents will grow indefinitely and performances will be hurt by bad agents,
 preventing local specialization in the system and ultimately dragging down the predictive accuracy.
 
\end_layout

\begin_layout Standard
Therefore,
 we define instantaneous normalized confidence 
\begin_inset Formula $c_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

 of an agent as the various feedbacks received by the agent
\begin_inset Formula 
\[
c_{i}=\tanh\left(k\times\begin{cases}
\Delta_{\mathcal{A}_{i}} & \text{if}\,N>1\\
\Delta_{\mathcal{A}_{i}}^{\prime} & \text{else}
\end{cases}\right)
\]

\end_inset

where 
\begin_inset Formula $k$
\end_inset

 is the steepness of the 
\begin_inset Formula $\tanh$
\end_inset

 function.
\end_layout

\begin_layout Standard
Then we define 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

,
 the running confidence of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as the exponental moving average of successive instantaneous confidence values (i.e feedback values) received by the agent
\begin_inset Formula 
\[
\bar{C}_{\mathcal{A}_{i}\,|\,t+1}=\left(1-\lambda\right)\bar{C}_{\mathcal{A}_{i}\,|\,t}+\lambda c_{\mathcal{A}_{i}}
\]

\end_inset

where 
\begin_inset Formula $\lambda$
\end_inset

 the smoothing factor.
\end_layout

\begin_layout Standard
The confidence value 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}$
\end_inset

 is calculated for each agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 and updated each time 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

is selected as a neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

.
 It allows to track its performance over the course of successive updates.
 When 
\family roman
\series medium
\shape up
\size normal
\emph off
\nospellcheck off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}>0$
\end_inset

,
 it means that,
 on average,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is categorized as strong compared to other neighbors or the short-term baseline predictor,
 and conversely if 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}<0$
\end_inset

.
 Confidence this allows us to distinguish between agents that strengthen the system and those that degrade it.
 We deduce that an agent whose trust falls below a certain threshold 
\begin_inset Formula $\tau_{\text{confidence}}$
\end_inset

 should be destroyed to allow the emergence of new and more efficient local structures.
\end_layout

\begin_layout Standard
Finally,
 we present in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Learning-rules-of-kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 a summary of the learning rules that describe the behavior of context agents in kCELL.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N>1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of kCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-kCELL"

\end_inset

 where 
\begin_inset Formula $N$
\end_inset

 is the number of neighbors,
 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 the relative error reduction compared to a baseline prediction and 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Experiment
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Illustration of local cooperative learning with learning Sinus 1D toy example (plot agents vs predictions)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on D4RL with various expertise datasets.
 Try feeding random => medium => expert.
 One test set for each dataset.
 Log performances on each to desmonstrate the adaptability.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Comparative Study of CELL Variants
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Comparison of paving for robot in maze between oCELL and kCELL
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on SARCOS + D4RL to test raw performances
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on number of neighbors and mahalanobis distances in various dimensions,
 and mention agent growth and problems of dimensionality
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Section
Parallelization and Differentiability
\end_layout

\begin_layout Subsection
Spatial Indexing
\end_layout

\begin_layout Subsection
Differentiable Programming Frameworks
\end_layout

\begin_layout Subsection
GPU-based parallelized updates
\end_layout

\begin_layout Chapter
Solving Control Tasks with CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Solving-Control-Tasks"

\end_inset


\end_layout

\begin_layout Standard
We introduced CELL (Context Ensemble Local Learning),
 an online machine learning framework.
 In this chapter,
 we demonstrate the use of CELL for solving complex control tasks without prior knowledge of system dynamics.
 CELL continuously learns the dynamics and is used as the predictive model within a Model Predictive Control (MPC) scheme.
\end_layout

\begin_layout Standard
For safe control tasks with hard operational constraints,
 we show that CELL's inherent local linearization enables a seamless integration with traditional non linear optimization methods such as Sequential Quadratic Programming.
 Moreover,
 the spatial organization of local experts provides a knowledge map of the model,
 allowing the control of the optimization process conservativeness to explore poorly modeled states or stay in well modeled regions.
 Building on this property,
 we propose a novel interpretability approach based on Linear Quadratic Regulator (LQR) to analyze and quantify the impact of constraints on the optimization objective,
 establishing a baseline for unconstrained performance.
\end_layout

\begin_layout Section
Model Predictive Control
\end_layout

\begin_layout Section
Constrained Optimization
\end_layout

\begin_layout Subsection
Soft Constraints
\end_layout

\begin_layout Subsection
Hard Constraints
\begin_inset CommandInset label
LatexCommand label
name "subsec:Hard-Constraints"

\end_inset


\end_layout

\begin_layout Section
Robust MPC (Uncertainty Handling)
\end_layout

\begin_layout Section
Explainable Control (LQR Explainer)
\end_layout

\begin_layout Chapter
Scalable Non-Linear CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Scalable-Non-Linear-CELL"

\end_inset


\end_layout

\begin_layout Standard
In chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we presented an ensemble learning algorithm to solve continuous supervised learning tasks.
 Then,
 in chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we demonstrated how to use our approach to continuously model the dynamics of a system in order to solve a constrained control task.
 Through our experiments,
 we have noticed that,
 when the state and action dimensions increased,
 the concept of neighborhood as we have defined it loses its consistency and informativeness due to the dilation of distances in the feature space 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
A justifier avec une petite xp  la fin du chapitre 3
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
Indeed,
 when the number of features increases,
 it is much rarer for an agent to be considered a neighbor of a new point.
 Therefore,
 the amoung of data required for training is much greater,
 and the number of agents created grows rapidly.
 Thus,
 we identify a need to limit the growth in the number of agents to increase sample efficiency and limit redundancy in the knowledge base.
 Until now,
 to mitigate this problem,
 we needed to rely on hard-to-tune hyperparameters to define the initial size of agents on each feature 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3 ou papier PRIMA
\end_layout

\end_inset

 or on locality hypothesis on consecutive points among a given trajectory to identify relevant closest agents 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3
\end_layout

\end_inset

.
 In this chapter,
 we present SGP-CELL a novel approach based on Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "williams1995gaussian"
literal "false"

\end_inset

 effectively tailored for scalable online learning.
 Our contributions are threefold:
\end_layout

\begin_layout Itemize
we propose a new spatialization approach for context agents based on Principal Component Analysis (PCA) 
\begin_inset CommandInset citation
LatexCommand cite
key "jolliffe2011principal"
literal "false"

\end_inset

 to robustify neighborhoods in larger feature spaces.
\end_layout

\begin_layout Itemize
we introduce a new learning process for individual agents based on model selection and greedy objective minimization.
\end_layout

\begin_layout Itemize
we demonstrate the performances and sample efficiency of SGP-CELL compared to a Sparse Gaussian Process baseline on a forward dynamics modeling task.
\end_layout

\begin_layout Section
Related Works
\end_layout

\begin_layout Standard
Gaussian Processes (GP) are non-parametric Bayesian approaches to solve regression tasks while modeling uncertainty in predictions.
 GPs have been successful in robotics to model inverse or forward dynamics of a system to solve safe non linear control problems 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
+ de REF ?
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "berkenkamp2015safe"
literal "false"

\end_inset

.
 However,
 GP have a high computational cost with a learning complexity of 
\begin_inset Formula $O\left(kN^{3}\right)$
\end_inset

 with 
\begin_inset Formula $N$
\end_inset

 the number of training points and 
\begin_inset Formula $k$
\end_inset

 the number of optimization steps to find optimal kernel parameters,
 which results from the inversion of the covariance matrix 
\begin_inset Formula $K$
\end_inset

.
 This makes GPs no able to handle large datasets.
\end_layout

\begin_layout Standard
Approximation methods like Sparse Gaussian Processes (SGP) alleviate this scaling issue.
 Instead of using the whole training dataset to build the model,
 a set of 
\begin_inset Formula $M$
\end_inset

 inducing points (with 
\begin_inset Formula $N\gg M$
\end_inset

) are selected to represent the whole dataset.
 The inducing points allow for a cheaper low-rank representation for approximating the posterior distribution lowering the complexity to 
\begin_inset Formula $O\left(NM^{2}\right)$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "snelson2005sparse,naish2007generalized"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Other works have extended SGP with Variational Inference to further enhance scalability with stochastic minibatch optimization to handle large datasets,
 improve generalization and reduce overfitting 
\begin_inset CommandInset citation
LatexCommand cite
key "titsias2009variational,bauer2016understanding"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
For
\end_layout

\begin_layout Subsection
Gaussian Process Regression
\end_layout

\begin_layout Subsection
Online Gaussian Processes
\end_layout

\begin_layout Section
SGP-CELL
\end_layout

\begin_layout Subsection
Scaling Neighborhoods
\end_layout

\begin_layout Subsection
Non-Linear Local Modeling
\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Section
Practical Design Guidelines
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add formalism for the whole CELL family
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Based on our experience designing our multiagent systems based on context agents for supervised learning,
 we present in this section comprehensive overview of common obstacles that must be overcome for such a system to work properly,
 allowing the emergence of learning.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
feedback (
\begin_inset Formula $\Delta$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
kCELL features
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion and limitations
\end_layout

\begin_layout Chapter
Speed Recommendation:
 Industrial Use Cases
\end_layout

\begin_layout Standard
The enforcement of the EU General Safety Regulation has accelerated the adoption of Intelligent Speed Assistance (ISA) systems in new vehicles,
 emphasizing the need for reliable embedded speed recommendations.
 Unlike classical speed control approaches that are centered on vehicle dynamics modeling,
 speed recommendation requires reasoning that considers the driver in the loop,
 introducing behavioral variability and acceptance constraints.
 Designing deployable systems further demands attention to safety compliance,
 homologation requirements,
 robustness under sensor failure and potential impacts on energy consumption.
 In this chapter,
 we discuss these challenges and outline design principles for building speed recommendation systems suitable for real-world deployment and propose search directions to advance the field toward operational intelligent speed recommendation solutions.
\end_layout

\begin_layout Chapter
Conclusion and Future Works
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "manuscript"
options "plain"
encoding "default"

\end_inset


\end_layout

\end_body
\end_document
