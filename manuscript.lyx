#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\usepackage{amssymb}
\usepackage{pifont}
\usepackage{graphicx}
\usepackage{forest}

\RestyleAlgo{ruled}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
linguistics
algorithm2e
\end_modules
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\float_alignment class
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008080
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Title
Adaptive Control via Local Online Learning
\end_layout

\begin_layout Standard
\align center
\begin_inset Note Note
status open

\begin_layout Plain Layout
Adaptive Control via Bottom-Up Local Online Learning
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Abstract
\end_layout

\begin_layout Standard
As the automotive industry gradually moves toward fully autonomous driving,
 the development of safe and intelligent transportation systems remains a crucial challenge,
 specifically with regard to interactions between the driver and the vehicle.
 The effectiveness of advanced driver assistance systems (ADAS),
 such as speed recommendation systems,
 depends on their ability to collaborate with the driver while taking into account the non-stationarity and uncertainty inherent in driver behavior.
\end_layout

\begin_layout Standard
Many machine learning approaches exploit the decomposition of the input space into specialized local models in order to better capture the variability of dynamics and facilitate continuous adaptation.
 This organization not only improves robustness in non-stationarity contexts,
 but also provides localized uncertainty estimates,
 facilitating the integration of learned models into safe control strategies.
\end_layout

\begin_layout Standard
In recent years,
 local learning based on contextual agents has emerged as a promising extension of these approaches.
 Inspired by the principles of self-organizing multi-agent systems,
 these methods allow each specialized model,
 represented by an agent,
 to cooperate and share information to enhance online adaptation,
 uncertainty management,
 and model interpretability.
\end_layout

\begin_layout Standard
In this context,
 we study the following question:
 to what extent cooperative local learning architectures such as CELL can serve as a foundation for safe control strategies,
 exploiting model introspection to guide exploration and support reliable decision-making ?
\end_layout

\begin_layout Standard
This thesis models the problem of speed recommendation as a problem of adaptive control of complex systems with unknown and non-stationary dynamics.
 We introduce the CELL (Context Ensemble Local Learning) formalism,
 inspired by self-organizing multi-agent systems.
 This formalism allows us to design online learning architectures capable of modeling nonlinear dynamics through the cooperation of specialized local models.
 This theoretical framework allows us to design systems that continuously adapt to environmental changes while preserving a spatialized representation of knowledge,
 which is essential for estimating the epistemic uncertainty required for reliable learning-based control.
\end_layout

\begin_layout Standard
Based on this formalism,
 we propose two systems derived from CELL:
 oCELL,
 in which local models are spatialized using orthotopes,
 and kCELL,
 which uses radial basis functions to obtain smoother approximations.
 A first series of experiments demonstrates that the geometric organization of agents offers introspective capabilities that can be linked to the notions of explainability and interpretability in machine learning.
 In particular,
 kCELL proves capable of overcoming the stability-plasticity dilemma in a non-stationary environment,
 while remaining competitive with classical approaches.
\end_layout

\begin_layout Standard
kCELL is then integrated into a predictive control system (Model Predictive Control - MPC).
 We exploit the model's introspective properties to direct exploration towards areas of high uncertainty and ensure safety by avoiding poorly modeled regions.
 Finally,
 we introduce a new method of explainability for constrained control,
 allowing us to quantify the influence of constraints on the optimization result.
\end_layout

\begin_layout Standard
Finally,
 future research directions are highlighted concerning the scaling up of CELL-based systems for higher dimensional spaces and the use of heterogeneous local models,
 paving the way for more robust and transparent adaptive learning systems.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Résumé
\end_layout

\begin_layout Standard
Alors que l'industrie automobile évolue progressivement vers une conduite entièrement autonome,
 le développement de systèmes de transport sûrs et intelligents demeure un enjeu crucial,
 notamment en ce qui concerne les interactions entre le conducteur et le véhicule.
 L'efficacité des systèmes avancés d'aide à la conduite (ADAS),
 tels que les systèmes de recommandation de vitesse,
 repose sur leur capacité à collaborer avec le conducteur tout en tenant compte de la non-stationnarité et de l'incertitude inhérentes à son comportement.
\end_layout

\begin_layout Standard
Plus largement,
 de nombreuses approches en apprentissage automatique exploitent la décomposition de l'espace d'entrée en sous-modèles locaux spécialisés afin de mieux capturer la variabilité de la dynamique et de faciliter l'adaptation continue.
 Cette organisation permet non seulement d'améliorer la robustesse face à la non-stationarité mais aussi de fournir des estimations d'incertitude localisées,
 facilitant l'intégration des modèles appris dans des stratégies de contrôle sûres.
\end_layout

\begin_layout Standard
Ces dernières années l'apprentissage local fondé sur des agents contextuels a émergé comme une extension prometteuse de ces approches.
 Inspirée des principes des systèmes multi-agents auto-organisés,
 ces méthodes permettent à chaque modèle spécialisé,
 modélisé par un agent,
 de coopérer et de partager l'information pour renforcer l'adaptation en ligne,
 la gestion de l'incertitude et l'interprétabilité du modèle.
\end_layout

\begin_layout Standard
Dans ce contexte,
 nous nous posons la question question suivante:
 dans quelle mesure des architectures d'apprentissage local coopératif telles que CELL peuvent-elles servir de fondation à des stratégies de contrôle sûres,
 exploitant l'introspection du modèle pour orienter l'exploration et soutenir une prise de décision fiable en condition réelles ?
\end_layout

\begin_layout Standard
Cette thèse modélise le problème de la recommandation de vitesse en un problème de contrôle adaptatif de systèmes complexes à dynamique inconnue et non-stationaire.
 Nous introduisons le formalisme CELL (
\emph on
Context Ensemble Local Learning
\emph default
),
 inspiré des systèmes multi-agents auto-organisés.
 Ce formalisme permet de concevoir des architectures d'apprentissage en ligne capables de modéliser des dynamiques non linéaires grâce à la coopération de modèles locaux spécialisés.
 Ce cadre théorique permet de concevoir des systèmes s'adaptant continuellement aux changements environnementaux tout en préservant une représentation spatialisée des connaissances,
 essentielle à l'estimation de l'incertitude épistémique requise pour un contrôle fiable basé sur l'apprentissage.
\end_layout

\begin_layout Standard
À partir de ce formalisme,
 nous proposons deux systèmes dérivés de CELL:
 oCELL,
 dans lequel les modèles locaux sont spatialisés à l'aide d'orthotopes,
 et kCELL qui utilise des fonctions de base radiales pour obtenir des approximations plus lisses.
 Une première série d’expériences démontre que l’organisation géométrique des agents offre des capacités d’introspection qui peuvent être reliées aux notions classiques d’explicabilité et d’interprétabilité en apprentissage automatique.
 En particulier,
 kCELL se révèle capable de surmonter le dilemme stabilité-plasticité dans un environnement non stationnaire,
 tout en étant compétitif avec les approches classiques.
\end_layout

\begin_layout Standard
kCELL est ensuite intégré dans un système de contrôle prédictif (
\emph on
Model Predictive Control
\emph default
 
\emph on
- MPC
\emph default
).
 Nous exploitons les propriétés d'introspection du modèle pour orienter l'exploration vers les zones de forte incertitude et sécuriser l'exploitation en évitant les régions mal modélisées.
 Enfin,
 nous introduisons une nouvelle méthode d'explicabilité pour le contrôle sous contraintes,
 permettant de quantifier l'influence des contraintes sur le résultat de l'optimisation.
\end_layout

\begin_layout Standard
Enfin,
 les orientations futures de la recherche sont mises en évidence concernant le passage à l'échelle des systèmes basés sur CELL pour des espaces de plus grande dimensions et l'utilisation de modèles locaux hétérogènes,
 ouvrant la voie à des systèmes d'apprentissage adaptatifs plus robustes et transparents.
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter*
General Introduction
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{chapter}{General Introduction}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In modern robotics,
 a robot can be defined by its ability to sense,
 think and act 
\begin_inset CommandInset citation
LatexCommand cite
key "siegel2003sense"
literal "false"

\end_inset

.
 As of the 21st century,
 this paradigm is currently undergoing a profound transformation.
 In modern systems,
 a fourth component emerges as essentia:
 
\emph on
communication
\emph default
.
 This evolution represents a transition from robots as isolated industrial units to robots as collaborative partners 
\begin_inset CommandInset citation
LatexCommand cite
key "baratta2023human"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
As we move from the technology-driven era of industry 4.0 toward the anthropocentric vision of Industry 5.0,
 the focus is shifting back to the human operator 
\begin_inset CommandInset citation
LatexCommand cite
key "baratta2023human"
literal "false"

\end_inset

 in the objective of building a synergy between machines and humans.
\end_layout

\begin_layout Standard
Robots need to move beyond being mere executors of pre-programmed tasks to penetrate consumer markets and more complex social environments.
 This requires developing social skills and advanced learning capabilities to achieve true synergy with human partners.
 This synergy strongly relies on the ability of a system to not only perceive its environment but to also adapt its behavior to the uncertain dynamics introduced by human presence.
\end_layout

\begin_layout Standard
This shift is especially present in the field of intelligent mobility.
 Nowadays,
 autonomous vehicles technologies are developing rapidly.
 Some companies in the US like Waymo or Baidu in China,
 already moved toward a driverless future by proposing autonomous taxi services.
 However,
 the reality of the consumer market must be nuanced.
 Current projections suggest that full market saturation by autonomous vehicles may not occur until the 2050s 
\begin_inset CommandInset citation
LatexCommand cite
key "lavasani2016market"
literal "false"

\end_inset

.
 For now,
 the human driver will remain a central component of the transport ecosystem.
\end_layout

\begin_layout Standard
Consequently,
 developing Advanced Driver Assistance Systems (ADAS) is of public utility.
 Technologies such as Adaptive Cruise Control (ACC) and Electronic Braking Systems (EBS) are essential to assists the driver and keep road users safe.
\end_layout

\begin_layout Standard
In particular,
 given the obvious correlation between speed mismanagement and road fatalities,
 the development of Intelligent Speed Assistance (ISA) systems has become a major concern for global road safety.
\end_layout

\begin_layout Standard
In some sense,
 an ISA system can be conceptualized as a robot.
 Its 
\begin_inset Quotes eld
\end_inset

body
\begin_inset Quotes erd
\end_inset

 is the vehicle,
 its 
\begin_inset Quotes eld
\end_inset

senses
\begin_inset Quotes erd
\end_inset

 are the suite of on-board sensors,
 its 
\begin_inset Quotes eld
\end_inset

thoughts
\begin_inset Quotes erd
\end_inset

 are the algorithms running on electronic control units and its 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 are the recommendation of speed set points communicated to the driver.
\end_layout

\begin_layout Standard
This setting represents a unique Human-Robot Collaboration (HRC) challenge.
 Including the human in the loop introduces a significant layer of uncertainty and non-stationarity.
 To be effective,
 the system cannot remain static and must be able to anticipate driver intent,
 consider behavioral variability and adapt to continuously changing driving contexts.
\end_layout

\begin_layout Standard
However,
 achieving this level of adaptation in safety-critical systems poses a dilemma:
 how can a controller learn and adapt in real-time without sacrificing the predictability and transparency required for safe control?
 This tension between adaptability and reliability leads to the core research question of this thesis:
 
\end_layout

\begin_layout Standard
\align center

\emph on
To what extent can cooperative local learning architectures,
 such as CELL,
 serve as a foundation for adaptive safe control strategies by exploiting model introspection to guide exploration and support reliable decision-making ?
\end_layout

\begin_layout Section*
Contributions
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Contributions}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this thesis the foundational challenges induced by this collaboration are explored through the prism of adaptive control with a continuously learning dynamic model.
 To address our research question,
 we explore a paradigm shift toward self-organizing multi-agent systems for supervised learning.
 We argue that the decomposition of complex tasks into local,
 specialized experts governed by cooperation rules,
 provides the necessary introspection capabilities to bridge the gap between online learning and adaptive safe control.
\end_layout

\begin_layout Standard
Throughout this research work,
 we demonstrate that the bottom-up social feedback and the local nature of these agents do more than just enable adaptation.
 They provide inherent introspection capabilities that can be linked to traditional interpretability and explainability literature.
 In addition to that,
 we show that these properties can be leveraged to enhance the optimization process in Model Predictive Control (MPC) to influence exploration or exploitation.
\end_layout

\begin_layout Standard
Our contributions are structured along two primary axes.
 On one hand,
 we contribute to the field of online learning by introducing the CELL (Context Ensemble Local Learning) formalism.
 It provides the theoretical foundations for local adaptations that allow for online learning in non-stationary environments from a stream of data.
 We propose three specific instantiations of CELL,
 namely oCELL,
 kCELL and sgpCELL.
 We demonstrate through experiments their ability to solve regression tasks while maintaining a meaningful spatialization of knowledge.
 The local nature and bottom-up social feedbacks of the learning procedure leads to the emergence of introspection properties that can be linked to the notions of interpretability and explainability 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
On the other hand,
 we provide contributions to the field of control with learned models.
 We investigate how the introspection capabilities of the CELL models can be leveraged to improve the reliability of autonomous systems.
 Specifically,
 we integrate the kCELL model into a MPC pipeline,
 where the model's introspection properties are used to guide data collection through uncertainty-aware exploration and to safeguard the system during exploitation by avoiding poorly modeled regions.
 In addition to that,
 we exploit the structure of local agents to develop a novel explainability approach that quantifies the influence of constraints on the final control decisions.
\end_layout

\begin_layout Section*
Outline of the Thesis
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Outline of the Thesis}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This thesis is structured as following (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Outline-of-the-Thesis"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 for the illustrated version):
\end_layout

\begin_layout Itemize
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Introduction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces the industrial and regulatory context of this thesis which originates from industrial requirements from AUMOVIO.
 It establishes the scientific abstraction process from a speed recommendation task to the more generalist challenge of adaptive control for non-stationary systems with unknown dynamics.
\end_layout

\begin_layout Itemize
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:State-of-the-Art"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 provides a comprehensive review of literature regarding online learning methods and control strategies.
 It positions the research works of this thesis at the intersection of these two fields by identifying the specific research gaps related to real-time adaptation.
\end_layout

\begin_layout Itemize
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces the CELL formalism and detail the iterative development of oCELL and kCELL algorithms.
 It also presents some experiments that demonstrate how local cooperation rules enable for learning and adaptation.
\end_layout

\begin_layout Itemize
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents the integration of kCELL into a MPC scheme.
 The mechanisms of uncertainty-aware exploration and exploitation are detailed.
 In addition to that,
 a novel explanation method for controllers is proposed to analyze the influence of constraints in the optimization process.
\end_layout

\begin_layout Itemize
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 exposes prospective works aimed at overcoming the curse of dimensionality and demonstrating the possibilities offered by the modularity of multi-agent systems for learning.
 We define sgpCELL,
 a new instantiation of CELL aiming at making Gaussian Processes scale to higher number of data points.
\end_layout

\begin_layout Itemize
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Industrial-use-Case"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 returns to the initial industrial motivation of this thesis discussing the applications of the developed methods for intelligent speed recommendation under an engineering point of view.
\end_layout

\begin_layout Itemize
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Conclusion"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 summarizes the contributions of this work and discusses the broader implications for adaptive control with learned models.
 It also highlights the future directions for research.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Intro générale => faire comme thibault
\end_layout

\begin_layout Plain Layout
1 paragraphe explicatif + contributions + plan de la thèse
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Itemize
Definition of Robot => modern robotics defines a robot by its ability to sense,
 think and act.
 Nowadays,
 some argue that the 
\begin_inset Quotes eld
\end_inset

communicate
\begin_inset Quotes erd
\end_inset

 functionality can be added to this list.
 
\begin_inset CommandInset citation
LatexCommand cite
key "siegel2003sense"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "baratta2023human"
literal "false"

\end_inset

 Review about human robot collaboration in industry.
\end_layout

\begin_deeper
\begin_layout Itemize
The paper identifies HRC as a foundational pillar of Industry 4.0 that is rapidly evolving into a core component of Industry 5.0.
 While Industry 4.0 focused on technological development,
 Industry 5.0 is expected to be more anthropocentric,
 placing the human operator back at the center of industrial processes.
\end_layout

\begin_layout Itemize
Robots are moving away from being simple tools to becoming partners with social skills => prerequisite for consumer market penetration
\end_layout

\begin_layout Itemize
Need for robots with advanced learning capabilities to achieve better synergy in complex and dynamic environments => autonomous adaptation and social adaptation to human partners
\end_layout

\begin_layout Itemize
However,
 the autonomous vehicles industry is not mature enough and human drivers will remain for a long time
\end_layout

\end_deeper
\begin_layout Itemize
In mobility,
 research around autonomous cars are developing rapidly.
 Some companies event proposing autonomous taxi services like Waymo in the US or Baidu in China.
\end_layout

\begin_layout Itemize
However those technologies are not mature enough at the current time.
 Some studies predcit 80-100% market saturation by the 2050s 
\begin_inset CommandInset citation
LatexCommand cite
key "lavasani2016market"
literal "false"

\end_inset

.
 So the human driver is here to stay for some time.
\end_layout

\begin_layout Itemize
So the development of Advanced Driver Assistance Systems (ADAS) are of public utility to improve road safety.
 => ACC,
 EBS,
 ISA,
 etc...
\end_layout

\begin_layout Itemize
Excesses and mismanagement of speed on the roads have been proven to be positively correlated to the occurence of accidents with injuries and fatalities 
\begin_inset CommandInset citation
LatexCommand citep
key "hauerSpeedSafety2009,elvikSpeedRoadSafety2005"
literal "false"

\end_inset

 => This motivates the development of devices like Intelligent Speed Assist to assist drivers to modulate their speed in order to stay safe.
\end_layout

\begin_layout Itemize
In some sense,
 Intelligent Speed Assist systems that recommend speed to the driver can be considered as robots whose body is the car and that are able to sense from the sensors,
 to think with on-board computation devices and to act by recommending a speed set point which is communicated to the driver on-board.
\end_layout

\begin_layout Itemize
This human robot collaboration setting poses several engineering and research challenges.
 Including the human in the loop adds a significant amount of uncertainties that need to be considered by the device to maximize its efficiency.
 Moreover,
 those systems should be able to adapt to significant behavior changes of users.
 This force the use continuously adapting systems.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/PhD_Structure.pdf
	lyxscale 30
	darkModeSensitive
	height 90theight%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Outline of the Thesis
\begin_inset CommandInset label
LatexCommand label
name "fig:Outline-of-the-Thesis"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Chapter
From Speed Recommendation to Adaptive Control
\begin_inset CommandInset label
LatexCommand label
name "chap:Introduction"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
This thesis is financed by an automotive company.
 Initially the goal was to work on intelligent speed recommendation.
\end_layout

\begin_layout Plain Layout
I structure my introduction this way:
\end_layout

\begin_layout Plain Layout
- 1.
 Background and Motivation
\end_layout

\begin_layout Plain Layout
- 2.
 Problem Statement
\end_layout

\begin_layout Plain Layout
- 3.
 Contributions
\end_layout

\begin_layout Plain Layout
In 1.
 I want to present why our company cares about speed recommendation.
 Then,
 in this part I also want to show a short review of literature to show that several speed management systems are considered in research:
\end_layout

\begin_layout Plain Layout
- Open Loop systems => that recommend speed to the driver via simple rule based approaches without considering any driver feedback => These approaches are more interpretable but limited in terms of objectives considered and do not enable personalization
\end_layout

\begin_layout Plain Layout
- Closed Loop systems => that control the speed of the vehicle in an autonomous way => performance but no consideration of the driver
\end_layout

\begin_layout Plain Layout
We notice that both approaches are inherently limited in their consideration of the driver.
 Indeed,
 in a speed recommendation context,
 the driver can delay,
 accept or refuse a speed recommendation set point.
 Moreover,
 as introducing the driver in the loop generates uncertainty because all human drivers are different,
 speed recommendations should be personalized to each one to better align with their driving style to maximize acceptance of recommendation set points.
 In addition to that,
 to maximize acceptance and the positive behavioral impact on driving,
 speed recommendation strategies should be interpretable to be able to justify their decisions to some extent to the driver.
\end_layout

\begin_layout Plain Layout
To bridge the gap between performant autonomous approaches and speed recommendation systems,
 we propose to tackle the speed recommendation problem as a control problem under the assumption that the vehicle-driver system is continuously modeled to account for the non-stationarity of the driver behavior over his life.
 Formulated in this way,
 the speed recommendation problem is reduced to an adaptive control problem with a learned model.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Before reaching a world in which every vehicle is autonomous without the need for a human driver,
 the future of mobility in the short and medium term lies in the development of effective collaboration between humans and machines.
 There is a need to move from theoretical collaboration to functional safety-critical control systems.
 Thus,
 it is necessary to address the inherent unpredictability and non-stationarity introduced by humans in the context of this collaboration.
\end_layout

\begin_layout Standard
This work was initiated within the industrial context of developing Intelligent Speed Assistance (ISA) for the automotive sector.
 The core scientific challenge of this task lies in the development of a recommendation system able to adapt continuously to the behavior of a human driver that evolves over time.
 This property is key in order to incorporate more intelligence into the speed recommendation process to move beyond static recommendation systems.
 This chapters demonstrates that by treating the vehicle and the driver as a whole dynamical non-stationary system,
 the speed recommendation problem can be abstracted into a problem of Adaptive Control with a Learned Model.
\end_layout

\begin_layout Standard
The objective of this chapter is to detail the reasoning that leads from the specific industrial case of speed recommendation to a more generalist scientific abstraction.
 The remainder of this chapter is structured as following.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Industrial-Context"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 exposes the industrial context of this thesis.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Background-and-Motivation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 presents a contextualization on speed management systems and their current limitations.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Statement"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows how a speed recommendation problem can be asbtracted into an adaptive control problem with a continuously learning model.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Research-Questions"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 exposes the research questions that frame the contributions of this thesis into the fields of 
\emph on
online learning
\emph default
 and 
\emph on
control with learned models
\emph default
.
\end_layout

\begin_layout Section
Industrial Context
\begin_inset CommandInset label
LatexCommand label
name "sec:Industrial-Context"

\end_inset


\end_layout

\begin_layout Standard
This doctoral research is conducted under a CIFRE funding in partnership with AUMOVIO,
 a global supplier specialized in automotive engineering and mobility solutions.
 AUMOVIO develops hardware,
 software and systems to make mobility safe,
 connected,
 autonomous and more intelligent.
 The strategic vision of the company is rooted in the Software-Defined Vehicle (SDV) philosophy.
 By decoupling hardware and software development cycles,
 the company aims to leverage its ecosystem of sensors,
 including radar and vision systems to build more intelligent and adaptive Advanced Driver Assistance Systems (ADAS).
\end_layout

\begin_layout Standard
Speed management remains the most significant lever for improving road safety.
 Excessive speed is a primary factor in serious accidents,
 affecting both driver's reaction time and the physical limits of the vehicle's braking.
 Research has consistently demonstrated a direct,
 non-linear relationship between speed and fatality risk.
 For instance,
 empirical crash data suggests that the probability of a fatality in a collision grows exponentially with speed,
 while the risk is about 10% at 40km/h,
 it surges to over 80% at 80km/h 
\begin_inset CommandInset citation
LatexCommand cite
key "hussain2019relationship"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Despite these risks,
 drivers often fail to maintain safe speeds due to environmental complexity,
 missing signage or adverse weather conditions.
 While passive safety systems such as airbags and seatbelts provide essential reactive protection,
 they are often insufficient to preserve physical integrity during high-speed impacts,
 making active speed management a priority for the automotive industry.
\end_layout

\begin_layout Standard
To address these challenges,
 the European Transport Safety Council (ETSC) recommends the deployment of Intelligent Speed Assistance (ISA) (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Illustration-of-ISA"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 This system is designed to inform the drivers about legal speed limits and encourage compliance.
 They argue that it has the potential to reduce road collisions by 30% and fatalities by 20% 
\begin_inset CommandInset citation
LatexCommand cite
key "etsc2017isa"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Beyond safety,
 speed management increasingly intersects with broader logistical and environmental goals,
 such as reducing fuel consumption,
 improving passenger comfort and optimizing estimated times of arrival.
 This has led to significant regulatory changes:
\end_layout

\begin_layout Itemize
As of July 6,
 2022:
 The European Union mandated that all new vehicle types must be equipped with ISA.
\end_layout

\begin_layout Itemize
As of July 7,
 2024:
 This requirement was extended to all new vehicles sold within the EU market 
\begin_inset CommandInset citation
LatexCommand cite
key "eu2019regulation"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
A critical aspect of the current European regulation 
\begin_inset CommandInset citation
LatexCommand cite
key "eu2021delegated"
literal "false"

\end_inset

 is the preservation of driver authority over the system.
 The ISA system must be overridable (e.g through a maintained pressure on the accelerator) and allow for manual deactivation during a journey.
 This ensures that the system acts as a collaborative assistant rather than an autonomous override.
\end_layout

\begin_layout Standard
For AUMOVIO,
 this creates a significant engineering and scientific challenge to make the most out of this kind of systems.
 The system must provide recommendations that are effective enough to ensure safety and efficiency,
 yet intuitive enough to be accepted by a human driver who retains ultimate control.
 As it is explored in subsequent sections,
 the success of such systems depends on the ability of the developed system to adapt to the inherent non-stationarity of human behavior under various driving contexts.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/etscISA.png
	lyxscale 35
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of what is Intelligent Speed Assistance from the european safety council 
\begin_inset CommandInset citation
LatexCommand cite
key "etsc2018isa"
literal "false"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-ISA"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Itemize
CIFRE financing by AUMOVIO
\end_layout

\begin_layout Itemize
AUMOVIO focuses on software defined vehicles philosophy separating hardware and software development cycles to build more intelligent Advanced Driver Assistance Systems (ADAS).
\end_layout

\begin_layout Itemize
AUMOVIO develops ADAS systems
\end_layout

\begin_layout Itemize
AUMOVIO provides
\end_layout

\begin_deeper
\begin_layout Itemize
various sensors (speed,
 chassis accelerometer)
\end_layout

\begin_layout Itemize
radar systems
\end_layout

\begin_layout Itemize
camera systems
\end_layout

\begin_layout Itemize
Control Units for heavy vehicles
\end_layout

\begin_layout Itemize
Electronic Brake Systems
\end_layout

\end_deeper
\begin_layout Itemize
Excessive speed is a major factor for serious car accidents.
 Speed impacts on both the driver ability to react to events and on the vehicle’s components (general structure,
 braking systems ...).
 There is a relationship between speed and road safety 
\begin_inset CommandInset citation
LatexCommand cite
key "elvik2004speed"
literal "false"

\end_inset

 and even small increases in speed can significantly raise the risk of fatal injuries 
\begin_inset CommandInset citation
LatexCommand cite
key "elvik2009power"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Drivers may not always be aware of the safe speed limit due to complex traffic situations,
 missing speed limit signs,
 or weather conditions.
 During a high-speed impact,
 security systems like airbag or security belt are not enough to protect physical integrity.
 As an example,
 fatality probability in car-to-car or car-to-pedestrian crashes is about 10% at 40 kph,
 50% at 60 kph,
 and over 80% at 80 kph,
 based on empirical models from crash data 
\begin_inset CommandInset citation
LatexCommand cite
key "hussain2019relationship"
literal "false"

\end_inset

 => exponential growth of fatality probability depending on speed.
\end_layout

\begin_layout Itemize
The European Transport Safety Council (ETSC) proposes a system to inform the driver on the legal speed.
 This system,
 named ISA (Intelligent Speed Assistance) is expected to reduce collisions by 30% and deaths by 20% 
\begin_inset CommandInset citation
LatexCommand cite
key "etsc2017isa"
literal "false"

\end_inset

.
 The purpose of Intelligent Speed Assist (ISA) systems is to help drivers acknowledge the best speed so they can be sure that their safety will be guaranteed.
 In addition to safety concerns,
 speed choice impacts other driving aspects such as fuel consumption,
 passengers’ comfort,
 estimated time of arrival,
 among others.
\end_layout

\begin_layout Itemize
As of July 6,
 2022,
 the EU mandated that all new types of vehicles must be equipped with ISA.
 As of July 7,
 2024,
 this requirement applies to all new vehicles sold in the EU.
 
\begin_inset CommandInset citation
LatexCommand cite
key "eu2019regulation"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
The system must be overridable (e.g.,
 by pressing the accelerator harder) and must allow for manual deactivation for the duration of a journey.
 However,
 it must automatically reset to "On" every time the vehicle is restarted.
 => the driver must keep ultimate authority + the driver need to be informed mearning the ISA system does not take over 
\begin_inset CommandInset citation
LatexCommand cite
key "eu2021delegated"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Background and Motivation
\begin_inset CommandInset label
LatexCommand label
name "sec:Background-and-Motivation"

\end_inset


\end_layout

\begin_layout Standard
Excesses and mismanagement of speed on the roads have been proven to be positively correlated to the occurence of accidents with injuries and fatalities 
\begin_inset CommandInset citation
LatexCommand citep
key "hauerSpeedSafety2009,elvikSpeedRoadSafety2005"
literal "false"

\end_inset

.
 Studies have shown that vehicle speed control devices like Intelligent Speed Assist (ISA) could significantly contribute to the reduction of road accidents 
\begin_inset CommandInset citation
LatexCommand cite
key "tate1997implementation"
literal "false"

\end_inset

.
 Moreover,
 better speed management can lead to significant reduction in energy consumption 
\begin_inset CommandInset citation
LatexCommand cite
key "xu2021overview"
literal "false"

\end_inset

 making this issue a strategic concern for individuals,
 but also for fleet management companies 
\begin_inset CommandInset citation
LatexCommand cite
key "atri2024operational"
literal "false"

\end_inset

.
 Consequently,
 developing speed management systems that help drivers maintain safe and efficient speeds is essential for public safety and for the sustainable development of the automotive industry.
\end_layout

\begin_layout Standard
From an industrial perspective,
 the main challenge for developing intelligent speed recommendation systems lies in designing a system that effectively influences vehicle speed while maintaining a high level of user acceptance,
 safety and energy efficiency.
 As the driver can chose to 
\emph on
accept
\emph default
,
 
\emph on
delay
\emph default
 or 
\emph on
refuse
\emph default
 a recommended speed set point,
 the effectivenes of such recommendation systems is largely determined by the underlying system architecture and how it interacts with an unpredictable human driver.
\end_layout

\begin_layout Standard
Research on speed management can be broken down into two distinct branches as displayed on Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Taxonomy-of-Vehicle"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 On one hand,
 
\emph on
Open-Loop
\emph default
 systems comprise mainly advisory systems that do not consider any form of feedback from the vehicle or driver responses to recommendation set points.
 On the other hand,
 
\emph on
Closed-Loop
\emph default
 systems solely consider feedbacks from the vehicle state,
 removing the driver from the execution loop,
 enabling for safety guarantees,
 stability and self correction.
 
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{
\backslash
columnwidth}{!}{%
\end_layout

\begin_layout Plain Layout


\backslash
begin{forest}
\end_layout

\begin_layout Plain Layout

for tree={
\end_layout

\begin_layout Plain Layout

	l sep=30pt
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

[Speed Management
\end_layout

\begin_layout Plain Layout

  [Open-Loop Systems
\end_layout

\begin_layout Plain Layout

    [Heuristic / Rules]
\end_layout

\begin_layout Plain Layout

    [Optimization]
\end_layout

\begin_layout Plain Layout

    [Offline Planning]
\end_layout

\begin_layout Plain Layout

    [Infrastructures]
\end_layout

\begin_layout Plain Layout

  ]
\end_layout

\begin_layout Plain Layout

  [Closed-Loop Systems
\end_layout

\begin_layout Plain Layout

	[Feedback Laws]
\end_layout

\begin_layout Plain Layout

    [Online Planning]
\end_layout

\begin_layout Plain Layout

	[Model-Free]
\end_layout

\begin_layout Plain Layout

    [HitL]
\end_layout

\begin_layout Plain Layout

  ]
\end_layout

\begin_layout Plain Layout

]
\end_layout

\begin_layout Plain Layout


\backslash
end{forest}%
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Taxonomy-of-Vehicle"

\end_inset

Taxonomy of Vehicle Speed Management approaches
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Open loop systems correspond to systems that do not consider feedback from the driver or vehicle current state.
 In the speed management literature,
 these works primarily focus on translating environment constraints such as traffic light timings 
\begin_inset CommandInset citation
LatexCommand cite
key "krauseTrafficLightAssistantDriven2012,alsabaanOptimizationFuelCost2013"
literal "false"

\end_inset

,
 weather conditions 
\begin_inset CommandInset citation
LatexCommand cite
key "galanisEnvironmentalBasedSpeedRecommendation2019"
literal "false"

\end_inset

 or road geometry 
\begin_inset CommandInset citation
LatexCommand cite
key "hazoorDevelopmentNovelIntelligent2021"
literal "false"

\end_inset

 into recommended speed profiles.
 Among the proposed approaches,
 some employ advanced optimization techniques like Pontryagin's Maximum Principle 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayVelocityProfileOptimization2017"
literal "false"

\end_inset

 to maximize energy efficiency.
 Others rely on passive infrastructure-based solutions ranging from physical speed enforcements via road bumps 
\begin_inset CommandInset citation
LatexCommand cite
key "salauVehicleSpeedControl2004"
literal "false"

\end_inset

 to visual stimulations 
\begin_inset CommandInset citation
LatexCommand cite
key "zhaoHowDoesMural2022"
literal "false"

\end_inset

 aiming at increasing speed awareness through environmental design.
\end_layout

\begin_layout Standard
However,
 whether digital or physical,
 these approaches share the same structural limitation because they assume that the recommendation set points are going to be followed perfectly and instantaneously.
 This assumption ignores the non-stationarity and variability of human-behavior.
 Consequently,
 without online feedback mechanisms to account for driver acceptance,
 the theoretical benefits of these optimizations are rarely fully realized in real-world conditions.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Rules / Heuristics
\end_layout

\begin_layout Itemize
Communication of speed recommendation with smartphone (work on HMIs),
 rule-based approach based on traffic lights state and distance to traffic light to avoid dead stops (for energy consumption ) 
\begin_inset CommandInset citation
LatexCommand cite
key "krauseTrafficLightAssistantDriven2012"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Rule-based recommendation approach based on fusion of several data sources (weather,
 road profile,
 ...) and comparison to nominal speed profiles (for safety and comfort).
 
\begin_inset CommandInset citation
LatexCommand cite
key "galanisEnvironmentalBasedSpeedRecommendation2019"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Rule based recommendation approach based on Stopping Distance and Available Sight Distance (mainly for safety,
 then for energy efficiency) 
\begin_inset CommandInset citation
LatexCommand cite
key "hazoorDevelopmentNovelIntelligent2021"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Optimization
\end_layout

\begin_layout Itemize
Optimization based recommendation approach to determine the optimal Speed Limit (Variable Speed Limit problem) that is transmitted to the driver via V2I which is also used for collecting data for computind the optimal speed (for safety).
 
\begin_inset CommandInset citation
LatexCommand cite
key "wuCombinedConnectedVehicles2020"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Communication of speed recommendation with V2X (V2V and V2I).
 Optimization (Heuristic provided too for real time) based approach based on traffic light schedule (for energy consumption).
 
\begin_inset CommandInset citation
LatexCommand cite
key "alsabaanOptimizationFuelCost2013"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Optimization based speed recommendation method based on analytical PMP solution relying on offline linearization of road profile beforehand.
 Method is fast because analytical solution and adaptive a bit online because some parameters are dynamic (for energy consumption then for legal speed limit enforcement).
 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayVelocityProfileOptimization2017"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Offline Planning
\end_layout

\begin_layout Itemize
PMP speed control approach for cruising (for energy) which handles gear shifts and alternates between acceleration and idling.
 
\begin_inset CommandInset citation
LatexCommand cite
key "shenFuelOptimalPeriodicControl2018"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Infrastructures
\end_layout

\begin_layout Itemize
Infrastructure-based approach using road bumps.
 Communication of speed limitations to driver with signs and physical enforcement (vibration too hard above design speed limit).
 Study about road bump characteristics to enforce speed limit efficiently (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "salauVehicleSpeedControl2004"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Infrastructure / Heuristic approach using discontinuous mural decorations on tunnel sidewalls at specific frequencies to provide visual stimulation.
 It induces a passive psychological signal that enhances driver's ability to estimate his true speed => improving speed awareness and alertness (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhaoHowDoesMural2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Works on closed-loop speed management systems are rooted in the development of autonomous vehicles.
 In a sense,
 they resolve the main limitation of open-loop systems by completely ignoring the driver and focusing solely on vehicle control.
 In this context,
 the system plays an active role in speed regulation by acting directly on low level vehicle's actuators (throttle / brake),
 thereby bypassing the uncertainties of driver acceptance.
 The related literature can be divided into two technical branches:
 
\emph on
model-based online planning
\emph default
 and 
\emph on
data-driven
\emph default
 approaches.
\end_layout

\begin_layout Standard
On the one hand,
 model-based online planning approaches rely extensively on physical models of the vehicle coupled with Model Predictive Control (MPC) 
\begin_inset CommandInset citation
LatexCommand cite
key "asadiPredictiveCruiseControl2010,kamalModelPredictiveControl2012,hanSafeEcoDrivingControl2018"
literal "false"

\end_inset

,
 Pontryagin's Maximum Principle (PMP) 
\begin_inset CommandInset citation
LatexCommand cite
key "maEcodriveExperimentRolling2019,ozatayAnalyticalSolutionMinimum2014"
literal "false"

\end_inset

 or Dynamic Programming (DP) 
\begin_inset CommandInset citation
LatexCommand cite
key "sunOptimalEcoDrivingControl2020"
literal "false"

\end_inset

.
 These approaches take into account changes in the environment by solving constrained optimization problems in real-time that mostly balance energy efficiency,
 safety and travel time.
 Since solving many optimization problems can be costly,
 research efforts have focused on finding analytical solutions 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayAnalyticalSolutionMinimum2014,malikopoulosOptimalControlSpeed2018,hanSafeEcoDrivingControl2018"
literal "false"

\end_inset

 or using discretization techniques 
\begin_inset CommandInset citation
LatexCommand cite
key "jinPowerBasedOptimalLongitudinal2016,jinEnergyoptimalSpeedControl2023"
literal "false"

\end_inset

 to solve the optimization problems.
 These methods offer rigorous safety and stability guarantees as they rely on pre-defined physical models coupled with control theory.
 However,
 the main limitation exposed for open-loops systems remains.
 The human driver is excluded from the control loop,
 resulting in mostly unusable systems when considering a human driver controlling the vehicle.
 Moreover,
 the capabilities of the resulting controllers depend on the accuracy of the physical models used.
 To ensure the controller operates in real-time,
 it is often necessary to make compromises between the complexity and accuracy of the physical model,
 making it difficult to handle large number of variables.
\end_layout

\begin_layout Standard
On the other hand,
 data-driven approaches have emerged to address the limitations of physical modeling,
 particularly for capturing complex,
 non-linear behaviors that are difficult to formalize analytically.
 By leveraging Reinforcement Learning,
 data-driven approaches also simplify multi-objective optimization through the design of reward functions that balance energy,
 safety and comfort 
\begin_inset CommandInset citation
LatexCommand cite
key "xuHierarchicalSpeedControl2022,duComfortableEnergyefficientSpeed2022,liuLongitudinalControlConnected2023"
literal "false"

\end_inset

.
 Various architectures are leveraged to handle speed control tasks such as DDPG for car-following and heavy vehicles 
\begin_inset CommandInset citation
LatexCommand cite
key "sunDDPGBasedDecisionMakingStrategy2020,moghaddam2024cooperative"
literal "false"

\end_inset

,
 PPO for traffic efficiency 
\begin_inset CommandInset citation
LatexCommand cite
key "xuHierarchicalSpeedControl2022,liuLongitudinalControlConnected2023,zhao2024adaptive"
literal "false"

\end_inset

 or SAC and DQN for safe speed control 
\begin_inset CommandInset citation
LatexCommand cite
key "jiangReinforcementLearningBased2022,kim2025reinforcement"
literal "false"

\end_inset

.
 These methods also allow to generate human-like profiles by learning directly from vast datasets of driving trajectories 
\begin_inset CommandInset citation
LatexCommand cite
key "zhangHumanlikeAutonomousVehicle2018,zhuHumanlikeAutonomousCarfollowing2018"
literal "false"

\end_inset

.
 However,
 these approaches rely on extensive and sample inefficient training,
 resulting in frozen policies that cannot adapt to the non-stationary nature of the road environment.
 Furthermore,
 compared to model-based methods,
 data-driven controllers lack formal safety and stability guarantees.
 They mostly rely on neural networks which make enforcing hard constraints difficult in safety-critical control systems due to the brittleness of their predictions outside the training distribution and to the lack of interpretability of their inner workings 
\begin_inset CommandInset citation
LatexCommand cite
key "zhang2020testing"
literal "false"

\end_inset

.
 Neural networks can be very efficient but are black-boxes that are hard to trust and validate.
 Specifically in industrial safety-critical use cases,
 the use of neural networks is mostly reduced to small certifiable networks,
 largely limiting the scalability potential 
\begin_inset CommandInset citation
LatexCommand cite
key "zhang2020testing"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Despite their differences,
 both model-based and data-driven closed-loop architectures share a common limitation:
 they prioritize the autonomy of the vehicle,
 denying the authority of the driver.
 Human-in-the-Loop (HitL) systems seek to address this limitation.
 These approaches attempt to reintegrate the driver into the control loop by treating human behavior as a dynamic variable of the problem rather than ignoring it.
 In this field,
 literature focuses on personalizing speed recommendations by monitoring physiological signals such as heart rate to model stress levels 
\begin_inset CommandInset citation
LatexCommand cite
key "maganaDesignSpeedAssistant2017"
literal "false"

\end_inset

,
 or by estimating driver acceptance scores to modulate the speed recommendation strategy 
\begin_inset CommandInset citation
LatexCommand cite
key "vyas2021drivebfr"
literal "false"

\end_inset

.
 Other works use simple online reinforcement learning strategies to steer the static cloud-based planning toward the driver's historical preferences 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayCloudBasedVelocityProfile2014"
literal "false"

\end_inset

 or use context-aware models to predict expert driver reactions on blind intersections 
\begin_inset CommandInset citation
LatexCommand cite
key "saitoContextawareDriverModel2021"
literal "false"

\end_inset

.
 These approaches represent significant steps toward driver consideration into closed-loop systems.
 However,
 they still remain limited by their offline nature.
 Most of these HitL systems are built upon static databases or pre-trained driver profiles that fail to account for the variability of human driving behaviors and for the non-stationarity of those behaviors that can evolve over time.
 In reality,
 a driver's response is not a fixed parameter but a non-stationary process influenced by physiological states,
 environmental context and long-term behavioral adaptation.
\end_layout

\begin_layout Standard
The research literature on speed management systems reveals a significant gap in the state-of-the-art.
 Open-loop advisory systems respect driver's autonomy but lack the consideration of feedbacks on driver's behavior to ensure high effectiveness through acceptance.
 Conversely,
 closed-loop autonomous systems offer high performance and theoretical guarantees but exclude the human driver from the execution loop.
 Finally,
 HitL methods that try to reinsert the driver in the loop through personalization and data-driven approaches,
 are limited by their inability to adapt in real-time to non-stationary behavior and learn continuously.
\end_layout

\begin_layout Standard
We identified a research gap in the lack of interpretable methods capable of learning continuously to adapt to the non-stationarity of the human driver behavior.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Statement"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows that from the identified research gap,
 the industrial speed recommendation problem can be abstracted to a more fundamental scientific challenge which is the control of complex non-stationary systems.
 By considering the vehicle-driver plant as a whole with unknown non-stationary dynamics,
 the problem is reformulated as a task of Adaptive Control with a Learned Model which represents the core focus of this thesis.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Feedback Laws
\end_layout

\begin_layout Itemize
Offline Policy computation via Stochastic Dynamic Programming from Markov Chains then online exploitation of the policy from feedback on terrain (for tradeoff between energy and travel speed) 
\begin_inset CommandInset citation
LatexCommand cite
key "kolmanovskyTerrainTrafficOptimized2010"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $H_{\infty}$
\end_inset

 control for eco-driving speed control for car following scenario (for energy and safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "chenComparativeStudyModel2021"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Online Planning
\end_layout

\begin_layout Itemize
Eco-driving speed control approach using Relaxed PMP from V2I data for planning and PID for speed trajectory tracking (for energy with safety constraints).
 Similar to MPC.
 
\begin_inset CommandInset citation
LatexCommand cite
key "maEcodriveExperimentRolling2019"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dynamic Programming speed control in space (not time) to make it suitable for online planning.
 Method to handle traffic lights intersections (for energy with safety constraints).
 
\begin_inset CommandInset citation
LatexCommand cite
key "sunOptimalEcoDrivingControl2020"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Predictive Cuise Control using MPC + Rules to determine target speed to handle traffic light intersections (for energy,
 travel time,
 safety,
 comfort).
 
\begin_inset CommandInset citation
LatexCommand cite
key "asadiPredictiveCruiseControl2010"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC for speed control with real time traffic information and V2V / V2I communication (vehicles / traffic signals).
 Mainly an advanced ACC system (for energy,
 safety,
 comfort) 
\begin_inset CommandInset citation
LatexCommand cite
key "kamalModelPredictiveControl2012"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC with analytical solution (for energy,
 safety and legality) for autonomous connected vehicle.
 
\begin_inset CommandInset citation
LatexCommand cite
key "hanSafeEcoDrivingControl2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC optimized with Mixed Integer Linear Programming (MILP) for speed control.
 Discretization of states to make the optimization faster in an online setting.
 Heavy offline computations to compute costs for discretized map.
 (for energy and safety).
\begin_inset CommandInset citation
LatexCommand cite
key "jinPowerBasedOptimalLongitudinal2016"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MPC optimized with MILP for speed control (for energy and safety) for buses.
 
\begin_inset CommandInset citation
LatexCommand cite
key "jinEnergyoptimalSpeedControl2023"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Analytical solution to PMP for speed control (intelligent cruise control) under some assumptions to allow for real time recomputations and embedding on board of the vehicle (for energy).
 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayAnalyticalSolutionMinimum2014"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Analytical solution for speed control based on Hamiltonian analysis to tackle approach of speed reduction zones or bottlenecks (for energy and safety).
 
\begin_inset CommandInset citation
LatexCommand cite
key "malikopoulosOptimalControlSpeed2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
MinMax on learned transition model to control the speed of the vehicle (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "messaoudiAgentbasedIntervehicleCooperative2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Model-based RL for eco-driving (for energy).
 Maintain domain knowledge of vehicle dynamics while maintaining model-free adaptability.
 
\begin_inset CommandInset citation
LatexCommand cite
key "leeModelBasedReinforcementLearning2020"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Model-Free
\end_layout

\begin_layout Itemize
Policy gradient RL for speed control for safe longitudinal car following (safety and efficiency).
 
\begin_inset CommandInset citation
LatexCommand cite
key "desjardinsCooperativeAdaptiveCruise2011"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
RL based dynamic speed limit control model for stochastic traffic networks (for energy consumption of vehicles in the network) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhuAccountingDynamicSpeed2014"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Human-like speed control through Deep Q Learning (for human-like behavior) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhangHumanlikeAutonomousVehicle2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Human-like speed control through DDPG for car following (for human-like behavior) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhuHumanlikeAutonomousCarfollowing2018"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Speed control through variant of PPO (for safety,
 energy and comfort) 
\begin_inset CommandInset citation
LatexCommand cite
key "xuHierarchicalSpeedControl2022"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Adaptive Cruising (speed control) of heavy vehicles through DDPG (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "sunDDPGBasedDecisionMakingStrategy2020"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Speed control on rough pavement through DDPG (for comfort and energy) 
\begin_inset CommandInset citation
LatexCommand cite
key "duComfortableEnergyefficientSpeed2022"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Longitudinal speed control through Soft-Actor-Critic (SAC) (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "jiangReinforcementLearningBased2022"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Speed control through PPO with reward shaping (for energy,
 safety,
 traffic efficiency) 
\begin_inset CommandInset citation
LatexCommand cite
key "liuLongitudinalControlConnected2023"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Variable Speed Limit throught DQN 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2025reinforcement"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Adaptive Cruise Control using safe Deep Reinforcement Learning (Projected Constrained Policy Optimization) (for safety and traffic efficiency) 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2024adaptive"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Adaptive Cruise Control suing DDPG (for safety,
 comfort,
 energy) 
\begin_inset CommandInset citation
LatexCommand cite
key "moghaddam2024cooperative"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Rule-based
\end_layout

\begin_layout Itemize
Rule based geometric approach to account for curve estimation and legal constraints (mainly for safety)
\begin_inset CommandInset citation
LatexCommand cite
key "gamezsernaDynamicSpeedAdaptation2017"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
Human-in-the-Loop
\end_layout

\begin_layout Itemize
Offline planning via Dynamic Programming (before trip) but a simple reinforcement learning module looks online to maximize acceptance by steering the recommendations towards an acceptable range (for energy) 
\begin_inset CommandInset citation
LatexCommand cite
key "ozatayCloudBasedVelocityProfile2014"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Offline computation via Dynamic Programming of optimal speed profile to then obtain local action rules for elementary road sections.
 These actions rules are chosen dynamically online to give speed recommendations (for energy with safety / legality constraints).
 
\begin_inset CommandInset citation
LatexCommand cite
key "jimenezRealtimeSpeedProfile2013"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Speed Recommendation approach that monitors state of vehicle and traffic signal's state to dynamically calculate speed recommendation set points to avoid red light dead stop based on remaining distance (for energy).
 Safety override to avoid danger.
 
\begin_inset CommandInset citation
LatexCommand cite
key "mahlerCellularCommunicationTraffic2017"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Particle Swarm Optimization and Deep Learning to estimate and recommend optimal average speed for upcoming road segments.
 Balancing predicted driver stress level estimated from heart rate and driving behavior against total trip time (for comfort) 
\begin_inset CommandInset citation
LatexCommand cite
key "maganaDesignSpeedAssistant2017"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Estimation of driver behavior score through a Mixture of Expert method (Neural Net),
 then optimize to find the speed recommendation looking for a normal behavior and reduced energy consumption => Claim to be personalized but learned offline 
\begin_inset CommandInset citation
LatexCommand cite
key "vyas2021drivebfr"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Context-aware driver model that uses multiple linear regression and database of near-miss incidents to determine recommended driving speed for blind intersections (for safety) 
\begin_inset CommandInset citation
LatexCommand cite
key "saitoContextawareDriverModel2021"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Problem Statement
\begin_inset CommandInset label
LatexCommand label
name "sec:Problem-Statement"

\end_inset


\end_layout

\begin_layout Standard
To address the gaps identified in the literature,
 this thesis proposes a shift in perspective.
 Rather than viewing speed recommendation as a static recommendation task,
 we treat it as a Human-Robot Collaboration (HRC) problem.
 For a robot to work effectively with humans,
 it requires anticipatory skills 
\begin_inset CommandInset citation
LatexCommand cite
key "dani2024human"
literal "false"

\end_inset

.
 The controller must infer the driver's intended motion and behavior to synchronize its recommendations effectively.
 By forecasting a human's response,
 the controller can provide set points that are complementary to the human's intent rather than being reactionary or disruptive.
\end_layout

\begin_layout Standard
Consequently,
 we propose to tackle the speed recommendation problem as a control problem under the assumption that the vehicle-driver plant is modeled as a whole.
 Given the non-stationarity and complexity of human behavior,
 this plant cannot be described by a static physical model.
 Instead,
 it is non-stationary and it must be continuously learned online from experience.
 Formulated in this way,
 the speed recommendation problem is abstracted into a problem of Adaptive Control that can be decomposed into two subproblems:
 
\series bold
online learning
\series default
 and
\series bold
 control with learned model
\series default
.
\end_layout

\begin_layout Standard
First,
 the online learning subproblem consists in the continuous generation of a predictive model 
\begin_inset Formula $\hat{f}:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$
\end_inset

 of the vehicle-driver dynamics from a stream of state-action pairs 
\begin_inset Formula $\left[s_{t},u_{t}\right]\in\mathbb{R}^{n}$
\end_inset

.
 Function 
\begin_inset Formula $\hat{f}$
\end_inset

 maps a states and actions to next state prediction such as
\begin_inset Formula 
\begin{equation}
\hat{f}\left(s_{t},u_{t}\right)=s_{t+1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Then,
 the control with learned model subproblem consists in the derivation of a control law that minimizes a cost function 
\begin_inset Formula $J$
\end_inset

 over a horizon 
\begin_inset Formula $H$
\end_inset

 based on the predictions of the learned model 
\begin_inset Formula $\hat{f}$
\end_inset

.
\end_layout

\begin_layout Standard
To solve these subproblems in a non-stationary environment,
 we argue for the necessity of using a local learning approach in which the feature space is partitioned into regions managed by local experts.
 This choice is driven by the requirements for interpretability and real-time adaptability.
 In the context of HRC,
 interpretability may not be a strict mathematical requirement for control but it is a functional necessity to ensure the certifiability of the system 
\begin_inset CommandInset citation
LatexCommand cite
key "kress2021formalizing"
literal "false"

\end_inset

 and to improve human trust toward the controller 
\begin_inset CommandInset citation
LatexCommand cite
key "anjomshoae2019explainable"
literal "false"

\end_inset

.
 For safety,
 industrial standards require that the internal models driving the system's decisions be traceable and verifiable.
 This task remains notoriously difficult with black-box global approximators like neural networks.
 For HRC,
 a human is more likely to accept and cooperate with a system whose behavior is predicatble and grounded in transparent logic.
\end_layout

\begin_layout Standard
Moreover,
 global approximation methods often struggle with the stability-plasticity dilemma 
\begin_inset CommandInset citation
LatexCommand cite
key "mermillod2013stability"
literal "false"

\end_inset

 where learning new behaviors leads to the forgetting of old ones.
 With local learning methods,
 the model can adapt to new behaviors locally and incrementally without corrupting knowledge stored in other regions.
 This allows the model to remain accurate across different driving contexts without requiring computationally heavy,
 and often impossible,
 offline training.
\end_layout

\begin_layout Standard
Local learning provides transparency by decomposing complex global dynamics into a set of specialized local models.
 Unlike global architectures where a single weight update can unpredictably affect the entire model,
 a local learning approach can ensure that any update stays local.
 This spatialization ensures that any prediction is traceable to a specific region of the feature space.
\end_layout

\begin_layout Standard
The long-term goal of this research is to enable efficient HRC,
 specifically in the automotive sector.
 This goal depends on the reliability of the underlying control architecture.
 Therefore,
 this thesis does not address the high-level social or psychological aspects of HRC but rather the foundational subproblems required to make the best out of HRC:
 local online learning and control with learned models.
 The following section details the research questions that shape the goal of this thesis.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Itemize
For successful human-robot collaboration,
 the robot must infer the human's intended motion to synchronize its actions.
 Anticipatory skills are required for robots to work effectively with humans.
 By forecasting a human's trajectory,
 the robot can set a control set point that is complementary to the human's current and future behavior rather than being reactionary or disruptive.
 
\begin_inset CommandInset citation
LatexCommand cite
key "dani2024human"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Thus,
 from the previous statement,
 we deduce that to bridge the gap between performant autonomous approaches and speed recommendation systems,
 the speed recommendation problem can be tackled as a control problem under the assumption that the vehicle-driver system is continuously modeled to account for the non-stationarity of the driver behavior.
 Formulated in this way,
 the speed recommendation problem can be abstracted into an adaptive control problem with a learned model.
\end_layout

\begin_layout Itemize
Therefore,
 the problem can be broken down into 2 subproblems:
 Online modeling and Control with learned model [HOW TO JUSTIFY THIS MPC ARCHITECTURE ?]
\end_layout

\begin_layout Itemize
[SHOULD WE INTRODUCE LOCAL LEARNING HERE OR WAIT FOR STATE OF THE ART ?]
\end_layout

\begin_layout Plain Layout
We notice that both approaches are inherently limited in their consideration of the driver.
 Indeed,
 in a speed recommendation context,
 the driver can delay,
 accept or refuse a speed recommendation set point.
 Moreover,
 as introducing the driver in the loop generates uncertainty because all human drivers are different,
 speed recommendations should be personalized to each one to better align with their driving style to maximize acceptance of recommendation set points.
 In addition to that,
 to maximize acceptance and the positive behavioral impact on driving,
 speed recommendation strategies should be interpretable to be able to justify their decisions to some extent to the driver.
\end_layout

\begin_layout Plain Layout
To bridge the gap between performant autonomous approaches and speed recommendation systems,
 we propose to tackle the speed recommendation problem as a control problem under the assumption that the vehicle-driver system is continuously modeled to account for the non-stationarity of the driver behavior over his life.
 Formulated in this way,
 the speed recommendation problem is reduced to an adaptive control problem with a learned model.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Research Questions
\begin_inset CommandInset label
LatexCommand label
name "sec:Research-Questions"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
RQ1:
 How can a learning architecture continuously model non-linear,
 non-stationary dynamics from an online stream of data while avoiding catastrophic forgetting ?
\end_layout

\begin_layout Plain Layout
RQ2:
 How can a learning-based controller adapt continuously to non-stationary dynamics while maintaining reliability and safety ?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The industrial and scientific challenges detailed in previous sections highlight a tension between the need for continuous adaptation and the requirement for reliability.
 To guide the works of this thesis and provide robust contributions,
 we investigate the two following research questions:
\end_layout

\begin_layout Itemize

\series bold
Online Learning of Non-Stationary Dynamics
\series default
:
 How can a learning architecture continuously model non-linear,
 non-stationary dynamics from an online stream of data while avoiding catastrophic forgetting?
\end_layout

\begin_layout Itemize

\series bold
Reliability in Learning-Based Control
\series default
:
 How can a learning-based controller adapt continuously to non-stationary dynamics while maintaining reliability and safety ?
\end_layout

\begin_layout Standard
The resolution of these questions lies at the intersection of two research fields.
 This thesis works borrow from both machine learning and control theory.
 The following chapter provides a comprehensive review of literature organized around these two research axes.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Float table
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="left" valignment="top" width="95col%">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intrinsic XAI through Self-Organization Analysis:
 Developed the oCELL algorithm and formalized a novel methodology leveraging agent self-organization structures to perform model introspection and infer underlying function properties for enhanced explainability and interpretability.
 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Empirical Evaluation of oCELL Performance:
 A low-dimensional comparative study demonstrating oCELL's competitive performance against SotA ensemble algorithms.
 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Non-Stationary Adaptation Capabilities:
 Development of the kCELL algorithm and a study demonstrating its ability to adapt to non-stationary dynamics for forward prediction,
 using introspection to analyze the system's behavior.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Integration for Constrained Optimal Control:
 Formalization of a novel coupling method to integrate the kCELL learning mechanism into traditional optimization solvers for solving complex constrained optimal control problems with learned models.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Introspection-Enhanced Safe Control:
 Proposal of a novel methodology that utilizes kCELL's intrinsic introspection capabilities to enhance the safety and performance of the solved constrained optimal control problems with learned models.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Constraint-Impact Explainability Method:
 Proposal of a novel XAI method leveraging kCELL's structure to quantify and explain the impact of constraints on optimization outcomes in safe control.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scalable CELL Spatialization:
 Proposal of Principal Component Analysis (PCA) as a novel technique to scale the CELL paradigm to higher-dimensional feature spaces,
 including a comparative evaluation.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scalable Gaussian Process Learning (SGP-CELL):
 Development of the SGP-CELL algorithm,
 a novel machine learning model that leverages the CELL paradigm to achieve online learning and scalability in Gaussian Processes (GP) with respect to the number of data points.
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of Contributions
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Chapter
State of the Art
\begin_inset CommandInset label
LatexCommand label
name "chap:State-of-the-Art"

\end_inset


\end_layout

\begin_layout Standard
For a robotic system to collaborate effectively with humans,
 it must possess anticipatory skills to adapt to the uncertainty and non-stationarity introduced by humans.
 Human-Robot Collaboration problems can be modeled as control problems in non-stationary environments that comprise humans in the loop.
 This perspective transforms the interaction challenge into a problem of Adaptive Control with a Learned Model.
 To solve this problem,
 the controller must be able to continuously learn the evolving behavior of the human collaborator while simultaneously ensure that its actions remain safe and reliable.
\end_layout

\begin_layout Standard
The objective of this chapter is to answer the research questions introduced in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Research-Questions"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 by reviewing the existing research landscape.
 This literature review is structured around two axes that mirror the subproblems tackled in this thesis.
 First,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Control-with-Learned-Models"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 traces the evolution of control theory from reactive regulation to predictive optimization with Model Predictive Control (MPC).
 Afterwards,
 the shift from the use of first-principle models toward learning-based methods such as Reinforcement Learning is analyzed.
 Following this,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Online-Machine-Learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 addresses the specific modeling requirements for a continuously learning model that could be integrated in a MPC setting.
 This section examines the evolution of learning paradigms from static batch data processing to online methods capable of handling data streams.
 The emphasis is put on the stability-plasticity dilemma inherent to global learners.
 We argue for the architectural advantages of local online learning for safety and more specifically for exploring mutli-agent systems for online supervised learning.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Positioning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 concludes on this chapter by positioning our works within these fields,
 highlighting the specific gaps that we intend to fill.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Enumerate

\series bold
From Global to Local Online Learning => 
\series default
Argue that while online learning exists,
 standard 
\begin_inset Quotes eld
\end_inset

global
\begin_inset Quotes erd
\end_inset

 methods (like Neural Networks) fail at handling non-stationarity,
 data-streams and are hardly interpretable => necessitating a local approach.
\end_layout

\begin_deeper
\begin_layout Enumerate
Foundations & Definitions => define what are data-streams,
 how we define interpretability and explainability,
 what is introspection in the context of the thesis.
\end_layout

\begin_layout Enumerate
Online Learning Paradigm
\end_layout

\end_deeper
\begin_layout Enumerate
Control with Learned Models
\end_layout

\begin_layout Plain Layout
What we want to show in SotA:
\end_layout

\begin_layout Itemize
Online Learning
\end_layout

\begin_deeper
\begin_layout Enumerate
What is Online Learning ?
 => define the shift from batch learning to online learning
\end_layout

\begin_layout Enumerate
Global models => global models for online learning suffer hard from the stability-plasticity problem + global models are often black boxes
\end_layout

\begin_layout Enumerate
local online learning can alleviate this issue by making localized updates => memory based learning (kNN),
 RBF networks,
 LWPR => those approaches can be very performant in control setting (ex:
 robotics) like LWPR but hard to scale => we develop a system that can be considered similar to LWPR (kCELL in chapter 3) => In LWPR the model and update logics are closely tied => LWPR lacks modularity => we conjecture that bringing more modularity via bottom up approaches could provide a strong alternative framework
\end_layout

\begin_layout Enumerate
multiagent local learning => SACL paradigm and filiation of our works
\end_layout

\begin_layout Enumerate
XAI and Uncertainty => define uncertainties and explainability / interpretability => for control with learned models the model needs to be trusted => thus need for transparent interpretable inner workings as well as uncertainty quantification.
\end_layout

\end_deeper
\begin_layout Itemize
Control with Learned models
\end_layout

\begin_deeper
\begin_layout Enumerate
What is MPC ?
 => define what is MPC => fitting architecture for using learned models (transition function to plan over horizon H)
\end_layout

\begin_layout Enumerate
Model Reliability
\end_layout

\begin_deeper
\begin_layout Enumerate
=> Problem in control with learned models is that learned models can be unreliable for out-of-distribution data => so we use models that are able to quantify uncertainty (epistemic uncertainty) like GPs but GPs are hard to scale to online learning (despite attempts) => need for a model that is uncertainty-aware / computationally efficient / local (ref section on Online Learning)
\end_layout

\begin_layout Enumerate
=> Problem of out-of-distribution predictions => reduction of this problem through exhaustive dataset => when no data available and no prior knowledge of dynamics there is a need for exploration => in some complex environment need for intelligent exploration strategies [WE DO NOT TACKLE SAFE EXPLORATION BUT INFORMATIVE EXPLORATION]
\end_layout

\begin_layout Enumerate
=> Problem of out-of-distribution predictions => impossible to always get exhaustive dataset and exploration is not always tractable => so need to avoid going into unknown states => in MPC avoid optimizing on garbage => conservative optimization based on epistemic uncertainty.
\end_layout

\end_deeper
\begin_layout Enumerate
Explainability in Constrained Optimization => even with perfect model,
 a constrained optimizer is often opaque => need for constraint influence analysis to explain to the end user why a specific suboptimal set point has been chosen.
\end_layout

\end_deeper
\begin_layout Plain Layout
Problem 1 => how to mention Gaussian Processes (and variants used to do online learning) (maybe GPs could only be mentionned in the control part ?) and Hoeffding Trees ?
\end_layout

\begin_layout Plain Layout
Problem 2 => where to put XAI talk in which we mention SHAP and LIME and define interpretability / explainability ?
 and aleatoric / epistemic uncertainties ?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
Notes
\end_layout

\begin_layout Itemize
How to justify using kCELL instead of LWPR ?
 because with linear regressions they are very similar systems
\end_layout

\begin_deeper
\begin_layout Itemize
LWPR is a top-down approach and CELL are bottom-up approaches
\end_layout

\begin_deeper
\begin_layout Itemize
bottom-up approaches are more modular => possibility to change the model easily or to mofidy the spatialization layer independently of the modeling layer for example
\end_layout

\begin_layout Itemize
bottom-up approaches are more flexible to evolving requirements
\end_layout

\begin_layout Itemize
bottom-up approaches allow for emergent behavior to happen
\end_layout

\end_deeper
\begin_layout Itemize
Social Feedback vs.
 Statistical Thresholds:
 in LWPR,
 a model is updated based on its own incremental error (like oCELL).
 In kCELL a leave one out contribution is used for updates.
 An agent survival depends on its value relative to its peers.
 It rewards agent for providing unique information.
\end_layout

\begin_layout Itemize
Short-Term baseline:
 use of a short-term linear predictor as a baseline for when there are 1 or 0 neighbors to create agent or update the only selected one.
 It treats the agent as an entity that must "justify its existence" against a simpler,
 generalist behavior.
 LWPR lacks this comparative competitive layer.
\end_layout

\begin_layout Itemize
We investigate social learning:
 a different learning paradigm to achieve similar results.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Plain Layout
To solve the LWPR 
\begin_inset Quotes eld
\end_inset

Problem
\begin_inset Quotes erd
\end_inset

:
\end_layout

\begin_layout Enumerate
in SotA (Chapter 2) => In LWPR the model and the update logic are closely tied => lacks modularity that could bring scalability possibilities => So we investigate more modular local learning approaches with CELL a bottom up theoretical ground for designing learning systems (contrary to LWPR which is top-down).
 In CELL that we present in Chapter 3,
 the social rules are agnostic of the internal model update logic => separation of spatialization layer and modeling layer.
 Furthermore,
 the social structure of the model allows to trace back decisions down to the negociation layer of agents.
\end_layout

\begin_layout Enumerate
in kCELL Section (Chapter 3) => kCELL is inherently different because the agents negociate with global baseline or other neighbors => this does not create an independant collection of models but a cooperative ensemble that provide a different kind of interpretability and explainability.
\end_layout

\begin_layout Enumerate
in Control (Chapter 4) => We justify the exploration and conservatism works not by claiming superior performance over existing local learners,
 but by demonstrating that the Social Introspection signals emergent from the CELL paradigm can be used and be reliable for closing the loop in constrained MPC.
 This validates that a bottom-up,
 agent-based learning approach can satisfy the requirements for real-time control and provide a modular alternative to traditional statistical methods.
\end_layout

\begin_layout Plain Layout
\begin_inset Note Note
status open

\begin_layout Plain Layout
LWPR can be seen as a special case of CELL => LWPR corresponds to a highly constrained instance of our learning paradigm in which agent selection,
 structural adaptation,
 and usefulness diagnostics are collapsed into a single distance-based mechanism.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Control with Learned Models
\begin_inset CommandInset label
LatexCommand label
name "sec:Control-with-Learned-Models"

\end_inset


\end_layout

\begin_layout Standard
The design of autonomous systems capable of seamless and efficient interactions with humans requires a control architecture that is both mathematically rigorous and adaptive.
 This section provides a review of literature about control theory aiming at answering the following question:
 
\end_layout

\begin_layout Standard
\align center

\emph on
How can a learning-based controller adapt continuously to non-stationary dynamics while maintaining reliability and safety?
\end_layout

\begin_layout Standard
First,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Control-Theory-Formalism"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces control theory to set up the formalism that will be used throughout the course of this thesis.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Reactive-to-Predictive"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 examines the shift from error-driven feedback laws such as Proportional-Integral-Derivatice (PID) controllers to optimization-based frameworks like Model Predictive Control (MPC).
 It highlights how the shift toward predictive optimization was driven by the need to handle multivariable processes and to respect hard physical and safety constraints in real-world settings.
 However,
 as systems move from controlled industrial settings to more complex and uncertain real-world environments,
 the use of static physics-based models represents a limitation.
 Consequently,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Physics-to-Learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 explores the integration of Machine Learning into the control loop.
 By analyzing the strengths and limitations of model-free Reinforcement Learning (RL) and Model-Based RL (MBRL),
 we argue that pure end-to-end data-driven approaches often compromise safety and reliability established by classical methods.
\end_layout

\begin_layout Subsection
Control Theory Formalism
\begin_inset CommandInset label
LatexCommand label
name "subsec:Control-Theory-Formalism"

\end_inset


\end_layout

\begin_layout Standard
Before dwelving into the reasoning towards learning-based control approaches,
 it is required to establish the formalism used in this thesis regarding control theory.
 Control Theory consists in the study of the means of influencing the behavior of a dynamical system to achieve a desired state or trajectory.
\end_layout

\begin_layout Standard
The evolution of a physical system over time is governed by its dynamics.
 In the context of digital control,
 a discrete-time representation can be considered where the state at the next time step is a function of the current state 
\begin_inset Formula $s_{t}$
\end_inset

 and the applied action 
\begin_inset Formula $u_{t}$
\end_inset

:
\begin_inset Formula 
\[
s_{t+1}=f\left(s_{t},u_{t}\right)
\]

\end_inset

where 
\begin_inset Formula $f:\mathcal{S}\times\mathcal{U}\mapsto\mathcal{S}$
\end_inset

 represents the transition function.
 In classical control theory,
 
\begin_inset Formula $f$
\end_inset

 is assumed to be a known,
 stationary first-principles model (e.g Newtonian mechanics).
 This interaction between the system and the controller is traditionally represented as a closed-loop system as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Control-Loop"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 One of the main challenge in Human-Robot Collaboration (HRC) is that 
\begin_inset Formula $f$
\end_inset

 often becomes non-stationary or partially unknown due to the stochastic nature of humans leading to model mismatch,
 i.e the model does not match the reality anymore.
\end_layout

\begin_layout Standard
The controller can perceive the states of the system and act on it through actuators.
 The boundaries of the states and actions are reffered to as the State Space (
\begin_inset Formula $\mathcal{S}$
\end_inset

) and the Action Space (
\begin_inset Formula $\mathcal{U}$
\end_inset

).
 The State Space (
\begin_inset Formula $\mathcal{S}$
\end_inset

) is a manifold that represents all possible configurations of the system (e.g joint angles,
 velocities,
 human positions).
 The state of the system at time 
\begin_inset Formula $t$
\end_inset

 is denoted as 
\begin_inset Formula $s_{t}\in\mathcal{S}$
\end_inset

.
 The Action Space (
\begin_inset Formula $\mathcal{U}$
\end_inset

) is the set of all possible control inputs (e.g.,
 motor torques,
 voltage).
 The action at time 
\begin_inset Formula $t$
\end_inset

 that is applied on the system is denoted as 
\begin_inset Formula $u_{t}\in\mathcal{U}$
\end_inset

.
\end_layout

\begin_layout Standard
The controller follows a goal that is mathematically described by the minimization of a cost function (or the maximization of a reward in Reinforcement Learning literature).
 For a given horizon 
\begin_inset Formula $T$
\end_inset

 (that could be equal to 
\begin_inset Formula $\infty$
\end_inset

),
 the objective is to minimize the cumulative cost 
\begin_inset Formula $J$
\end_inset


\begin_inset Formula 
\[
J=\sum_{k=0}^{T-1}l\left(s_{t+k},u_{t+k}\right)+l_{T}\left(s_{t+T}\right)
\]

\end_inset

where 
\begin_inset Formula $l$
\end_inset

 is the stage cost (e.g.
 tracking error or energy consumption) and 
\begin_inset Formula $l_{T}$
\end_inset

 is the terminal cost.
\end_layout

\begin_layout Standard
Depending on the task to be accomplished and its requirements,
 systems can be subject to physical and safety limits.
 These are expressed as algebraic inequalities such as 
\begin_inset Formula 
\[
g\left(s_{t},u_{t}\right)\leq0\,\,\text{or}\,\,h\left(s_{t},u_{t}\right)=0
\]

\end_inset

These constraints may represent hard limits (e.g.
 maximum current) or safety boundaries (e.g.
 speed limits,
 minimum distance to human operator).
\end_layout

\begin_layout Standard
Finally,
 the control law (also referred to as policy in RL literature) 
\begin_inset Formula $\pi$
\end_inset

 encapsulates the decision making logic such as 
\begin_inset Formula 
\[
u_{t}=\pi\left(s_{t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
These elements are part of the standard Optimal Control Problem,
 which serves as the template for the controllers discussed in the remainder of this chapter:
\begin_inset Formula 
\begin{align}
\min_{U}\,\,\, & \sum_{k=0}^{T-1}l\left(s_{t+k},u_{t+k}\right)+l_{T}\left(s_{t+T}\right)\\
\text{s.t.\,\,\, } & s_{t+1}=f\left(s_{t},u_{t}\right)\\
 & u_{t}\in\mathcal{U},\,\,s_{t}\in\mathcal{S}\\
 & g\left(s_{t},u_{t}\right)\leq0\\
 & h\left(s_{t},u_{t}\right)=0
\end{align}

\end_inset


\end_layout

\begin_layout Standard
To ground this formalism in an physical example,
 let's consider the classical pendulum problem.
 A mass 
\begin_inset Formula $m$
\end_inset

 is attached to a pivot by a rod of length 
\begin_inset Formula $L$
\end_inset

.
 The objective is to control its angular position 
\begin_inset Formula $\theta$
\end_inset

 using a motor that applies a torque 
\begin_inset Formula $\tau$
\end_inset

 at the pivot (c.f Figure).
 The components of the problem are the following
\end_layout

\begin_layout Itemize
State 
\begin_inset Formula $s_{t}$
\end_inset

:
 The states are represented by the angle and angular velocity 
\begin_inset Formula $s_{t}=\left[\theta,\dot{\theta}\right]^{\top}$
\end_inset


\end_layout

\begin_layout Itemize
Dynamics 
\begin_inset Formula $f$
\end_inset

:
 The dynamics are derived from Newton's Second Law,
 where the next state depends on gravity,
 damping and the applied torque 
\begin_inset Formula $u_{t}$
\end_inset


\end_layout

\begin_layout Itemize
Constraints 
\begin_inset Formula $\left(g,h\right)$
\end_inset

:
 An inequality constraint 
\begin_inset Formula $g$
\end_inset

 represents the physical limit of the torque that can be applied by the motor (
\begin_inset Formula $\left|u\right|\leq u_{\max}$
\end_inset

) while an equality constraint enforces the dynamics (
\begin_inset Formula $s_{t+1}=f\left(s_{t},u_{t}\right)$
\end_inset

)
\end_layout

\begin_layout Itemize
Objective 
\begin_inset Formula $J$
\end_inset

:
 The cost function penalizes the distance from a target angle (e.g reaching 
\begin_inset Formula $\theta=0$
\end_inset

) while minimizing the energy 
\begin_inset Formula $u^{2}$
\end_inset

 consumed by the motor.
\end_layout

\begin_layout Standard
This deterministic system provides a baseline where 
\begin_inset Formula $f$
\end_inset

 is perfectly known.
 However,
 even this simple system must satisfy some mathematical properties to be regulated effectively.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/pendulum.png
	lyxscale 30
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of the Pendulum Control Task
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The existence and quality of a solution to the OCP defined above depends on the following three properties of the system:
\end_layout

\begin_layout Itemize

\series bold
Controllability:
 
\series default
This property assesses whether the control input 
\begin_inset Formula $u$
\end_inset

 can drive the system from any initial state 
\begin_inset Formula $s_{0}$
\end_inset

 to any desired state 
\begin_inset Formula $s_{t}$
\end_inset

 within a finite time.
 In HRC,
 controllability is often shared.
\end_layout

\begin_layout Itemize

\series bold
Observability:
 
\series default
This corresponds to the ability to reconstruct the internal state 
\begin_inset Formula $s_{t}$
\end_inset

 from available measurements.
\end_layout

\begin_layout Itemize

\series bold
Stabilizability:
 
\series default
Even if a system is not fully controllable,
 it is considered stabilizable if all the unstable modes can be brought to a steady state using the available actions.
\end_layout

\begin_layout Standard
Beyond the internal properties of the system,
 the effectiveness of a controller is governed by the complexity of the considered system.
 This is formalized by Ashby's Law of Requisite Variety 
\begin_inset CommandInset citation
LatexCommand cite
key "ashby1956introduction"
literal "false"

\end_inset

,
 which states that for a controller to effectively manage a system,
 its internal variety,
 i.e the number of possible states,
 must be at least equal to the variety of the disturbances it aims to compensate for.
 In other words,
 a controller must be at least as complex as the task of keeping the goal satisfied.
\end_layout

\begin_layout Standard
Mathematically,
 from the perspective of information theory,
 if 
\begin_inset Formula $D$
\end_inset

 represents the system's disturbances and 
\begin_inset Formula $R$
\end_inset

 represents controller's actions,
 the entropy of the viable states of the system 
\begin_inset Formula $H\left(E\right)$
\end_inset

 is bounded such as
\begin_inset Formula 
\[
H\left(E\right)\geq H\left(D\right)-H\left(R\right)
\]

\end_inset


\end_layout

\begin_layout Standard
An extension of this theorem,
 the Conant-Ashby theorem 
\begin_inset CommandInset citation
LatexCommand cite
key "conant1970every"
literal "false"

\end_inset

,
 states that every good controller of a system must be a model of that system.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/Control_Loop.pdf
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of Closed-Loop Control
\begin_inset CommandInset label
LatexCommand label
name "fig:Control-Loop"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
From Reactive Regulation to Predictive Optimization
\begin_inset CommandInset label
LatexCommand label
name "subsec:Reactive-to-Predictive"

\end_inset


\end_layout

\begin_layout Standard
As shown in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Control-Theory-Formalism"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the objective of control theory is to build a controller that interacts with a system via actuators to achieve a desired behavior.
 For example,
 this behavior can be defined by a setpoint or a reference trajectory.
 Historically,
 one of the most common approach to designing controllers was the reactive feedback laws.
 The industry baseline for this type of controllers is the Proportional-Integral-Derivative (PID) controller 
\begin_inset CommandInset citation
LatexCommand cite
key "aastrom2001future,qin2003survey"
literal "false"

\end_inset

.
 These controllers are essentially error-driven,
 meaning that they generate an action in response to a deviation 
\begin_inset Formula $e_{t}$
\end_inset

 between the reference 
\begin_inset Formula $s_{\text{ref}}$
\end_inset

 and the measured output 
\begin_inset CommandInset citation
LatexCommand cite
key "aastrom2001future"
literal "false"

\end_inset

 (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PID-Control"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Their ease of implementation and effectiveness in various industrial contexts have made them a default controller to try setting up before attempting more sophisticated approaches.
 However,
 their effectiveness diminish in a non-stationary environement and they struggle with handling several inputs and outputs,
 limiting the possibilities in terms of manageable complexity and multiobjective consideration.
 In addition to that,
 this type of controller can be considered as myopic because the control action is issued in response to past or current errors,
 lacking the ability to anticipate future changes and avoid suboptimal well solutions that can bring the system into a state from which it is impossible to recover 
\begin_inset CommandInset citation
LatexCommand cite
key "aastrom2006advanced,qin2003survey"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/PID_ Control.pdf
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of PID Control
\begin_inset CommandInset label
LatexCommand label
name "fig:PID-Control"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Control tasks progressively shifted towards the management of more complex,
 multivariable processes.
 In this setting,
 purely reactive laws that do not consider a model of the environment,
 are inherently limited.
 To address these limitations,
 the field moved toward Optimal Control frameworks.
 Instead of simple gain tuning,
 the control laws are derived by minimizing a quadratic cost function that coordinates multiple inputs and outputs simultaneously 
\begin_inset CommandInset citation
LatexCommand cite
key "schwenzer2021review"
literal "false"

\end_inset

.
 For example Linear Quadratic Regulators (LQR) 
\begin_inset CommandInset citation
LatexCommand cite
key "kalman1964linear"
literal "false"

\end_inset

 (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:LQR-Control"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) provide an analytical solution to the optimal control problem by minimizing a quadratic cost function.
 It ensures stability for linear systems under the assumption of perfect model knowledge giving a control law such as
\begin_inset Formula 
\begin{equation}
u_{t}=Ks_{t}
\end{equation}

\end_inset

where 
\begin_inset Formula $u_{t}$
\end_inset

 is the action,
 
\begin_inset Formula $s_{t}$
\end_inset

 the current state of the system and 
\begin_inset Formula $K$
\end_inset

 the gain derived from Ricatti Equations.
\end_layout

\begin_layout Standard
To address the reality of noisy sensors and incomplete state information,
 the Linear Quadratic Gaussian (LQG) 
\begin_inset CommandInset citation
LatexCommand cite
key "kalman1961new"
literal "false"

\end_inset

 controller combines LQR with a Kalman Filter,
 providing an optimal solution under Gaussian white noise.
 However,
 LQG can lack robustness to model mismatches.
 To account for structural uncertainties and external disturbances,
 
\begin_inset Formula $H_{\infty}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "francis1987linear,zames2003feedback"
literal "false"

\end_inset

 controller was developed.
 It treats control design as a minimax optimization problem,
 aiming to minimize the worst-case gain,
 thereby ensuring robust performance with conservative behavior.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/LQR_Control.pdf
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of LQR Control
\begin_inset CommandInset label
LatexCommand label
name "fig:LQR-Control"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In classical LQR or 
\begin_inset Formula $H_{\infty}$
\end_inset

,
 the optimization has no hard constraint,
 that is to say,
 it assumes that actions have infinite range and that system states can fluctuate without bounds.
 In reality,
 physical systems are governed by hard limits.
 For example,
 an electric motor has a maximum torque it can produce before the current saturates or the windings overheat,
 and a chemical valve can only transition between fully open (100%) and fully closed (0%) positions.
 Beyond action constraints,
 the system states themselves often have safety or structural boundaries.
 For instance,
 a robotic arm must avoid joint limit angles to prevent mechanical damage and a drone must maintain a minimum altitude above the ground to avoid a collision.
 Ignoring these hard constraints can lead to catastrophic system failure when the control law demands an action that the hardware cannot execute.
 When these hard constraints are reached,
 classical feedback laws often require heuristics (e.g anti-windup strategies 
\begin_inset CommandInset citation
LatexCommand cite
key "galeani2009tutorial"
literal "false"

\end_inset

) which can compromise the stability and optimality of the system 
\begin_inset CommandInset citation
LatexCommand cite
key "qin2003survey"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Consequently,
 there is a clear necessity to transition from reactive regulation from static feedback gains toward predictive optimization.
 This paradigm transitions from pre-calculated control laws with the resolution of Optimal Control Problems (OCP) over a finite future horizon.
 By embedding a predictive model directly within a mathematical optimization framework (e.g Quadratic Programming),
 the controller gains the ability to proactively plan actions.
 In modern robotics and automotive systems,
 this is primarily achieved through Model Predictive Control (MPC) 
\begin_inset CommandInset citation
LatexCommand cite
key "GARCIA1989335"
literal "false"

\end_inset

,
 which is the main control framework for online constrained planning 
\begin_inset CommandInset citation
LatexCommand cite
key "bemporad2006model,schwenzer2021review"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Unlike global optimization methods,
 that solve the entire control problem beforehand and which are computationally prohibited for real-time use,
 MPC relies on a receding horizon.
 At each timestep,
 the controller solves a constrained optimization problem to find the optimal sequence of future actions based on a model of the system.
\end_layout

\begin_layout Standard
The core mechanism of MPC involves the repeated resolution of an OCP at each timestep 
\begin_inset Formula $t$
\end_inset

.
 Given the current state 
\begin_inset Formula $s_{0}$
\end_inset

,
 the controller seeks an optimal sequence of future actions 
\begin_inset Formula $U^{*}=\left\{ u_{0},\dots,u_{T-1}\right\} $
\end_inset

 that minimizes a cost function 
\begin_inset Formula $J$
\end_inset

 over a finite prediction horizon 
\begin_inset Formula $T$
\end_inset

 under some inequality or equality constraints
\begin_inset Formula 
\begin{align}
\min_{U}\,\,\, & J\left(s_{t:t+T},U\right)\\
\text{s.t.\,\,\, } & s_{t+1}=f\left(s_{t},u_{t}\right)\\
 & h\left(s_{t},u_{t}\right)\leq0\\
 & g\left(s_{t},u_{t}\right)=0
\end{align}

\end_inset

where 
\begin_inset Formula $f$
\end_inset

 denotes the internal predictive model,
 
\begin_inset Formula $h$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 represent respectively the inequality and equality constraints.
 
\end_layout

\begin_layout Standard
The defining feature of MPC is the receding-horizon principle:
 only the first control input 
\begin_inset Formula $u_{0}^{*}$
\end_inset

 is applied to the system.
 After that,
 the horizon is shifted forward and the optimization is repeated at the next timestep.
 This control loop is summarized in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:MPC-Control-Loop"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:MPC-Control"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the overall MPC architecture,
 highlighting the interactions between the environment,
 the predictive model and the optimization solver.
 
\end_layout

\begin_layout Standard
Historically,
 the model is derived from first-principles (e.g kinematic or dynamic equations of motion),
 assuming that the underlying physics are well-understood and stationary.
 To ensure that the resulting trajectory is physically feasible,
 constraints on both actions 
\begin_inset Formula $u_{t}$
\end_inset

 and states 
\begin_inset Formula $s_{t}$
\end_inset

 are embedded direclty into the optimization problem.
 
\end_layout

\begin_layout Standard
Two types of constraints can be distinguished:
 hard and soft constraints 
\begin_inset CommandInset citation
LatexCommand cite
key "domshlak2006hard"
literal "false"

\end_inset

.
 On the one hand,
 hard constraints correspond to conditions that must strictly be satisfied for a solution to be valid.
 On the other hand,
 a soft constraint is a constraint that can be violated but with an associated penalty,
 thereby preserving feasibility at the cost of degraded perfromance.
 When the safety or operational requirements allow for constraint relaxation,
 hard constraints can be reformulated as soft constraint by introducing penalty terms in the cost function.
 One of the most common approach consists in adding a regularization term 
\begin_inset Formula $\Omega$
\end_inset

 to the cost function such as 
\begin_inset Formula 
\begin{equation}
J_{\text{global}}\left(s_{t:t+T},U\right)=J\left(s_{t:t+T},U\right)+\lambda\Omega\left(s_{t:t+T},U\right)
\end{equation}

\end_inset

where 
\begin_inset Formula 
\begin{equation}
\Omega\left(s_{t:t+T},U\right)=\sum_{k=0}^{T}\omega\left(g\left(s_{t+k},u_{k}\right)\right)
\end{equation}

\end_inset

 is a non-negative penalty function satisfying 
\begin_inset Formula $\omega\left(g\right)=0$
\end_inset

 (with 
\begin_inset Formula $g$
\end_inset

 the constraint function) whenever the constraint is satisfied,
 and 
\begin_inset Formula $\lambda>0$
\end_inset

 weights the trade-off between optimality and constraint enforcement.
 The choice of both 
\begin_inset Formula $\lambda$
\end_inset

 and the penalty structure directly impacts constraint satisfaction,
 numerical conditioning and closed-loop behavior.
\end_layout

\begin_layout Standard
Solving such constrained optimization problems in real-time requires efficient numerical solvers.
 Depending on the structure of the dynamics,
 cost function,
 and constraints,
 different classes of solvers may be employed.
 For instance,
 BFGS 
\begin_inset CommandInset citation
LatexCommand cite
key "nocedal2006numerical"
literal "false"

\end_inset

 can be applied to general nonlinear dynamics and cost functions but do not natively enforce hard constraints without additional mechanisms.
 In contrast,
 solvers such as OSQP 
\begin_inset CommandInset citation
LatexCommand cite
key "stellato2020osqp"
literal "false"

\end_inset

 are designed to efficiently solve Quadratic Programs (QP) with linear constraints.
 When the considered dynamics are linear and the cost function 
\begin_inset Formula $J$
\end_inset

 is quadratic,
 the MPC problem can be formulated as a QP of the form
\begin_inset Formula 
\begin{align}
\min_{U}\,\,\, & \sum_{t=0}^{T-1}\left(s_{t}^{\top}Qs_{t}+q^{\top}s_{t}+u_{t}^{\top}Ru_{t}+r^{\top}u_{t}\right)\\
\text{s.t.\,\,\, } & s_{t+1}=As_{t}+Bu_{t}+c\\
 & h_{\text{lin}}\left(s_{t},u_{t}\right)\leq0\\
 & g_{\text{lin}}\left(s_{t},u_{t}\right)=0
\end{align}

\end_inset

where 
\begin_inset Formula $A$
\end_inset

,
 
\begin_inset Formula $B$
\end_inset

 and 
\begin_inset Formula $c$
\end_inset

 define the linear dynamics,
 
\begin_inset Formula $h_{\text{lin}}$
\end_inset

 and 
\begin_inset Formula $g_{\text{lin}}$
\end_inset

 represent the linear inequality and equality constraints,
 the matrices 
\begin_inset Formula $Q$
\end_inset

,
 
\begin_inset Formula $R$
\end_inset

 and vectors 
\begin_inset Formula $q$
\end_inset

,
 
\begin_inset Formula $r$
\end_inset

 defined the quadratic cost function.
 
\end_layout

\begin_layout Standard
Constraint satisfaction guarantees in MPC depend on both the problem formulation and the numerical solver used.
 Some solvers are designed to strictly enforce hard constraints upon convergence while others provide only approximate solutions that could result in small constraint violations due to early termination,
 numerical tolerances or limited iteration budgets imposed by real-time computation requirements 
\begin_inset CommandInset citation
LatexCommand cite
key "cannon2002efficient,hosseinzadeh2023robust"
literal "false"

\end_inset

.
 Moreover,
 enforcing hard constraints may lead to infeasible optimization problems in practice.
 For example,
 due to model mismatch,
 disturbances or state estimation errors.
 Such infeasibility must be handled explicitely at deployment time,
 either through constraint relaxation,
 solving a feasibility problem or leveraging fallback strategies 
\begin_inset CommandInset citation
LatexCommand cite
key "cannon2002efficient,hosseinzadeh2023robust"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Despite the effectiveness of MPCs in industry,
 these performance are contingent upon the accuracy of the used predictive model 
\begin_inset Formula $f$
\end_inset

.
 In complex real-world environments,
 particularly those involving Human-Robot Collaboration (HRC),
 deriving an analytical model that remains accurate over time is often infeasible.
 First-principle equations struggle to capture stochastic and non-stationary nature of human behavior,
 leading to a significant model mismatch that can compromise both performance and safety.
 To address these limitations,
 a shift toward Learning-Based Control is required.
 Data-driven methods offer new possibilities to either augment or replace traditional analytical models with architectures capable of adapting to more complex environments.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
DontPrintSemicolon
\end_layout

\begin_layout Plain Layout


\backslash
KwIn{Initial state $s_0$,
 prediction horizon $T$,
 system model $f$,
 cost function $J$,
 constraints $
\backslash
mathcal{C}$}
\end_layout

\begin_layout Plain Layout


\backslash
For{$t = 0,1,2
\backslash
dots$}{
\end_layout

\begin_layout Plain Layout

	Measure or estimate the current state $s_t$
\backslash
;
\end_layout

\begin_layout Plain Layout

	$U^* 
\backslash
gets 
\backslash
text{solve OCP for}
\backslash
left(s_t,
 T,
 f,
 
\backslash
mathcal{C},
 J
\backslash
right)$
\backslash
;
\end_layout

\begin_layout Plain Layout

	Apply first action $u_0^*$
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
MPC Control Loop
\begin_inset CommandInset label
LatexCommand label
name "alg:MPC-Control-Loop"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/Model_Predictive_Control.pdf
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
MPC Control Architecture
\begin_inset CommandInset label
LatexCommand label
name "fig:MPC-Control"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Why MPC for learning based control and not RL or Imitation Learning?
 => Why MPC with online models for adaptive control?
\end_layout

\begin_layout Plain Layout
PID (Least modeling effort) => LQR & 
\begin_inset Formula $H_{\infty}$
\end_inset

 & LQG (LQR + Kalman Filter) => MPC
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "francis1987linear"
literal "false"

\end_inset

 
\begin_inset Formula $H_{\infty}$
\end_inset

 paper
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "tinoco2025review"
literal "false"

\end_inset

 Review paper about advanced control methodologies.
 The PID controller acts as the baseline reactive regulator,
 effective for fixed industrial tasks but limited by its inability to handle the dynamic uncertainties of real-world environments like agriculture.
 In response to this rigidity,
 LQR and 
\begin_inset Formula $H_{\infty}$
\end_inset

 (Robust Control) emerge as more sophisticated mathematical frameworks that explicitly account for system stability and error minimization,
 yet they still struggle when the system parameters change unexpectedly.
 To bridge this gap,
 Adaptive Control and Sliding Mode Control introduce real-time flexibility—
the former by updating its own parameters on-the-fly and the latter by "forcing" the system to follow a desired path despite disturbances.
 However,
 as tasks require more foresight,
 Model Predictive Control (MPC) responds by shifting the focus from current error correction to future optimization,
 solving a moving-horizon problem to anticipate needs before they occur.
 Finally,
 to overcome the heavy dependency on precise mathematical models required by MPC and robust methods,
 Learning-Based Control (Fuzzy Logic and Neural Networks) represents the ultimate shift toward "intelligence," using data and heuristic rules to navigate complex,
 non-linear environments that are otherwise too difficult to model or predict through classical equations.
\end_layout

\begin_deeper
\begin_layout Itemize
Late Correction:
 Traditional reactive controllers like the standard PID generate commands only after receiving feedback,
 meaning they react to errors that have already occurred.
\end_layout

\begin_layout Itemize
Dependency on Static Environments:
 These regulators are suitable for industrial scenarios where variables (weights,
 positions) are known and fixed,
 but they fail in dynamic or uncertain environments like agriculture.
\end_layout

\begin_layout Itemize
Predictive Optimization:
 Unlike reactive laws that act only on past errors,
 proactive methods like Model Predictive Control (MPC) define control laws by predicting the future output of the system and solving an optimization problem.
\end_layout

\begin_layout Itemize
Online Adaptability:
 There is a strong research trend toward Reinforcement Learning,
 which provides "strong online adaptability and self-learning capabilities".
 This allows the robot to proactively adjust its behavior when the environment changes rather than just reacting to a setpoint.
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "qin2003survey"
literal "false"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The PID Family:
 Single-Input Single-Output (SISO) Regulation => The earliest "family" of feedback laws is the PID (Proportional-Integral-Derivative) controller.
\end_layout

\begin_deeper
\begin_layout Itemize
The Logic:
 It is a purely reactive,
 error-driven feedback law.
 It looks at the difference between the setpoint and the current output and reacts.
\end_layout

\begin_layout Itemize
The Limitation:
 While excellent for simple loops,
 PID cannot "see" other variables => great complexification when trying to handle multiple inputs and outputs.
 In a complex plant,
 changing one PID loop often upsets another.
 To handle constraints,
 engineers had to add "overrides" and "select logic," making the system a fragile "jungle" of interconnected loops that was difficult to manage.
\end_layout

\end_deeper
\begin_layout Itemize
The LQG/LQR Family:
 Multivariable State-Space Control => In the 1960s,
 the LQG (Linear Quadratic Gaussian) and LQR (Linear Quadratic Regulator) family emerged as a more sophisticated feedback law.
\end_layout

\begin_deeper
\begin_layout Itemize
The Logic:
 It uses a mathematical model of the process to coordinate multiple inputs and outputs simultaneously.
 It minimizes a quadratic "cost function" to find the optimal feedback gains.
 The Kalman Filter is often used here to estimate internal states that cannot be measured directly.
\end_layout

\begin_layout Itemize
The Limitation:
 As the paper notes,
 this family is "unconstrained." It assumes the process can move infinitely in any direction.
 In reality,
 valves can only open so far,
 and pressures can only go so high.
 Without explicit constraint handling,
 these optimal laws could easily drive a plant into an unsafe or shut-down state.
\end_layout

\end_deeper
\begin_layout Itemize
The Predictor-Corrector Family:
 Early Predictive Control (IDCOM/DMC) => In the 1970s,
 industry began moving away from pure feedback gain matrices toward Predictive Control.
\end_layout

\begin_deeper
\begin_layout Itemize
The Logic:
 This family (like IDCOM and DMC) introduced the "Moving Horizon" concept.
 Instead of just reacting to the current state,
 it uses a model to predict the future plant output over a "prediction horizon."
\end_layout

\begin_layout Itemize
The Transition:
 It calculates a set of future moves,
 but—
to ensure robustness—
it only implements the first move and then "corrects" its prediction at the next step using new feedback.
 This is known as a Receding Horizon strategy.
\end_layout

\end_deeper
\begin_layout Itemize
Modern MPC:
 The Synthesis of Optimization and Constraints => The final step in the flow is the modern MPC architecture,
 which synthesizes the best of the previous families.
\end_layout

\begin_deeper
\begin_layout Itemize
The Logic:
 It takes the multivariable coordination of LQR,
 the state estimation of the Kalman Filter,
 and the future-looking nature of DMC,
 but adds Mathematical Programming (Quadratic Programming).
\end_layout

\begin_layout Itemize
The Result:
 It doesn't just calculate a feedback law;
 it solves an optimization problem in real-time at every single time step.
 This allows it to honor hard constraints on valves and process limits proactively.
 It has moved from being a simple "law" (like PID) to a "real-time strategy" that anticipates and prevents problems before they occur.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "schwenzer2021review"
literal "false"

\end_inset

 Model Predictive Control (MPC) represents a paradigm shift from classical "reactive" feedback laws—
like PID,
 which relies on past error,
 or LQR,
 which provides a static optimal law—
to a "proactive" optimization strategy that utilizes a mathematical model to anticipate future system behavior.
 By solving a constrained optimization problem over a finite,
 receding horizon at every time step,
 MPC allows engineers to directly incorporate physical constraints and multi-variable interactions that traditional controllers struggle to handle.
 Ultimately,
 this evolution moves the engineering focus away from abstract gain tuning and toward process modeling,
 enabling the control of highly complex,
 nonlinear systems across diverse industries.
\end_layout

\begin_deeper
\begin_layout Itemize
Significant limitations and challenges associated with Model Predictive Control (MPC) => A primary drawback is its high computational burden,
 as it requires solving complex optimization problems in real-time at every time step,
 which remains a major factor in controller design.
 Additionally,
 MPC is heavily dependent on model accuracy;
 inaccuracies in the process model directly affect the quality of output predictions and can complicate robustness analysis.
 Ensuring mathematical stability and feasibility—
especially for non-linear systems or those with short prediction horizons—
is also extremely difficult and often requires complex artificial measures like terminal cost constraints or slack variables to prevent the optimization from failing.
 Finally,
 while MPC excels at handling constraints,
 its sophisticated design often results in a more complex implementation compared to the well-proven and simpler "reactive" classical controllers like PID.
\end_layout

\begin_layout Itemize
Use of MPC with learned models =>
\end_layout

\begin_deeper
\begin_layout Itemize
1.
 Structure for Safe Learning => MPC provides a rigorous mathematical framework that can "wrap" around learned components to ensure safety.
 For example,
 researchers use Gaussian process modeling to learn system dynamics while establishing confidence intervals that define safe trajectories.
 This allows the system to learn from data without violating critical physical boundaries,
 a major advantage over pure "black-box" learning methods.
\end_layout

\begin_layout Itemize
2.
 Solving the "Curse of Dimensionality" => One of the primary arguments for learning-based MPC is its ability to overcome the traditional computational burden of real-time optimization.
\end_layout

\begin_deeper
\begin_layout Itemize
Approximating Explicit MPC:
 Neural Networks (NNs) are used to learn the "solution space" of an explicit MPC,
 effectively turning a complex optimization into a fast function evaluation.
\end_layout

\begin_layout Itemize
Efficiency Gains:
 The paper notes that this approach can speed up computation by factors of 65 to 200,
 making advanced control feasible for high-speed applications like robotics and power converters.
\end_layout

\end_deeper
\begin_layout Itemize
3.
 Bridging Data and Physics => MPC is fundamentally based on models,
 which allows it to naturally incorporate different types of knowledge.
\end_layout

\begin_deeper
\begin_layout Itemize
Hybrid Modeling:
 It allows for a "best of both worlds" approach where well-known physical dynamics are handled by traditional equations,
 while complex,
 hard-to-model uncertainties (like friction or wind) are learned from data.
\end_layout

\begin_layout Itemize
Intuitive Integration:
 Because MPC's parameters (like the cost function and constraints) have physical meaning,
 engineers can more easily interpret and tune the "learned" behavior compared to other architectures.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Historical flow described in the paper:
\end_layout

\begin_deeper
\begin_layout Itemize
The Classical Feedback Era:
 PID Control
\end_layout

\begin_layout Itemize
Mechanism:
 PID controllers are "reactive",
 calculating the manipulated variable $u$ based on the deviation ($e=r-y$) between a reference and measured variable.
\end_layout

\begin_deeper
\begin_layout Itemize
Perspective:
 They only consider past and current system behavior.
\end_layout

\begin_layout Itemize
Limitations:
 While PID is highly effective for approximately 90% of control problems,
 it is difficult to parameterize for nonlinear or time-variant systems.
 It is fundamentally limited by system dynamics and cannot handle technical limitations of actuators (constraints) without heuristic,
 hard-to-maintain solutions
\end_layout

\end_deeper
\begin_layout Itemize
The Move Toward Optimality:
 LQR and LQG
\end_layout

\begin_deeper
\begin_layout Itemize
Evolutionary Link:
 The transition toward MPC was bridged by the study of infinite horizon control problems,
 such as Linear Quadratic Gaussian (LQG) control.
\end_layout

\begin_layout Itemize
Advancement:
 These methods introduced the concept of a cost function to achieve "optimal" control behavior.
\end_layout

\begin_layout Itemize
The Constraint Hurdle:
 LQG/LQR provides global asymptotic stability for linear systems,
 but these classical optimal methods do not directly consider hard constraints (like physical limits of a valve).
\end_layout

\end_deeper
\begin_layout Itemize
3.
 The Robustness Shift:
 
\begin_inset Formula $H_{\infty}$
\end_inset

 and Uncertainty
\end_layout

\begin_deeper
\begin_layout Itemize
Evolutionary Link:
 As optimal control grew more complex,
 research shifted toward robustness—
ensuring performance is met despite model variations or uncertainties.
\end_layout

\begin_layout Itemize
Mechanism (
\begin_inset Formula $H_{\infty}$
\end_inset

 connection):
 The paper highlights that minimizing the maximum error (
\begin_inset Formula $L_{\infty}$
\end_inset

-norm) in a prediction horizon is a strategy used to favor robustness.
\end_layout

\begin_layout Itemize
Trade-off:
 This approach leads to more conservative control actions,
 preventing the controller from making full use of the plant's potential.
\end_layout

\end_deeper
\begin_layout Itemize
The Predictive Era:
 Model Predictive Control (MPC) => MPC emerged by combining the optimality of earlier methods with the ability to handle constraints and predict the future.
\end_layout

\begin_deeper
\begin_layout Itemize
From Infinite to Receding Horizon:
 While LQR/LQG typically assumed an infinite horizon,
 MPC uses a "receding horizon".
 It solves a finite-term optimization at each time step but only implements the first value of the resulting trajectory.
\end_layout

\begin_layout Itemize
Implicit vs.
 Explicit Laws:
 Unlike PID or LQR,
 which use precomputed (explicit) control laws,
 MPC determines the control law implicitly by repeatedly solving a constrained optimization problem in real-time.
\end_layout

\begin_layout Itemize
Direct Constraint Handling:
 MPC's greatest leap over previous families is its ability to directly incorporate hard input and soft output constraints into the mathematical optimization.
\end_layout

\begin_layout Itemize
Model Flexibility:
 While early MPC (like Dynamic Matrix Control) was restricted to linear models,
 modern MPC can utilize nonlinear,
 impulse response (IRF),
 or state-space models.
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "bemporad2006model"
literal "false"

\end_inset

 MPC uses a dynamical model of an open-loop process to construct an optimization problem.
 It solves this problem at each sampling time to find an optimal sequence of future control moves,
 applying only the first move and repeating the process at the next step (receding-horizon mechanism).
\end_layout

\begin_deeper
\begin_layout Itemize
Systematic Constraint Handling:
 MPC is uniquely capable of achieving performance while explicitly respecting restrictions on input and output variables (such as actuator saturation or safety ranges).
 Traditional methods often require "a-posteriori patches" to handle these limits,
 whereas MPC embeds them directly into the design flow.
\end_layout

\begin_layout Itemize
Multivariable Complexity:
 They are used to control highly complex multivariable processes where command inputs,
 internal states,
 and measured outputs are deeply interconnected.
\end_layout

\begin_layout Itemize
Near-Optimal Performance:
 These methods provide near-optimal performance by translating technical specifications (weights on tracking errors and actuator efforts) into a mathematical cost function that is minimized.
\end_layout

\begin_layout Itemize
Future Anticipation (Preview):
 Optimization allows the controller to "look ahead" and explicitly account for future reference signals or measured disturbances,
 automatically resulting in feedforward action.
\end_layout

\begin_layout Itemize
Hybrid Dynamics:
 In response to systems involving logic,
 switching,
 and on/off inputs,
 optimization-based hybrid MPC provides a systematic way to synthesize controllers that would otherwise be impossible to design using heuristic "trial and error" procedures (through MILP for example).
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "tinoco2025review"
literal "false"

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Online Adaptability:
 There is a strong research trend toward Reinforcement Learning,
 which provides "strong online adaptability and self-learning capabilities".
 This allows the robot to proactively adjust its behavior when the environment changes rather than just reacting to a setpoint.
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

 Review of literature => From Learning-based control to safe reinforcement learning
\end_layout

\begin_deeper
\begin_layout Itemize
How is machine learning used in control ?
\end_layout

\begin_deeper
\begin_layout Itemize
Learning Uncertain Dynamics:
 Data is used to learn unknown or uncertain parts of a robot's dynamics.
 This information is then integrated into standard control frameworks (like adaptive or robust control) to improve performance while maintaining safety guarantees.
\end_layout

\begin_layout Itemize
Encouraging Safety and Robustness in RL:
 In scenarios where a prior model is unavailable,
 reinforcement learning (RL) uses data to "encourage" safety.
 This is often done by penalizing dangerous actions or using risk-averse strategies.
\end_layout

\begin_layout Itemize
Online Adaptation:
 Data is used in real-time to adjust controller parameters,
 dynamics models,
 or constraint functions during operation.
\end_layout

\begin_layout Itemize
Offline Learning:
 Data from previous trials is recorded and used to update models in a batch manner between operations.
\end_layout

\end_deeper
\begin_layout Itemize
Why using learning in control ?
 => related to deployment in real world complex environments
\end_layout

\begin_deeper
\begin_layout Itemize
Handling Uncertainty and unknown dynamics a priori:
 Traditional control relies on precise models,
 but real-world dynamics are often partially unknown (e.g.,
 the mass of a payload).
 Learning allows systems to reduce conservatism by "knowing what is not known".
\end_layout

\begin_layout Itemize
Adaptability to Complex Environments:
 Robots frequently operate in environments that are not well-characterized or include other agents with unknown plans.
 Machine learning enables robots to adapt to these new contexts.
\end_layout

\begin_layout Itemize
Improving Performance:
 By extracting patterns from large volumes of data,
 learning-based methods can safely improve a robot's performance beyond what is possible with a fixed,
 prior model.
\end_layout

\end_deeper
\begin_layout Itemize
Challenges of learned models in control
\end_layout

\begin_deeper
\begin_layout Itemize
1.
 Safety and Formal Guarantees
\end_layout

\begin_deeper
\begin_layout Itemize
Safety During Learning:
 A primary challenge is ensuring the robot's safety during the learning process itself,
 not just for the final optimized policy.
 This is critical to avoid costly hardware failures.
\end_layout

\begin_layout Itemize
Providing Hard Guarantees:
 While traditional control provides strong guarantees within specific contexts,
 data-driven approaches like Reinforcement Learning (RL) struggle to provide formal safety and stability guarantees.
\end_layout

\begin_layout Itemize
Difficulty in Verification:
 Safety guarantees often rely on assumptions (like Lipschitz continuity) that are difficult to verify before a robot begins operation.
\end_layout

\end_deeper
\begin_layout Itemize
2.
 Generalization and Data Issues
\end_layout

\begin_deeper
\begin_layout Itemize
Distribution Shifts:
 Learned models may struggle when they encounter data that differs from their training distribution (distribution shifts).
\end_layout

\begin_layout Itemize
Generalization vs.
 Safety:
 While data-driven approaches generalize well to new contexts,
 they often do so at the expense of formal guarantees.
\end_layout

\begin_layout Itemize
Data Sparsity:
 In real-world robotics,
 data can be sparse,
 making it difficult for expressive models to extract accurate patterns efficiently.
\end_layout

\end_deeper
\begin_layout Itemize
3.
 Computational and Scaling Hurdles
\end_layout

\begin_deeper
\begin_layout Itemize
Computational Complexity:
 Applying deep RL to constrained problems is computationally expensive,
 particularly for the off-policy evaluation of trajectory-level constraints.
\end_layout

\begin_layout Itemize
Optimality-Complexity Trade-off:
 There is a constant trade-off between achieving the most "optimal" performance and the computational complexity required for real-time implementations in a control loop.
\end_layout

\begin_layout Itemize
Scalability:
 Many current safe learning methods have only been demonstrated on small "toy" problems;
 scaling them to high-dimensional,
 real-world robotic systems is non-trivial.
\end_layout

\end_deeper
\begin_layout Itemize
4.
 Modeling and Measurement Uncertainties
\end_layout

\begin_deeper
\begin_layout Itemize
Imperfect State Measurements:
 Most approaches assume direct access to perfect state measurements,
 but in reality,
 sensor noise and inaccurate state estimation (e.g.,
 using images as measurements) introduce errors that the control system must account for.
\end_layout

\begin_layout Itemize
Black-Box Nature:
 The interpretability of "black-box" models like Deep Neural Networks (DNNs) remains an open challenge for safe closed-loop operation.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Safest models ?
 => Probabilistic Models (High Confidence Safety) => Models that provide a measure of uncertainty are considered safer for control because they allow for "cautious adaptation".
\end_layout

\begin_deeper
\begin_layout Itemize
Gaussian Processes (GPs):
 These are frequently highlighted as a safer choice for learning unknown dynamics.
 Because they specify a distribution over functions,
 they provide a built-in confidence metric.
 Controllers can be designed to rely on the learned model only when confidence is high,
 allowing for Safety Level III (Hard Guarantees) through stochastic stability analysis.
\end_layout

\begin_layout Itemize
Bayesian Linear Regression (BLR):
 Similar to GPs,
 BLR is a probabilistic model that allows the controller to account for uncertainty in its predictions.
\end_layout

\end_deeper
\end_deeper
\end_inset


\end_layout

\begin_layout Subsection
From Physics-Based to Learning-Based Control
\begin_inset CommandInset label
LatexCommand label
name "subsec:Physics-to-Learning"

\end_inset


\end_layout

\begin_layout Standard
The effectiveness of Model Prective Control (MPC) described in previous section is contingent upon the fidelity of the internal predictive model 
\begin_inset Formula $f$
\end_inset

.
 Historically,
 these models have been derived from first-principles such as kinematic or dynamic equations of motion.
 Such analytical models are highly effective for well-characterized physical systems but they reach their limits in highly complex non-stationary environments,
 especially in Human-Robot Collaboration settings where accurate first-principle models are either computationally too heavy or simply do not exist for describing phenomenon like human behavior.
\end_layout

\begin_layout Standard
To address this issue,
 early research focused on Hybrid MPC leveraging physics-informed learning.
 In this paradigm,
 a low-fidelity physics model (e.g linear model) is used as a baseline and is paired with a statistical learning model such as a Gaussian Process (GP) 
\begin_inset CommandInset citation
LatexCommand cite
key "williams2006gaussian"
literal "false"

\end_inset

,
 to compensate for residual errors 
\begin_inset CommandInset citation
LatexCommand cite
key "aswani2013provably"
literal "false"

\end_inset

.
 This approaches preserves part of the structural safety of the physics-based controller but a gap still remains in the theoretical guarantees because they can only be guaranteed for the behavior of the baseline 
\begin_inset CommandInset citation
LatexCommand cite
key "hewing2020learning"
literal "false"

\end_inset

.
 In addition to that the baseline model remains fixed which is not suitable to handle non-stationary dynamics.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/Hybrid-MPC_Control.pdf
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Hybrid-MPC Control Architecture
\begin_inset CommandInset label
LatexCommand label
name "fig:Hybrid-MPC-Control"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
To open up the field toward more complex control tasks,
 model-free Reinforcement Learning (RL) has been extensively studied.
 By interacting directly with the environment,
 the RL agent learns a control policy 
\begin_inset Formula $\pi$
\end_inset

 end-to-end by looking to maximize a cumulative scalar reward signal without any prior knowledge of the system's dynamics 
\begin_inset CommandInset citation
LatexCommand cite
key "sutton1998reinforcement"
literal "false"

\end_inset

 (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RL-Control"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
The success of model-free RL has been demonstrated across diverse and highly complex control tasks on which traditional modeling approach struggle.
 Algorithms such as Deep Q-Networks (DQN) 
\begin_inset CommandInset citation
LatexCommand cite
key "mnihHumanlevelControlDeep2015"
literal "false"

\end_inset

 and Proximal Policy Optimization (PPO) 
\begin_inset CommandInset citation
LatexCommand cite
key "schulmanProximalPolicyOptimization2017"
literal "false"

\end_inset

 have shown that controllers learned with RL could master superhuman strategies in discrete and continuous spaces.
 In the field of robotics,
 model-free RL has enabled end-to-end control using only pixels as input,
 tasks where agents learn to perform agile maneuvers (e.g quadrupeds recovering from falls 
\begin_inset CommandInset citation
LatexCommand cite
key "lee2019robust"
literal "false"

\end_inset

 or high-speed drone racing 
\begin_inset CommandInset citation
LatexCommand cite
key "kaufmann2023champion"
literal "false"

\end_inset

),
 tasks where the aerodynamic or contact forces are too non-linear to be captured by first-principles in real-time 
\begin_inset CommandInset citation
LatexCommand cite
key "hammouda2025application,hwangbo2019learning"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Despite these remarkable feats in complex robotics tasks,
 the application of model-free RL to safety-critical tasks necessitating Human-Robot Collaboration (HRC).
 As highlighted in 
\begin_inset CommandInset citation
LatexCommand cite
key "semeraro2023human"
literal "false"

\end_inset

,
 these approaches often lack quantitative safety guarantees.
 In RL,
 the underlying class of models used are mostly Neural Networks.
 Thus,
 it results in opaque black box models that rely on reward shaping to penalize dangerous states,
 providing only probabilistic incentives toward safety rather than hard mathematical boundaries offered by MPC.
 This makes real-world deployment of RL still rare in unstructured safety-critical environments 
\begin_inset CommandInset citation
LatexCommand cite
key "semeraro2023human"
literal "false"

\end_inset

.
 Furthermore,
 the trial-and-error learning procedure of model-free RL results in extreme sample inefficiency.
 It necessitates high-fidelity simulators that often fail to bridge the gap between simulation and reality.
 This is especially true for tasks that involves humans that can hardly be simulated.
 Finally,
 most deep RL implementations results in frozen policies that cannot adapt to non-stationarity.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/RL_Controller.pdf
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Model-free RL Control Architecture
\begin_inset CommandInset label
LatexCommand label
name "fig:RL-Control"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In response to the sample inefficiency of model-free RL,
 Model-Based Reinforcement Learning (MBRL) offers an approach more closely aligned with classical control theory by explicitly learning the system dynamics.
 Early algorithms such as PILCO 
\begin_inset CommandInset citation
LatexCommand cite
key "deisenroth2011pilco"
literal "false"

\end_inset

 uses probabilistic models like GPs to account for model uncertainty,
 significantly reducing the amount of data for obtaining efficient policies.
 This was further improved by methods like PETS 
\begin_inset CommandInset citation
LatexCommand cite
key "chua2018deep"
literal "false"

\end_inset

,
 which employed ensembles of neural networks to capture epistemic and aleatoric uncertainty,
 paired with Cross-Entropy Method (CEM) 
\begin_inset CommandInset citation
LatexCommand cite
key "rubinstein2004cross"
literal "false"

\end_inset

 for planning over the learned dynamics.
\end_layout

\begin_layout Standard
More recently,
 the field has entered the era of Latent World Models,
 where algorithms such as DreamerV3 
\begin_inset CommandInset citation
LatexCommand cite
key "hafner2023mastering"
literal "false"

\end_inset

 and MuZero 
\begin_inset CommandInset citation
LatexCommand cite
key "schrittwieser2020mastering"
literal "false"

\end_inset

 learn to predict future rewards and states within a compressed latent space.
 By planning entirely inside a learned representation of the environment,
 these approaches have achieved remarkable performance in tasks with complex high-dimensional observations.
 However,
 despite their predictive power,
 world models remain complex to implement and necessitate vast amounts of data for their initial training phase.
 Furthermore,
 these approaches still lead to fixed policies lacking the lightweight recursive update mechanisms required to handle non-stationary dynamics in real-time 
\begin_inset CommandInset citation
LatexCommand cite
key "semeraro2023human"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Beyond the architectural complexity,
 learning-based control introduces challenges regarding data availability and reliability.
 The most prominent one is the Exploration-Exploitation trade-off.
 In a learning paradigm like RL where the controller learns from continuous interaction with the environment,
 the learning process itself is non-stationary because the policy is regularly updated to improve from its past self.
 In this non-stationary setting,
 the controller must occasionally take exploratory actions to gather new data to avoid collapsing into local optimum.
 In RL literature this is often addressed through intrinsic motivation mechanisms,
 such as Curiosity-driven exploration 
\begin_inset CommandInset citation
LatexCommand cite
key "pathak2017curiosity"
literal "false"

\end_inset

 or Random Network Distillation (RND) 
\begin_inset CommandInset citation
LatexCommand cite
key "burda2018exploration"
literal "false"

\end_inset

,
 which provide an exploration bonus to the agent for visiting unfamiliar states.
 
\end_layout

\begin_layout Standard
Another closely related challenge is the risk of Out-of-Distribution (OoD) predictions.
 When a learning-based controller encounters a state-action pair that is significantly different from its training data,
 its predictions can become erratic or overly optimistic,
 leading the optimizer to select unsafe trajectories.
 This specific issue is largely studied in the field of Offline Reinforcement Learning,
 where algorithms seek to learn conservative policies that would stay within the support of the available dataset to avoid the pitfalls of unknown state-action spaces 
\begin_inset CommandInset citation
LatexCommand cite
key "levine2020offline"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
The limitations of both static physics-based control and pure RL necessitate a shift toward Model Predictive Control with a continuously learning model.
 This way,
 the architectural benefits of MPC regarding safety and constraints handling are preserved.
 In addition to that,
 replacing the static internal model with an online learning model allows to handle non-stationarity and to be able to adapt to changes in real-time.
 Unlike the frozen policies obtained with MBRL or model-free RL or the rigid baselines of Hybrid MPC,
 this approach allows the controller to adjust its predictions in response to a live data stream,
 enabling it to proactively account for the non-stationary dynamics.
\end_layout

\begin_layout Standard
However,
 implementing such a system with strict safety requirements introduce significant challenges regarding the choice of the learning architecture.
 Specifically,
 the model must be capable of fast,
 incremental updates without suffering from catastrophic forgetting or computational overhead.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
RL have non stationary learning procedure but cannot handle non stationarity at deployment
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
PILCO 
\begin_inset CommandInset citation
LatexCommand cite
key "deisenroth2011pilco"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
PETS 
\begin_inset CommandInset citation
LatexCommand cite
key "chua2018deep"
literal "false"

\end_inset

 => Ensemble Methods (for uncertainty estimation) + CEM Planning
\end_layout

\begin_layout Plain Layout
Latent World Model Era => Dreamerv3 
\begin_inset CommandInset citation
LatexCommand cite
key "hafner2023mastering"
literal "false"

\end_inset

 / MuZero 
\begin_inset CommandInset citation
LatexCommand cite
key "schrittwieser2020mastering"
literal "false"

\end_inset


\end_layout

\begin_layout Plain Layout
=> But still fixed models and some new researches on world models are really complex and necessitate a lot of data
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Hybrid MPC => model-free RL => model-based RL => MPC with online learning model (interesting review paper 
\begin_inset CommandInset citation
LatexCommand cite
key "hewing2020learning"
literal "false"

\end_inset

 on learning based MPC)
\end_layout

\begin_layout Itemize
In some cases,
 environment is so complex that accurate first principle models do not exist or are hard to develop or too computationally heavy
\end_layout

\begin_layout Itemize
In some cases MPC can be used with simple physics model (e.g linear model) and is enhanced by a learning model like a Gaussian Process to learn to compensate the errors of the simple model => physic informed learning based => limited when no first principle model exists at all
\end_layout

\begin_layout Itemize
Due to these limitations approaches based on model free RL have been used to learn end to end a controller in an online fashion without prior knowledge of the environment.
 => introduction of RL
\end_layout

\begin_layout Itemize
RL is very performant and has seen success in many use cases.
 However it is inherently limited by:
\end_layout

\begin_deeper
\begin_layout Itemize
its sample inefficiency => problem of exploration with learned models
\end_layout

\begin_layout Itemize
learning instabilities
\end_layout

\begin_layout Itemize
reality gap => need very accurate simulator
\end_layout

\begin_layout Itemize
it obtains frozen models => the process of learning is online with interactions with the environment,
 however at deployment the 
\end_layout

\begin_layout Itemize
lack of safety guarantees => addressed with safety layer added on top of the model
\end_layout

\end_deeper
\begin_layout Itemize
To address these limitations (especially sample inefficiency) => model-based RL have been developed (very similar to MPC in some sense) => PILCO 
\begin_inset CommandInset citation
LatexCommand cite
key "deisenroth2011pilco"
literal "false"

\end_inset

,
 PETS
\end_layout

\begin_layout Itemize
However MBRL still gives frozen policies and cannot be adaptive and continue learning online.
 Furthermore,
 it often is very computationally inefficient at deployment needing population based optimizers (e.g PETS)
\end_layout

\begin_layout Itemize
Best fit ?
 MPC with a continuously learning model for stationarity
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "hewing2020learning"
literal "false"

\end_inset

 => using an online learning model allows the controller to adjust to changing environments (ex:
 aging of the system) => challenges in active learning so that the controller intentionally chooses actions to better identify the system while still respecting constraints.
 => challenges in safe exploration
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "semeraro2023human"
literal "false"

\end_inset

 => problems of RL in human robot collaboration are safety (black box opaque models),
 real-time adaptation to non-stationarity and computational efficiency (learning expensive)
\end_layout

\begin_layout Itemize
1.
 Addressing the "Black Box" and Safety Constraints
\end_layout

\begin_deeper
\begin_layout Itemize
The Paper’s Claim:
 The review notes that RL is often used to model robot decision-making and actuation.
 However,
 a key result in many RL studies is merely a "proof of concept" rather than a quantitative safety guarantee.
\end_layout

\begin_layout Itemize
MPC Motivation:
 You can argue that while RL learns policies through trial-and-error which can be risky in physical HRC,
 MPC allows for the explicit integration of hard safety constraints (e.g.,
 joint limits,
 collision avoidance) directly into the optimization loop.
 This addresses the "safety and ergonomics" concerns mentioned as emerging research fields.
\end_layout

\end_deeper
\begin_layout Itemize
2.
 Handling Non-Stationarity and Unstructured Environments
\end_layout

\begin_deeper
\begin_layout Itemize
The Paper’s Claim:
 The review classifies HRC environments as "unstructured," where every interaction differs,
 making standardized control methods difficult.
 It also highlights that many RL models rely on offline demonstrations to achieve reactive capabilities,
 which limits their ability to handle drastically new human behaviors.
\end_layout

\begin_layout Itemize
MPC Motivation:
 An MPC with an online learning model can adapt its internal model of the human or environment in real-time.
 Unlike the "frozen" policies of many deep RL implementations,
 this hybrid approach can update its predictions as the human's behavior changes (non-stationarity),
 providing the "actual behavioural change" the paper identifies as a selection criterion for advanced HRC.
\end_layout

\end_deeper
\begin_layout Itemize
4.
 Overcoming the "Rare" Status of Deep RL
\end_layout

\begin_deeper
\begin_layout Itemize
The Paper’s Claim:
 The authors explicitly state that while deep RL is promising,
 its use in HRC is "still rare" and faces complexity in mapping complex state spaces.
\end_layout

\begin_layout Itemize
MPC Motivation:
 Using MPC with a learned model (e.g.,
 a neural network representing the human's motion) can be more sample-efficient than pure Deep RL.
 Since the paper highlights that HRC is "extraordinarily complex to model",
 a model-based approach like MPC can leverage known physical dynamics while using online learning to only "fill in" the uncertain parts of human behavior.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Subsection
Synthesis and Research Gaps
\end_layout

\begin_layout Standard
The transition from reactive feedback control laws to predictive optimization and then learning-based control highlights a persistent tension between mathematical rigor and adaptive capabilities.
 In this section we synthesize the reviewed literature to identify specific research gaps.
\end_layout

\begin_layout Standard
In the context of Human-Robot Collaboration (HRC),
 as introduced in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Control-Theory-Formalism"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the 3 core problematics of control,
 controllability,
 observability and stabilizability take on a specific meaning regarding the positioning of the works of this thesis:
\end_layout

\begin_layout Itemize

\series bold
Shared Controllability:

\series default
 In HRC,
 controllability is often shared.
 For instance,
 in the case of speed recommendation as defined in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Introduction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the human driver acts as a biological intermediary between the controller (i.e the speed recommendation system) and the vehicle.
 Depending on the driver and his receptivity to recommendation set points,
 the system may become under-actuated or locally uncontrollable as the controller itself cannot enforce the required acceleration.
 We argue that to maintain control authority,
 the controller must be able to anticipate non-receptivity rather than reacting to it.
\end_layout

\begin_layout Itemize

\series bold
Partial Observability:
 
\series default
In HRC,
 the human intent is not directly measurable.
 In this case,
 HRC systems often face partial observability and can necessitate the use of sophisticated state estimators.
 The control architecture must be robust to incomplete state information,
 favoring models that can explicitly handle uncertainty.
\end_layout

\begin_layout Itemize

\series bold
Stabilizability:

\series default
 In safety-critical contexts,
 the frozen policies of model-free RL are insufficient in light of the current state of research.
 The works of this thesis are positioned within the MPC framework because it provides structural mechanism for enforcement of hard safety constraints through the use of specialized optimizers adapted for solving constrained optimization problems.
 It ensures the system remains in a stabilizable region even when human behavior varies.
\end_layout

\begin_layout Standard
According to Ashby's Law of Requisite Variety,
 a controller in the context of HRC as described in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Introduction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 must possess an internal variety matching the uncertainty and non-stationarity introduced by the human driver.
 As the behavior of a specific human individual is hard to describe accuractely with first-principle models,
 this constrains the use of models learned from data.
 As summarized in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "Summary-of-Control-Architecture"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 classical parametric models,
 with a fixed number of parameters,
 lack this variety.
\end_layout

\begin_layout Standard
In learned based control,
 a significant research gap can be identified.
 Most learning-based controllers results in frozen policies after training.
 While MBRL and Latent World Models offer high variety,
 they still lack the lightweight recursive update mechanisms required to handle the non-stationarity induced by human behavior in real-time.
 To satisfy the Conant-Ashby Theorem,
 the model 
\begin_inset Formula $\hat{f}$
\end_inset

 must not only exist but must also adapt its own complexity continuously.
 This justifies the focus on non-parametric methods (with a variable number of parameters),
 which allow the model learning capacity to grow and refine alongside the data stream,
 ensuring growth of variety in a way that static or deep-frozen models cannot.
\end_layout

\begin_layout Standard
To navigate the trade-offs between anticipation capabilities,
 safety and adaptability,
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "Summary-of-Control-Architecture"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 provides a comparative synthesis of the control frameworks dicussed in this section.
 It assesses their ability fo meet the requirements of HRC,
 focusing on their resilience in non-stationary environments and their flexibility in high-variety tasks.
 Specifically,
 a distinction is made between the structural enforcement of constraints,
 i.e the architectural intent to remain safe,
 and the structural adaptability,
 which defines the controller's ability to maintain high-fidelity representations in a complex non-stationary setting.
\end_layout

\begin_layout Standard
We established Online Learning MPC as a promising architectural choice to address the challenges of HRC as it combines structural safety considerations with recursive online model updates.
 However,
 the theoretical feasibility of this approach depends entirely on the nature of the predictive model 
\begin_inset Formula $\hat{f}$
\end_inset

.
 While the framework allows for use of either parametric or non-parametric models,
 the requirement for requisite variety in a non-stationary human-in-the-loop environment favors models that can adapt their own complexity.
\end_layout

\begin_layout Standard
Having answered the question of which control architecture is the most promising,
 the question of which model could fulfill all the critera has to be addressed.
 Consequently,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Online-Machine-Learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 explores the research landscape about Online Machine Learning to identify the modeling methods best suited for providing structural compatibility,
 uncertainty-awareness,
 fast recursive updates and accurate predictions required in this hybrid control framework.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{1
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="6">
<features tabularvalignment="middle">
<column alignment="left" valignment="middle" width="12col%">
<column alignment="center" valignment="middle" width="13col%">
<column alignment="left" valignment="middle" width="20col%">
<column alignment="center" valignment="middle" width="20col%">
<column alignment="center" valignment="middle" width="12col%">
<column alignment="left" valignment="middle" width="20col%">
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Family
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Anticipation
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Structural Constraints Enforcement
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Non-Stationarity Handling
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Structural Adaptability
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Reactive Feedback Laws
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Fixed
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Optimal Control
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
First-Principles
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Fixed
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MPC
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Hard 
\end_layout

\begin_layout Plain Layout
\align center
(optimization-based)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
First-Principles
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Fixed 
\begin_inset Newline newline
\end_inset

(analytical)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model-Free RL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Soft 
\end_layout

\begin_layout Plain Layout
\align center
(reward penalty)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Data-Driven (batch learning)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Fixed 
\begin_inset Newline newline
\end_inset

(frozen weights)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model-Based RL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Soft
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Data-Driven (batch learning)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Fixed 
\begin_inset Newline newline
\end_inset

(frozen weights)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Online Learning MPC
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Hard 
\end_layout

\begin_layout Plain Layout
\align center
(optimization-based)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Data-Driven (recursive online learning)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Evolving 
\begin_inset Newline newline
\end_inset

(non-parametric)
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of control architectures across predictive capability,
 constraint handling and adaptability to non-stationarity.
 
\begin_inset CommandInset label
LatexCommand label
name "Summary-of-Control-Architecture"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Itemize

\series bold
Controllability:
 
\series default
This property assesses whether the control input 
\begin_inset Formula $u$
\end_inset

 can drive the system from any initial state 
\begin_inset Formula $s_{0}$
\end_inset

 to any desired state 
\begin_inset Formula $s_{t}$
\end_inset

 within a finite time.
 In HRC,
 controllability is often shared.
 In the specific case of speed recommendation as defined in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Introduction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the human driver acts as a biological intermediary between the controller (i.e the speed recommendation system) and the vehicle.
 Depending on the driver and his receptivity to recommendation set points,
 the system may become under-actuated or locally uncontrollable as the controller itself cannot enforce the required acceleration.
\end_layout

\begin_layout Itemize

\series bold
Observability:
 
\series default
This corresponds to the ability to reconstruct the internal state 
\begin_inset Formula $s_{t}$
\end_inset

 from available measurements.
 For instance,
 in HRC,
 the human intent is not directly measurable.
 In this case,
 HRC systems often face partial observability and can necessitate the use of sophisticated state estimators.
\end_layout

\begin_layout Itemize

\series bold
Stabilizability:
 
\series default
Even if a system is not fully controllable,
 it is considered stabilizable if all the unstable modes can be brought to a steady state using the available actions.
 This is the minimum requirement for a safe autonomous system because a controller must at least be able to prevent the system from diverging into unsafe states from which it is impossible to recover.
\end_layout

\begin_layout Plain Layout
=> Ashbys Law => Pour du HRC la variabilité est inconnue => donc nécessite un modèle d'apprentissage non paramétrique capable d'adapter sa complexité ?
\end_layout

\begin_layout Itemize
Requisite Variety Principle:
 Ashby's Law,
 from W.
 Ross Ashby's cybernetics work,
 requires the regulator's information processing and adaptive capacity to counter the disturbances in the controlled system.
 In human-machine settings—
like collaborative robotics or autonomous vehicles—
dynamics exhibit high variety due to unpredictable human behaviors,
 unmodeled nonlinearities,
 and environmental factors,
 which parametric models (e.g.,
 fixed-structure linearizations) cannot capture adequately.
\end_layout

\begin_layout Itemize
Non-Parametric Methods' Fit:
 Non-parametric approaches,
 such as Gaussian Processes (GPs) used in GP-MPC,
 inherently scale their complexity to data without assuming fixed forms,
 providing the flexibility to represent diverse dynamics.
 Dual MPC frameworks explicitly leverage GP posterior covariance to explore high-uncertainty regions,
 balancing identification and control while satisfying safety constraints—
this embodies requisite variety by adapting model capacity online.
\end_layout

\begin_layout Itemize
Application to Human-Machine Contexts:
 In highly interactive environments,
 human inputs introduce stochastic,
 non-stationary variety that rigid parametric models fail to match,
 risking poor performance or instability.
 Non-parametric learners enable MPC to maintain control authority by continuously refining high-fidelity approximations,
 as shown in dual control studies for safety-critical systems with nonparametric uncertainties.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Online Machine Learning
\begin_inset CommandInset label
LatexCommand label
name "sec:Online-Machine-Learning"

\end_inset


\end_layout

\begin_layout Standard
The ability to continuously build accurate and uncertainty-aware representations of non-stationary dynamics is a requirement for effective adaptive control in a Human-Robot Collaboration (HRC) setting.
 As shown in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Control-with-Learned-Models"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the transition from controlled industrial contexts to the complexity of Human-in-the-Loop (HitL) interactions necessitates a Model Predictive Control (MPC) architecture that can plan under uncertainty with a learned model.
 However,
 the performance,
 adaptability and safety of such a framework are contingent with the properties of its internal predictive model 
\begin_inset Formula $\hat{f}$
\end_inset

.
\end_layout

\begin_layout Standard
Transitioning from controlled standardized environments to the unstructured evolving complexity of HRC necessitates a shift in the modeling approach.
 Traditional machine learning techniques are constrained by the assumption of stationarity,
 thus,
 they usually are not tailored to handle non-stationarity where the underlying data distribution can change over time.
 In the context of this thesis,
 this section aims at answering the following question:
\end_layout

\begin_layout Standard
\align center

\emph on
How can a learning architecture continuously model non-linear,
 non-stationary dynamics from an online stream of data while avoiding catastrophic forgetting?
\end_layout

\begin_layout Standard
First,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Machine-Learning-Formalism"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces Machine Learning to set up the formalism that will be used throughout the course of this thesis.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:From-Batch-to-Online-Learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 distinguishes between Batch Learning and Online Learning,
 highlighting the transition from static datasets to continuous streams.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Global-Models-and-Stability-Plasticity"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 exposes the limitations of global models,
 specifically focusing on the stability-plasticity dilemma as an architectural bottleneck for global approximators like deep neural networks.
 In response,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Local-Online-Learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 provides an overview of local learning methods which naturally mitigate the stability-plasticity dilemma through spatial isolation.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Multiagent-Local-Learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces the use of multi-agent systems for online learning where the learning procedure is defined by a set of local social rules that allow self-organization of a set of agents and the global emergence of learning behavior.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Online Learning
\end_layout

\begin_layout Enumerate
Batch Learning towards Online Learning
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "smale2006online"
literal "false"

\end_inset

 Batch Learning = several samples at a time;
 Online Learning = one sample at a time.
 In online learning,
 the learner must recursively update a hypothesis using only one example at a time,
 whereas in batch learning,
 the learner is presented with the entire set of examples simultaneously.
 This shift introduces a significant challenge in the form of sample error,
 which represents the probabilistic fluctuation and "noise" caused by random sampling that does not occur in deterministic batch methods.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "gomes2019machine"
literal "false"

\end_inset

 Online learning arises from the industrial need of processing large volume of data in real time as they come without needing several passes over the dataset + need to be adaptive to incrementally learn new concepts.
\end_layout

\begin_deeper
\begin_layout Enumerate
Interleaved Phases:
 In batch learning,
 preprocessing,
 fitting,
 and testing are distinct sequential phases;
 in online learning,
 these operations must be interleaved and applied continuously as data arrives.
\end_layout

\begin_layout Enumerate
Single-Pass Constraint:
 Online learning algorithms must update models given a continuous influx of data without performing multiple passes,
 which is essential for handling high-velocity and high-volume big data.
\end_layout

\begin_layout Enumerate
Adaptive Learning:
 The focus of online learning is to develop methods that can learn and forget concepts incrementally to maintain an accurate decision model over time.
\end_layout

\begin_layout Enumerate
Unknown Global Statistics:
 Trivial batch tasks like feature normalization are complicated in online settings because global statistics (e.g.,
 min/max values) are unknown a priori and must be estimated incrementally.
\end_layout

\begin_layout Enumerate
Feature and Concept Drift:
 Online systems must account for "feature drift",
 where the relevance of a feature changes over time,
 and "concept drift",
 where the underlying data distribution shifts.
\end_layout

\begin_layout Enumerate
Model Complexity vs.
 Utility:
 The shift to online learning favors ensemble strategies because they can dynamically add or remove models to recover from drift,
 though this often increases computational demand and architectural complexity.
\end_layout

\begin_layout Enumerate
Stability vs.
 Accuracy Trade-off:
 The authors explicitly identify an "open challenge" in the contradiction between feature stability and selection accuracy.
 If a model remains "stable" (converged on a fixed set of features),
 it may lose accuracy when the importance of those features shifts over time (feature drift).
\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Global Models and stability-plasticity dilemma
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "wang2023incorporating"
literal "false"

\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Stability-Plasticity dilemma defined as the need to properly balance memory stability (preserving knowledge of old tasks) with learning plasticity (the ability to accommodate and learn new tasks).
\end_layout

\begin_layout Enumerate
Catastrophic Forgetting is defined as a phenomenon in artificial neural networks where parameter changes required to learn a new task well typically result in a "dramatic performance drop" on previously learned (old) tasks.
\end_layout

\begin_layout Enumerate
Catastrophic Forgetting:
 Parameter changes required to learn a new task often result in a dramatic performance drop on old tasks.
\end_layout

\begin_layout Enumerate
Mutual Interference:
 There is mutual interference between new and old tasks due to differences in their data distributions.
\end_layout

\begin_layout Enumerate
Difficulty of New Learning:
 Precisely remembering old tasks can increase the difficulty of learning each new task well.
\end_layout

\begin_layout Enumerate
Gap in Current Methods:
 Most existing advances focus primarily on preserving stability to mitigate forgetting but struggle to flexibly accommodate incremental changes as biological systems do.
\end_layout

\begin_layout Enumerate
In the paper they suggest using ensemble learning methods (diverse learners) because it makes it easier to create or drop new models dynamically => better to handle various learning tasks [could be used to steer the reasoning toward ensemble methods]
\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "xie2011comparison"
literal "false"

\end_inset

 presents a comparative analysis of the properties of traditional neural networks against RBF networks.
 They provide definitions for local learners and global learners.
\end_layout

\begin_deeper
\begin_layout Enumerate
Local Learning:
 outputs are determined by specific local units (e.g RBF Networks).
\end_layout

\begin_layout Enumerate
Global Learning:
 outputs are decided by all the neurons within the system (e.g Multi-Layer Perceptron).
\end_layout

\end_deeper
\begin_layout Enumerate
Simple Global Models
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "hue2016online"
literal "false"

\end_inset

 online learning with naive bayes for classification
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "strehl2007online"
literal "false"

\end_inset

 introduces an online linear regression algorithm for model based reinforcement learning.
 It uses uncertainty signals to drive exploration and learns only on unknown or not well modeled points => limited by linearity assumption and assumes some known parameters
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "jacobsen2024online"
literal "false"

\end_inset

 introduces discounted variant of the Vovk-Azoury-Warmuth (VAW) forecaster designed for online linear regression in non-stationary environments.
 The algorithm incorporates a "forgetting" or discount factor (
\begin_inset Formula $\gamma$
\end_inset

) into its statistics to prioritize recent observations over past ones,
 effectively allowing the model to adapt as the data-generating process changes => hard to tune discount parameter + limited by linearity assumption
\end_layout

\end_deeper
\begin_layout Enumerate
Neural Networks
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "chaudhry2019continual"
literal "false"

\end_inset

 Use of Experience Replay (Episodic Memory) with tiny episodic memory to learn neural networks better online.
 Better generalization and less forgetting however the catastrophic forgetting problem still there.
 Global models (especially neural net) are usually more sensitive to catastrophic forgetting than local models.
 => even with experience replay they can forget useful knowledge
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "kirkpatrick2017overcoming"
literal "false"

\end_inset

 Elastic weight consolidation method for overcoming catastrophic forgetting by regularization.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "aljundi2017expert"
literal "false"

\end_inset

 Use of Parameter Isolation.
 It is a meta-learning approach that creates expert models for new tasks and leverage knowledge transfer between models to warmup new experts.
 => problem of unlimited growth of expert
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "Delange_2021"
literal "false"

\end_inset

 Review that exposes that neural nets suffer particularly from stability-plasticity dilemma.
 They categorize methods for online learning with neural net into 3:
 Parameter Isolation (update only subset of parameters per task),
 Replay methods (use experience replay to keep learning on older experiences),
 Regularization methods (use regularization term to consolidate old knowledge without forgetting old ones).
 => Parameter Isolation is best for long challenging sequences => [It can be an argument toward the use of local learning methods in the thesis]
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "zheng2024lifelonglearninglargelanguage"
literal "false"

\end_inset

 Review that study the problem of lifelong learning for LLMs => indicates that neural networks suffer largely from catastrophic forgetting => Considered approaches in literature are Regularization-based,
 Replay-Based,
 Parameter Isolation (named Architetcure based in the paper),
 Distillation based (with teacher student models).
\end_layout

\end_deeper
\begin_layout Enumerate
Trees
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "domingos2000mining"
literal "false"

\end_inset

 introduces Very fast Decision Tree Learner (VFDT) or Hoeffding Trees,
 a system that builds decision trees by processing examples from a continuous data stream in constant time and memory per example.
 It utilizes Hoeffding bounds to statistically determine the minimum number of examples needed to select an optimal split at each node,
 ensuring that the resulting tree is asymptotically nearly identical to one produced by a conventional batch learner => no => stationary assumption
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "bifet2009adaptive"
literal "false"

\end_inset

 introduces Adaptive Hoeffding Trees thet extends classic Hoeffding tree by replacing traditional static counters in nodes (to track statistics) by ADWIN 
\begin_inset CommandInset citation
LatexCommand cite
key "bifet2007learning"
literal "false"

\end_inset

 estimators that are more adaptive and can detect concept drift => adaptation possible but still lags behind changes
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "saffari2009line"
literal "false"

\end_inset

 Online Random Forest using online bagging.
 When new sample arrives a tree is randomly selected to be updated with it.
 They also propose an online compliant growing tree strategy to maximize information gain.
 Trees are removed and added dynamically to handle non stationarity.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "lakshminarayanan2014mondrian"
literal "false"

\end_inset

 introduces mondrian forests that represent a significant upgrade for online random forests => better batch-online consistency,
 fast learning,
 data efficient,
 order independant => struggle to capture diagonal relationships between features,
 struggle with concept drift,
 hard to implement,
 struggle when number of irrelevant feature is high
\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Local Online Learning
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "zhang2010real"
literal "false"

\end_inset

 Online kNN forecaster for real-time price prediction with adaptive neighbor selection through KL divergence to handle non stationarity.
 The goal is to predict using most resembling previous data
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "han2010research"
literal "false"

\end_inset

 Self organizing RBF Network with growing and pruning for non-stationary online learning.
 Number of nodes is dynamic and updates are done with gradient descent.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "jia2025online"
literal "false"

\end_inset

 Self organizing RBF Networks with adding neurons via gaussian similarity (add when surely unknown data) and pruned via internally tracked metrics on neurons.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "maric2024online"
literal "false"

\end_inset

 Online learning with piecewise polynomial basis functions with incremental least squares => rely on uniform grid segmentation (nb models not dynamic) => lacks estimation of epistemic uncertainty
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "atkeson1997locally"
literal "false"

\end_inset

 Learning via Locally Weighted Regression.
 It is a lazy learning approach that stores all the points and at query time fits a local linear model around the query with closest points.
 Fast learning with only database insertion.
 => computationally inefficient at query time + sensitive to data density + needs external mechanism for memory management to handle concept drift
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "atkeson1997LocallyControl"
literal "false"

\end_inset

 LWR can be successfully leveraged for control to learn inverse or forward dynamics models => for ex:
 vulnerable in inverse dynamics in case of ambiguity (mapping is not one to one)
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "vijayakumar2000locally"
literal "false"

\end_inset

 Online Learning with Locally Weighted Projection Regression (LWPR) which is an extension of LWR that relies on multiple linear regression models instead of storing the integrality of points => can handle high number of dimensions and is often used for control.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "meier2014incremental"
literal "false"

\end_inset

 Use LWPR to approximate a Gaussian Process with uncertainty quantification.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "rudin2019stop"
literal "false"

\end_inset

 supports the fact that interpretable models should be preferred over black box models for explainability for high stake decisions.
 It supports that local learning approaches are more interpretable => for trust it's better to have interpretable white box models.
\end_layout

\end_deeper
\begin_layout Enumerate
Multi-Agent Local Learning
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "frenkel2021bottom"
literal "false"

\end_inset

 paper on neuromorphic intelligence.
 It provides a discussion on the current capabilities of bottom up approaches in neuromorphic intelligence.
 => the takeaway for this thesis might be 
\begin_inset Quotes eld
\end_inset

for tasks involving real-time,
 continuous adaptation to an environment (like autonomous robotics),
 bottom-up principles of online learning are highly relevant.
\begin_inset Quotes erd
\end_inset

 => and also,
 bottom up approaches can allow us to get inspiration from nature (e.g the brain) or by extensive from social behaviors to design learning systems.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset citation
LatexCommand cite
key "crespi2008top"
literal "false"

\end_inset

 Defines Bottom up and Top down => provide adaptation capabilities
\end_layout

\begin_deeper
\begin_layout Enumerate
Top-Down Approach:
 The design begins with global system requirements,
 assuming each component has global knowledge as in a centralized system.
 This solution is then decentralized by replacing global knowledge with inter-agent communication and relaxation of constraints.
\end_layout

\begin_layout Enumerate
Bottom-Up Approach:
 The design starts by specifying the requirements and capabilities of individual components.
 Global behavior is not explicitly designed but is said to emerge from the interactions between agents and their environment.
\end_layout

\end_deeper
\begin_layout Enumerate
Bottom
\end_layout

\end_deeper
\begin_layout Enumerate
XAI and Uncertainty
\end_layout

\begin_layout Plain Layout
Control with Learned models
\end_layout

\begin_layout Plain Layout
LWPR Problem
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "lehnert2012locally"
literal "false"

\end_inset

 use LWPR model weights to alter the control effort term in the cost function to steer trajectories towards existing local models => conservative
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "manzano2020online"
literal "false"

\end_inset

 uses LWPR to stay or get away from model centers => exploration / conservative
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Machine Learning Formalism
\begin_inset CommandInset label
LatexCommand label
name "subsec:Machine-Learning-Formalism"

\end_inset


\end_layout

\begin_layout Standard
Before dwelving into the reasoning towards online learning and multi-agent learning systems,
 it is required to establish the formalism used in this thesis regarding machine learning.
 In the context of this thesis,
 the goal of using machine learning is to approximate the unknown transition function 
\begin_inset Formula $f$
\end_inset

 from an available stream of observations.
\end_layout

\begin_layout Standard
As its core,
 supervised learning consists of learning a mapping function 
\begin_inset Formula $\hat{f}:\mathcal{X}\mapsto\mathcal{Y}$
\end_inset

 that relates an input space 
\begin_inset Formula $\mathcal{X}$
\end_inset

 and an output space 
\begin_inset Formula $\mathcal{Y}$
\end_inset

 based on a set of 
\begin_inset Formula $N$
\end_inset

 labeled examples 
\begin_inset Formula $\mathcal{D}=\left\{ \left(x_{i},y_{i}\right)\right\} _{i=0}^{N}$
\end_inset

.
\end_layout

\begin_layout Standard
Supervised learning can represent two types of tasks:
 
\emph on
regression
\emph default
 tasks where the output space 
\begin_inset Formula $\mathcal{Y}$
\end_inset

 is continuous (e.g.
 predicting house price or temperatures) and 
\emph on
classification
\emph default
 tasks where the output space 
\begin_inset Formula $\mathcal{Y}$
\end_inset

 is discrete or categorical (e.g.
 labeling images as cat/dog).
\end_layout

\begin_layout Standard
In this thesis,
 the focus is put on solving regression tasks because the goal,
 as specified in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Control-with-Learned-Models"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 is to approximate the unknown transition function 
\begin_inset Formula $f$
\end_inset

 of a dynamical system such as
\begin_inset Formula 
\[
s_{t+1}=f\left(s_{t},u_{t}\right)
\]

\end_inset

where 
\begin_inset Formula $s_{t}\in\mathcal{S}$
\end_inset

 the states of system (
\begin_inset Formula $\mathcal{S}$
\end_inset

 being a continuous state space) and 
\begin_inset Formula $u_{t}\in\mathcal{U}$
\end_inset

 the actions of the controller (
\begin_inset Formula $\mathcal{U}$
\end_inset

 being a continuous action space).
 The objective is to minimize an empirical risk,
 defined by a loss function 
\begin_inset Formula $L$
\end_inset

 (such as Mean Squared Error) to ensure that the approximation remains as close as possible to the true observation.
\end_layout

\begin_layout Standard
The nature and complexity of the mapping function 
\begin_inset Formula $\hat{f}$
\end_inset

 is defined by its underlying structure which can be categorized into two main families:
\end_layout

\begin_layout Itemize

\series bold
Parametric Approaches
\series default
:
 These models are defined by a fixed set of parameters 
\begin_inset Formula $\theta$
\end_inset

 (e.g.
 weights in a neural network or coefficients of a linear regression).
 The complexity of the model is determined beforehand by the number of parameters and remains constant regardless the amount of data collected.
 These models are computationally stable,
 meaning that they have predictable computational complexity during learning.
 However,
 they suffer from a capacity ceiling which can lead to underfitting if the true dynamics are more complex than the model's fixed structure.
 This can happen when the system is subjected to strict hardware constraints.
\end_layout

\begin_layout Itemize

\series bold
Non-Parametric Approches
\series default
:
 Unlike parametric models,
 the complexity of non-parametric approaches (e.g.
 Gaussian Processes (GPs) 
\begin_inset CommandInset citation
LatexCommand cite
key "williams2006gaussian"
literal "false"

\end_inset

 or k-Nearest Neighbors 
\begin_inset CommandInset citation
LatexCommand cite
key "stone1977consistent,yu2002kernel"
literal "false"

\end_inset

) is not fixed.
 Instead,
 the number of parameters and the model structure can grow and adapt in response to the data.
 This provides structural adaptability at the cost of less predictable computational cost at learning time.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
To address the limitations of individual learners,
 Ensemble Learning leverages the collective intelligence of multiple models to achieve more accurate predictions and provide better approximations of nonlinear functions.
 Ensemble learning is based on the emergence of collective intelligence within a set of weak learners.
 A weak learner is a model whose performance is at least as good as a model making random predictions.
 During the learning process,
 a set of models (which may differ from one another) are trained in parallel or sequentially 
\begin_inset CommandInset citation
LatexCommand cite
key "polikarEnsembleLearning2012"
literal "false"

\end_inset

.
 The objective is to encourage diversity among the models so that they do not all capture the same patterns in the data 
\begin_inset CommandInset citation
LatexCommand cite
key "dietterichEnsembleMethodsMachine2000"
literal "false"

\end_inset

.
 An input is transmitted to all weak learners,
 each of which makes a prediction proposal.
 A heuristic is implemented to select one of the proposals or to weight each of them in order to construct the final prediction.
 Several major approaches in ensemble learning can be distinguished:
 Boosting,
 Bagging and Stacking (c.f.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Bagging-Boosting-Stacking"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
In Bagging 
\begin_inset CommandInset citation
LatexCommand cite
key "breiman1996bagging"
literal "false"

\end_inset

 multiple models (usually homogeneous) are trained in parallel on different subsets of the training data to introduce diversity,
 reduce variance and improve stability.
 Then the final prediction is obtained by averaging the predictions of the weak learners (regression) or by majority voting (classification).
 Unlike Bagging,
 in Boosting 
\begin_inset CommandInset citation
LatexCommand cite
key "freund1997decision"
literal "false"

\end_inset

,
 the models are trained sequentially.
 Each new model focuses on correcting the errors of the previous ones to reduce bias and improve accuracy.
 Then the final prediction is obtained from a weighted average of the predictions of the all the weak learners.
 Finally,
 there is Stacking 
\begin_inset CommandInset citation
LatexCommand cite
key "wolpert1992stacked"
literal "false"

\end_inset

 that falls under meta-learning.
 A set of heterogeneous models are trained in parallel and then a meta-model is trained to combine the predictions of each model to obtain the final output of the system,
 in order to capture complementary strengths of each learning algorithms involved in the learning process.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/Ensemble_Learning.pdf
	lyxscale 30
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visual comparison of Bagging,
 Boosting and Stacking
\begin_inset CommandInset label
LatexCommand label
name "fig:Bagging-Boosting-Stacking"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
To achieve more accurate predictions and provide better approximations of nonlinear functions,
 it is common to aggregate multiple models for making predictions.
\end_layout

\begin_layout Plain Layout
Ensemble learning is based on the emergence of collective intelligence within a set of weak learners.
 A weak learner is a model whose performance is at least as good as a model making random predictions.
 During the learning process,
 a set of models (which may differ from one another) are trained in parallel or sequentially 
\begin_inset CommandInset citation
LatexCommand cite
key "polikarEnsembleLearning2012"
literal "false"

\end_inset

.
 The objective is to encourage diversity among the models so that they do not all capture the same patterns in the data 
\begin_inset CommandInset citation
LatexCommand cite
key "dietterichEnsembleMethodsMachine2000"
literal "false"

\end_inset

.
 An input is transmitted to all weak learners,
 each of which makes a prediction proposal.
 A heuristic is implemented to select one of the proposals or to weight each of them in order to construct the final prediction.
 We distinguish several major approaches in ensemble learning which are Boosting,
 Bagging and Stacking.
\end_layout

\begin_layout Plain Layout
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add figure to compare bagging,
 boosting and stacking
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visual comparison of bagging,
 boosting and stacking
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
In Bagging 
\begin_inset CommandInset citation
LatexCommand cite
key "breiman1996bagging"
literal "false"

\end_inset

 multiple models (usually homogeneous) are trained in parallel on different subsets of the training data to introduce diversity,
 reduce variance and improve stability.
 Then the final prediction is obtained by averaging the predictions of the weak learners (regression) or by majority voting (classification).
 Unlike Bagging,
 in Boosting 
\begin_inset CommandInset citation
LatexCommand cite
key "freund1997decision"
literal "false"

\end_inset

,
 the models are trained sequentially.
 Each new model focuses on correcting the errors of the previous ones to reduce bias and improve accuracy.
 Then the final prediction is obtained from a weighted average of the predictions of the all the weak learners.
 Finally,
 there is Stacking 
\begin_inset CommandInset citation
LatexCommand cite
key "wolpert1992stacked"
literal "false"

\end_inset

 that falls under meta-learning.
 We train in parallel a set of heterogeneous models and then a meta-model is trained to combine the predictions of each model to obtain the final output of the system,
 in order to capture complementary strengths of each learning algorithms involved in the learning process.
\end_layout

\begin_layout Plain Layout
The family of systems presented in this chapter,
 CELL,
 falls within ensemble learning and we could label it as a Bagging approach because we consider a set of weak learners as a collection of self-organizing cooperative agents.
 Each one of them is a local expert on the function to be approximated.
\end_layout

\begin_layout Plain Layout
What to mention ?
 (not in order)
\end_layout

\begin_layout Itemize
Supervised Learning
\end_layout

\begin_layout Itemize
Regression Tasks
\end_layout

\begin_layout Itemize
Ensemble Learning => combine several weak learners (comparison bagging,
 boosting,
 stacking)
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
s_{t+1}=f\left(s_{t},u_{t}\right)
\]

\end_inset

where 
\begin_inset Formula $f:\mathcal{S}\times\mathcal{U}\mapsto\mathcal{S}$
\end_inset

 represents the transition function
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
From Batch to Online Learning
\begin_inset CommandInset label
LatexCommand label
name "subsec:From-Batch-to-Online-Learning"

\end_inset


\end_layout

\begin_layout Standard
In machine learning and deep learning ,
 the Batch Learning paradigm is the most popular and widely used in the industry.
 In Batch Learning,
 the learner has access to a complete dataset 
\begin_inset Formula $\mathcal{D}$
\end_inset

 and learns from an entire set of examples simultaneously.
\end_layout

\begin_layout Standard
However,
 this paradigm is not sufficient to handle every industrial use case.
 For example,
 in deep learning,
 neural networks require extensive training data and several passes on data to converge 
\begin_inset CommandInset citation
LatexCommand cite
key "sarker2021deep"
literal "false"

\end_inset

,
 which is not compatible with use cases necessitating learning and adapting in real time from a stream of data that might be non-stationary.
 In response,
 the Online Learning paradigm has been explored in research.
 Unlike Batch Learning,
 in Online Learning,
 the learner recursively updates the model using only one example at a time,
 possibly under strict memory and pass constraint (e.g only single pass allowed) 
\begin_inset CommandInset citation
LatexCommand cite
key "gomes2019machine"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
This shift from Batch to Online Learning introduces several new challenges.
 First,
 the traditional sequential pipeline comprising data collection,
 pre-processing,
 training and testing is replaced by an interleaved architecture where these phases occur simultaneously without clear temporal order.
 This makes basic operations such as feature normalization non-trivial due to unknown global statistics.
 In this case the model needs to maintain incremental estimates that evolve alonside the data 
\begin_inset CommandInset citation
LatexCommand cite
key "gomes2019machine"
literal "false"

\end_inset

,
 introducing a second layer of non-stationarity into the learning process.
 Furtermore,
 because the learner cannot perform multiple passes over the dataset,
 it must balance generalization (i.e the variance introduced by seeing a finite subset of data),
 against approximation error (i.e the bias of the model).
 A higher generalization error is often tolerated for faster updates 
\begin_inset CommandInset citation
LatexCommand cite
key "smale2006online"
literal "false"

\end_inset

.
 However,
 this makes online learners even less reliable on out-of-ditribution data due to the short-term bias toward recent experience and the lack of global regularization.
\end_layout

\begin_layout Standard
The most important distinction lies in the assumption of stationarity.
 While Batch Learning methods assume that the data distribution is fixed and the dataset is exhaustive enough,
 Online Learning systems must be designed to handle non-stationarity that manifests through concept drift 
\begin_inset CommandInset citation
LatexCommand cite
key "gama2004learning"
literal "false"

\end_inset

,
 where the underlying relationship between inputs and outputs can changes.
 To continue being relevant,
 the learner must also include a mechanism for adaptive learning,
 incrementally forgetting obsolete concepts to make room for new dynamics.
 This requirement often leads to a trade-off between model stability and prediction accuracy 
\begin_inset CommandInset citation
LatexCommand cite
key "gama2014survey,shalev2025online"
literal "false"

\end_inset

.
 A model that converges too firmly,
 without letting room for plasticity may fail to adapt to concept drifts.
\end_layout

\begin_layout Standard
As new architectures are developed to handle these challenges,
 Ensemble Learning,
 a paradigm where multiple models are combined to solve a single task,
 seem to offer a way to dynamically add or remove learning capacity to recover from concept drift 
\begin_inset CommandInset citation
LatexCommand cite
key "gomes2019machine"
literal "false"

\end_inset

.
 This shifts adaptation from parameter space to model space.
 However,
 without locality,
 ensemble of global models do not completely solve the mutual interference problem because models' functions still overlap due to the global support of individual learners.
 Indeed,
 if the underlying models are global approximators like neural networks,
 updating on a single point can still lead to changes in the entire parameter space,
 potentially corrupting previously acquired knowledge.
 This structural vulnerability leads to a conflict known as the Stability-Plasticity dilemma 
\begin_inset CommandInset citation
LatexCommand cite
key "mermillod2013stability"
literal "false"

\end_inset

,
 which is explored in the following section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Global-Models-and-Stability-Plasticity"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Global Models and the Stability-Plasticity Dilemma
\begin_inset CommandInset label
LatexCommand label
name "subsec:Global-Models-and-Stability-Plasticity"

\end_inset


\end_layout

\begin_layout Standard
The transition to the Online Learning paradigm introduces new challenges and tensions on the internal representation of the models.
 This tension is formalized as the Stability-Plasticity dilemma which describes the challenge of balancing conservation of previously acquired knowledge (memory stability),
 with the ability to integrate new information from a non-stationary system (learning plasticity) 
\begin_inset CommandInset citation
LatexCommand cite
key "wang2023incorporating"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In Batch Learning,
 global learners are widely used.
 In global learning models,
 the output is decided by the collective activation of all neurons within the system 
\begin_inset CommandInset citation
LatexCommand cite
key "xie2011comparison"
literal "false"

\end_inset

.
 Because these parameters have global support,
 the gradient updates required to learn a new task or adapt to a concept drift can lead to mutual interference between the new and old tasks 
\begin_inset CommandInset citation
LatexCommand cite
key "wang2023incorporating"
literal "false"

\end_inset

.
 Indeed,
 a single update step can potentially have an impact on the entirety of the model.
 This interference problem is more generally referred to as the Catastrophic Forgetting problem,
 a phenomenon where parameter changes optimized for the current data distribution result in a dramatic performance drop on previously learned regions of the feature space 
\begin_inset CommandInset citation
LatexCommand cite
key "chaudhry2019continual,wang2023incorporating"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Simple global models such as linear regressions can be learned online and handle non-stationarity by incorporating discount factors in the learning procedure to prioritize recent observations 
\begin_inset CommandInset citation
LatexCommand cite
key "jacobsen2024online"
literal "false"

\end_inset

.
 These approaches are computationally efficient and can even be used for solving reinforcement learning problems 
\begin_inset CommandInset citation
LatexCommand cite
key "strehl2007online"
literal "false"

\end_inset

.
 However,
 they are limited by the linearity assumption and fail to capture the complex non-linear relationships between inputs and outputs in most dynamical systems,
 whereas high-capacity approximators like neural networks can provide the necessary representational depth.
\end_layout

\begin_layout Standard
In contrast,
 neural networks can capture such complexities but are highly susceptible to Catastrophic Forgetting.
 Beyond the Stability-Plasticity dilemma,
 these models are typically static,
 meaning that their internal complexity (number of layers and neurons) is fixed at design time and cannot adapt to the evolving complexity of the tackled problem.
 Several strategies have been proposed to mitigate these effects in global learners.
 
\emph on
Regularization
\emph default
 methods (e.g Elastic Weight Consolidation) attempt to anchor important weights to preserve stability 
\begin_inset CommandInset citation
LatexCommand cite
key "kirkpatrick2017overcoming"
literal "false"

\end_inset

 but this often hurt the plasticity capabilities of the model,
 preventing it to adapt to significant concept drifts.
 
\emph on
Replay
\emph default
 methods leverage episodic memory to re-train on past experiences to distillate old knowledge into the new one 
\begin_inset CommandInset citation
LatexCommand cite
key "chaudhry2019continual"
literal "false"

\end_inset

 to prevent forgetting.
 This trick is extensively used in Deep Reinforcement Learning to stabilize an inherently non-stationary learning procedure 
\begin_inset CommandInset citation
LatexCommand cite
key "mnihHumanlevelControlDeep2015,schaul2015prioritized,andrychowicz2017hindsight"
literal "false"

\end_inset

.
 However,
 it violates the single-pass constraint often associated with online learning as well as increasing the computational overhead.
 Finally,
 
\emph on
Parameter Isolation
\emph default
 methods create specialized experts sub-models for different tasks 
\begin_inset CommandInset citation
LatexCommand cite
key "aljundi2017expert,Delange_2021"
literal "false"

\end_inset

.
 They tackle the catastrophic forgetting problem by isolating sets of parameters allowing dynamic creation and destruction of relevant experts.
 While promising,
 this meta-learning approach often struggles with a problem of unlimited growth of experts and the lack of a clear spatial logic to trigger the correct expert in continuous state spaces.
\end_layout

\begin_layout Standard
Tree-based learners,
 such as Hoeffding Trees 
\begin_inset CommandInset citation
LatexCommand cite
key "domingos2000mining"
literal "false"

\end_inset

,
 Online Random Forests 
\begin_inset CommandInset citation
LatexCommand cite
key "saffari2009line"
literal "false"

\end_inset

 and Mondrian Forests 
\begin_inset CommandInset citation
LatexCommand cite
key "lakshminarayanan2014mondrian"
literal "false"

\end_inset

 offer an alternative to the neural networks which are widely considered as hard-to-interpret black-box models 
\begin_inset CommandInset citation
LatexCommand cite
key "yangSurveyLargeLanguage2023"
literal "false"

\end_inset

.
 They provide an interpretable symbolic structure from data streams.
 As these approaches struggle with handling concept drift,
 adaptive variants introducing structural modifications (e.g adding concept drift detectors like ADWIN 
\begin_inset CommandInset citation
LatexCommand cite
key "bifet2007learning"
literal "false"

\end_inset

) have been developed.
 Despite this,
 they are prone to structural instability caused by pruning strategies that can induce rough performance loss if not carefully designed 
\begin_inset CommandInset citation
LatexCommand cite
key "jiang2017forest"
literal "false"

\end_inset

.
 Furthermore,
 from a control perspective traditional trees are non-differentiable due to hard logical splits which produce a discontinuous output surface with zero gradients making them incompatible with gradient optimization methods.
 Attempts have been made to tackle this issue but they remain computationally inefficient 
\begin_inset CommandInset citation
LatexCommand cite
key "hazimeh2020tree"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Based on the limitations mentioned above,
 it would seem that global models struggle to handle non-stationarity due to global representations or structural difficulties to handle concept drift.
 This suggests that local learning could be more appropriate to handle the challenges inherent to Online Learning.
\end_layout

\begin_layout Subsection
Local Online Learning
\begin_inset CommandInset label
LatexCommand label
name "subsec:Local-Online-Learning"

\end_inset


\end_layout

\begin_layout Standard
The limitations of global learners in non-stationary environments motivates the exploration of local learning methods because they provide an architecural solution to the Stability-Plasticity dilemma.
 In local learners,
 the learning updates are spatially isolated and outputs are determined by specific local parameters 
\begin_inset CommandInset citation
LatexCommand cite
key "xie2011comparison"
literal "false"

\end_inset

.
 By restricting the influence of a data point to a specific neighborhood,
 these models achieve a natural form of Parameter Isolation,
 where adaptation to new dynamics in one region of the feature space does not disrupt the knowledge stored in another non-related one.
\end_layout

\begin_layout Standard
Beyond structural stability,
 the adoption of local learning is supported by the requirement for interpretability.
 In safety-critical systems,
 interpretable white-box models should be preferred over black-box approximators to ensure trust and safety through transparent inner workings 
\begin_inset CommandInset citation
LatexCommand cite
key "rudin2019stop"
literal "false"

\end_inset

.
 Local learning naturally provides traceability in the prediction process,
 provided that the local models are themselves interpretable.
 In this context,
 any prediction can be traced back to a specific,
 localized set of parameters rather than being the result of an opaque global activation.
\end_layout

\begin_layout Standard
The foundation of local learning lies in the k-Nearest Neighbors (kNN) algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "stone1977consistent,yu2002kernel"
literal "false"

\end_inset

.
 kNN makes predictions solely based on the most resembling points stored in memory.
 It can provide an intuitive mechanism to handle non-stationarity in an online learning setting through adaptive neighbor selection 
\begin_inset CommandInset citation
LatexCommand cite
key "zhang2010real"
literal "false"

\end_inset

.
 However it is often limited by data density,
 by poor generalization in sparse regions and by the high computational overhead induced by the search of nearest neighbors at prediction time,
 making it hard to use in real-time control applications.
\end_layout

\begin_layout Standard
To provide smoother approximations,
 Locally Weighted Regression (LWR) extends the nearest neighbor search by fitting local models to the neighborhood of an input 
\begin_inset CommandInset citation
LatexCommand cite
key "atkeson1997locally"
literal "false"

\end_inset

.
 LWR has been leveraged successfully to learn forward and inverse dynamics models for control 
\begin_inset CommandInset citation
LatexCommand cite
key "atkeson1997LocallyControl"
literal "false"

\end_inset

.
 Howevern it suffers from significant drawbacks.
 This approach is computationally inefficient as the database of stored points grows.
\end_layout

\begin_layout Standard
To address the inefficiencies of LWR,
 a set of incremental local expert models is maintained to replace raw data storage.
 For example Radial Basis Function (RBF) networks 
\begin_inset CommandInset citation
LatexCommand cite
key "moody1989fast"
literal "false"

\end_inset

 are a common approach.
 The function underlying the data is approximated from the weighted combinations of spatialized local neurons.
 However,
 RBF Networks require the centers of local neurons to be fixed beforehand,
 and the location of these centers plays a crucial role in the model's performance,
 which is a major drawback in the case of online learning.
 This issue has been addressed by designing methods in which neurons can be dynamically added or pruned to match the non-stationarity of a data stream 
\begin_inset CommandInset citation
LatexCommand cite
key "han2010research,jia2025online"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
A notable reference approach in online learning for control is a scalable extension of LWR:
 Locally Weighted Projection Regression (LWPR).
 LWPR manages complex,
 non-linear dynamics by maintaining a set of local linear models that are updated incrementally.
 Each linear model is associated with a radial basis function.
 The final prediction of the model is obtained by computing the average of the closest models weighted by the radial basis function value for the input.
 
\end_layout

\begin_layout Standard
More recent extensions have enabled this type of model to provide uncertainty quantification 
\begin_inset CommandInset citation
LatexCommand cite
key "meier2014incremental"
literal "false"

\end_inset

,
 bridging the gap between frequentist local models and probabilistic models like Gaussian Processes to improve safety guarantees when used in control contexts.
 
\end_layout

\begin_layout Standard
Despite these advancements,
 LWPR exhibits a structural rigidity arising from the tight coupling between its spatialization and update logics.
 Because every local unit is governed by the same predefined statistical update equations,
 the architecture lacks the modularity to incorporate heterogeneous local knowledge (e.g combining linear models with non-linear approximators) or adapt its internal coordination logic to specific regions of the input space to obtain more parsimonious representations (where the modeling complexity of a local expert can be matched to the local complexity of data).
 Furthermore,
 the management of the population of units (creation and pruning) relies on fixed thresholds that do not account for the relational dynamics between overlapping experts.
\end_layout

\begin_layout Standard
Beyond structural rigidity,
 local learning architectures are inherently vulnerable to the curse of dimensionality and the risk of uncontrolled population growth.
 Without carefully designed mechanisms for expert creation and pruning,
 the number of local models can expand exponentially in high-dimensional input spaces,
 leading to computational saturation and overfitting.
\end_layout

\begin_layout Standard
The structural common points between various local learning systems,
 specifically the use of local lower order models and radial basis functions,
 suggest a converging architectural philosophy.
 In this thesis,
 an alternative path is explored to mitigate the aforementioned limitations by shifting the focus from purely statistical optimization to multi-agent social self-organization.
 This approach adopts a bottom-up design philosophy,
 introducing a clear distintion in terms of learning procedure compared to approaches like LWPR.
 The system is described at the lowest level,
 by social rules governing the interactions between local experts.
 Rather than following a global objective function,
 local experts adapt,
 compete or cooperate locally,
 leading to the emergence of learning.
 This shift represents a transition from centralized function approximation to emergent collective behavior where the population size and expert behavior are regulated by local social dynamics rather than global heuristics.
\end_layout

\begin_layout Standard
The following section provides an overview of the literature landscape in the field of Multi-Agent Systems (MAS) for supervised learning.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
More recent extensions have enabled this type of model to provide uncertainty quantification 
\begin_inset CommandInset citation
LatexCommand cite
key "meier2014incremental"
literal "false"

\end_inset

,
 bridging the gap between frequentist local models and probabilistic models like Gaussian Processes to improve safety guarantees when used in control contexts.
 
\end_layout

\begin_layout Plain Layout
However,
 LWPR tightly couples spatialization,
 model structure and update logic,
 limiting modularity and constraining all local experts to the same model class (in this case linear regressions).
 Every local unit is governed by the same predefined statistical update equations and the coordination between units is limited.
 This creates a modeling bottleneck in the sense that the system cannot incorporate different types of local knowledge or adapt its internal coordination logic to specific regions of the input space.
 Furthermore,
 the management of the population of units (creation and pruning) relies on fixed thresholds that do not account for the relational dynamics between overlapping experts.
\end_layout

\begin_layout Plain Layout
The structural common points between various local learning systems suggest a converging architectural philosophy.
 For exemple the kCELL algorithm presented in this thesis in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) shares the use of radial basis functions to spatialize experts to manage non-linearity and non-stationarity with LWPR.
 However,
 the primary distinction lies in the learning procedure.
 While traditional local learning rely on a centralized top-down update logic,
 kCELL is driven by decentralized social feedbacks through a bottom-up design.
 Local experts adapt based on peer interactions,
 competition and cooperation rules rather than global optimization objectives.
 This shift from statistical optimization to multi-agent self-organization represents a transition from 
\emph on
function approximation
\emph default
 to 
\emph on
emergent collective behavior
\emph default
 grounded in explicit local interaction mechanisms.
\end_layout

\begin_layout Plain Layout
Learning methods such as LWPR exhibit a tight coupling between the spatialization logic (how the space is partitioned) and their modeling logic (the local linear regressions).
 This design limits the modularity and heterogeneity of the system.
 In LWPR,
 local units are typically restricted to a single model type and more specifically to linear regressions.
 A more modular architecture,
 where the spatialization layer is agnostic of the internal model,
 would allow for the use of a different class of local models or even for heterogeneous local models (e.g combining linear models with non-linear approximators).
 Such a decoupling theoretically allows for more parsimonious representative systems where the modeling complexity of an expert can be matched to the local complexity of the data.
\end_layout

\begin_layout Plain Layout
Despite their advantages,
 local learning systems remain vulnerable to the curse of dimensionality and uncontrolled growth in the number of experts if pruning and growth mechanisms are not carefully designed.
 In this thesis we mostly explore a more modular architecture through multi-agent social self-organization for supervised online learning (cf.
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 These mechanisms explicitely regulate expert creation,
 adaptation and interactions,
 ensuring a coherent global behavior emerging from local rules.
 In the following section,
 the foundations of multi-agent systems for supervised online learning are explored.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Multiagent Local Learning
\begin_inset CommandInset label
LatexCommand label
name "subsec:Multiagent-Local-Learning"

\end_inset


\end_layout

\begin_layout Standard
As shown in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Local-Online-Learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 local learning architectures exhibit several limitations,
 particularly regarding local experts population management and structural rigidity.
 These limitations motivate the exploration of an alternative research path,
 shifting away from statistical optimization towards the emergence of learning through Multi-Agent Systems (MAS).
\end_layout

\begin_layout Standard
MAS have gained popularity due to their ability to solve complex problems by breaking them down into simpler subproblems that can be easily addressed by autonomous agents,
 whether interconnected or not 
\begin_inset CommandInset citation
LatexCommand cite
key "dorri2018multi"
literal "false"

\end_inset

.
 By defining interaction rules at the individual level,
 the system can foster emergent global behaviors that are scalable and robust.
 The use of MAS has been proven effective in fields such as civil engineering 
\begin_inset CommandInset citation
LatexCommand cite
key "SHAMSHIRBAND20132105"
literal "false"

\end_inset

 or electrical engineering,
 specifically with issues related to smart grids 
\begin_inset CommandInset citation
LatexCommand cite
key "rohbogner2014design"
literal "false"

\end_inset

.
 The application of MAS also have been considered to tackle supervised learning problems,
 representing a distinct and original trajectory in machine learning research in which learning emerges from the organization of a dynamic set of local models called context agents 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability,nigon2017smart"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
This multi-agent modeling paradigm is rooted in the Self-Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,verstaevel2017lifelong"
literal "false"

\end_inset

.
 The learning problem is redefined as the construction,
 selection,
 and adaptation of local models encapsulated within agents,
 where the objective is to identify which local models best represent its neighborhood in the input space.
\end_layout

\begin_layout Standard
Early research works applied this paradigm to the control of complex bioprocesses 
\begin_inset CommandInset citation
LatexCommand cite
key "videau2011controlling"
literal "false"

\end_inset

 and industrial systems 
\begin_inset CommandInset citation
LatexCommand cite
key "boes2017self"
literal "false"

\end_inset

.
 These works demonstrated that by encapsulating a local context,
 a control action and a prediction with a context agent,
 a system could achieve high adaptivity through cooperative self-organization.
 However,
 these early implementations were primarily designed as myopic reactive controllers,
 without anticipation capabilities.
 While being able to adapt to non-stationarity,
 they lacked the predictive horizon required for the proactive planning necessary in safety-critical use cases.
\end_layout

\begin_layout Standard
Then,
 this approach has been generalized beyond simple regulation.
 It has been successfully transposed to classification tasks 
\begin_inset CommandInset citation
LatexCommand cite
key "verstaevel2016self,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

.
 Recent advancements have leveraged the introspection capabilities of agents to improve generalizability through active learning 
\begin_inset CommandInset citation
LatexCommand cite
key "dato2021apprentissage"
literal "false"

\end_inset

 and have demonstrated that the social behavior of agents can be used to extract novel explainability metrics 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
Moreover,
 the architectural modularity permitted by agents,
 theoretically allows for heterogeneous systems where the modling complexity of an individual agent could be tailored to the local complexity of the data 
\begin_inset CommandInset citation
LatexCommand cite
key "fourez2024analyzing"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In more recent years,
 reinforcement learning has been seriously considered to bypass the phase of designing rules that define agent behavior.
 Indeed,
 in Multi-Agent Reinforcement Learning (MARL),
 agents' behaviors are learning using reinforcement signals obtained by interaction with an environment 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
 It is important to distinguish MARL from supervised learning with context agents.
 While both rely on a set of local agents,
 their learning mechanisms differ.
 In MARL,
 agents' behavior are typically learned end-to-end to maximize a cumulative reward signal,
 often requiring millions of iterations to converge 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
 In contrast,
 the context agent approach used in this thesis combines fixed social interaction rules with immediate,
 simplified reinforcement signals (e.g.
 discrete good/bad feedbacks) rather than complex reward-shaping.
 This way,
 learning with context agent achieves significantly faster convergence and requires fewer iterations to adapt to a data stream 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
By shifting from global,
 static approximators to a bottom-up self-organization of autonomous local experts,
 the system gains te structural adaptability required to learn in a non-stationary environment.
 This multi-agent perspective transforms the learning problem into a self-regulating social process,
 ensuring that the model's variety can evolve alonside the complexity of the task without suffering catastrophic interference that are typical of global architectures.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Multi-agent systems (MAS) have gained popularity due to their ability to solve complex problems by breaking them down into simpler sub-problems that can be easily addressed by autonomous agents,
 whether interconnected or not 
\begin_inset CommandInset citation
LatexCommand cite
key "dorri2018multi"
literal "false"

\end_inset

.
 The interaction rules between agents or with the environment are defined by the system designer to achieve a specific objective.
 The use of MAS has proven effective in fields such as civil engineering 
\begin_inset CommandInset citation
LatexCommand cite
key "SHAMSHIRBAND20132105"
literal "false"

\end_inset

 or electrical engineering,
 particularly with issues related to smart grids 
\begin_inset CommandInset citation
LatexCommand cite
key "rohbogner2014design"
literal "false"

\end_inset

.
\end_layout

\begin_layout Plain Layout
=> An original approach to learning based on multiagent systems has been developed and it results from the organization of a dynamic set of local models called context agents 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "nigon2017smart"
literal "false"

\end_inset

.
\end_layout

\begin_layout Plain Layout
=> This learning method inherently local and tailored for online learning.
 Multiagent local learning is also grounded in ensemble learning => can be assimilated to Bagging in particular.
\end_layout

\begin_layout Plain Layout
=> In more recent years,
 reinforcement learning has been seriously considered to bypass the phase of designing rules that define agent behavior.
 Indeed,
 in Multi-Agent Reinforcement Learning (MARL),
 agents' behaviors are learned using reinforcement signals obtained by continuously interacting with an environment 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
 => works of this thesis is not MARL.
 Learning with context agents combines both approach:
 fixed interaction rules and reinforcement learning.
 Agents update using both reinforcement signals and cooperation rules.
 Unlike MARL,
 multiagent learning for supervised learning involves simpler reinforcement signals (e.g good,
 bad,
 ...) instead of complex rewards based on overall perforrmance.
 Moreover,
 it requires fewer iterations to converge 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset

 differing from MARL interactions with environemnt aiming at maximizing cumulative rewards.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "videau2011controlling"
literal "false"

\end_inset

 => Control of bioprocesses toward user defined objectives without prior knowledge of the system's dynamics => Limitation:
 myopic regulation (no prediction horizon)
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,verstaevel2017lifelong"
literal "false"

\end_inset

 Introduction of SACL Learning paradigm (inspiration of the works of this thesis) => The approach is based on the construction,
 selection,
 and adaptation of local models encapsulated within agents.
 The learning problem then consists in selecting,
 for each region of the input parameter space,
 the context agents that contain the most effective local models.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "boes2017self"
literal "false"

\end_inset

 => Control of complex systems => bottom up approach design for controller for complex system based on adaptive multiagent systems (AMAS) with context agents => context agents contain description of the situation (context),
 an action and estimation of action consequences on objective function (prediction) => cooperative self organization for adaptivity,
 scalability and robustness => emergence of learned control => Limitation:
 myopic regulation (no predictive horizon) 
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "verstaevel2016self"
literal "false"

\end_inset

 => transposition of context agent learning to the problem of classification => a context agent is associated with a class => each agent is a local classifier
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "dato2021apprentissage"
literal "false"

\end_inset

 Generalization of Context Agent learning to regression + Active Learning => use internal properties (i.e introspection capabilities) linked to neighboring experts to improve generalizability
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

 => online classification with context agents => theorically modular framework allowing for use of heterogeneous models 
\begin_inset CommandInset citation
LatexCommand cite
key "fourez2024analyzing"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset

 => modification of the aggregation function of agents prediction to build the final prediction of the system + showed that observing the behavior of agents in the system allows to extract novel explainability metrics
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Multi-agent systems (MAS) have gained popularity due to their ability to solve complex problems by breaking them down into simpler sub-problems that can be easily addressed by autonomous agents,
 whether interconnected or not 
\begin_inset CommandInset citation
LatexCommand cite
key "dorri2018multi"
literal "false"

\end_inset

.
 The interaction rules between agents or with the environment are defined by the system designer to achieve a specific objective.
 The use of MAS has proven effective in fields such as civil engineering 
\begin_inset CommandInset citation
LatexCommand cite
key "SHAMSHIRBAND20132105"
literal "false"

\end_inset

 or electrical engineering,
 particularly with issues related to smart grids 
\begin_inset CommandInset citation
LatexCommand cite
key "rohbogner2014design"
literal "false"

\end_inset

.
 In more recent years,
 reinforcement learning has been seriously considered to bypass the phase of designing rules that define agent behavior.
 Indeed,
 in Multi-Agent Reinforcement Learning (MARL),
 agents' behaviors are learned using reinforcement signals obtained by continuously interacting with an environment 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\begin_layout Plain Layout
In this chapter,
 we present various two instantiations of CELL,
 a MAS paradigm derived from the Self Adaptive Context Learning (SACL) 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 that combines both approaches to tackle online supervised learning problems.
 Agents of the system update using both reinforcement learning signals and cooperation rules.
 Unlike MARL,
 CELL requires fewer environment interactions and focuses on specialized agents collaborating within a supervised learning framework,
 differing from MARL's dynamic interactions aiming to maximize cumulative rewards through adaptive strategies (
\emph on
competitive
\emph default
 or 
\emph on
cooperative
\emph default
) 
\begin_inset CommandInset citation
LatexCommand cite
key "canese2021multi"
literal "false"

\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsection
XAI and Uncertainty
\begin_inset CommandInset label
LatexCommand label
name "subsec:XAI"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
The field of eXplainable Artificial Intelligence (XAI) addresses the opacity of complex models by providing insights into their decision-making processes.
 However,
 interpretability and explainability are defined in various ways 
\begin_inset CommandInset citation
LatexCommand cite
key "gilpin2018explaining,doshi2017towards"
literal "false"

\end_inset

 and often used interchangeably.
 Thus,
 following the distinction made in 
\begin_inset CommandInset citation
LatexCommand cite
key "burkart2021survey"
literal "false"

\end_inset

,
 we differentiate between interpretability and explainability.
 
\series bold
Interpretability
\series default
 is defined as the inherent ability to understand how the model works as a whole,
 focusing on the model's structure and mechanisms (i.e transparency).
 In contrast,
 
\series bold
Explainability 
\series default
is associated with the methodologies used to communicate the reasoning for a specific decision taken by a model.
\end_layout

\begin_layout Plain Layout
Approaches such as deep learning achieve good performance across a wide variety of tasks.
 However,
 these approaches generate highly complex models.
 There must be a compromise between the model's performance and its ability to produce explainable predictions and interpretable structures 
\begin_inset CommandInset citation
LatexCommand cite
key "linardatosExplainableAIReview2020"
literal "false"

\end_inset

.
 Some approaches were developed to adress the explainability of predictions.
 SHAP looks for the impact of each feature on the prediction using cooperative game theory 
\begin_inset CommandInset citation
LatexCommand cite
key "lundberg2017unified"
literal "false"

\end_inset

 and LIME builds an interpretable surrogate model that approximate a black-box model locally 
\begin_inset CommandInset citation
LatexCommand cite
key "ribeiro2016should"
literal "false"

\end_inset

.
\end_layout

\begin_layout Plain Layout
Within this discourse,
 machine learning models are typically categorized as white-box or black-box models 
\begin_inset CommandInset citation
LatexCommand cite
key "loyola-gonzalezBlackBoxVsWhiteBox2019"
literal "false"

\end_inset

.
 
\series bold
Black-box
\series default
 models have opaque and complex inner workings that are difficult for an external observer to understand.
 This categorisation includes deep learning models 
\begin_inset CommandInset citation
LatexCommand cite
key "lecunDeepLearning2015"
literal "false"

\end_inset

 and some ensemble models 
\begin_inset CommandInset citation
LatexCommand cite
key "breimanRandomForests2001,polikarEnsembleLearning2012,chenXGBoostScalableTree2016,keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

.
 Conversely,
 
\series bold
White-box
\series default
 models have simpler and less opaque inner workings.
 These models,
 considered more explainable than black-box models,
 include linear regression models 
\begin_inset CommandInset citation
LatexCommand cite
key "weisbergAppliedLinearRegression2005"
literal "false"

\end_inset

,
 decision trees 
\begin_inset CommandInset citation
LatexCommand cite
key "rokachDecisionTrees2005"
literal "false"

\end_inset

 and other rule-based approaches.
 To achieve explainability,
 white-box models are preferred.
\end_layout

\begin_layout Plain Layout
The explainability of a prediction is partly linked to the concept of uncertainty.
 An informed decision-making process must take uncertainty into account.
 We distinguish between epistemic uncertainty and aleatoric uncertainty 
\begin_inset CommandInset citation
LatexCommand cite
key "chuaDeepReinforcementLearning2018,hullermeierAleatoricEpistemicUncertainty2021"
literal "false"

\end_inset

.
 
\series bold
Aleatoric uncertainty
\series default
 arises from the inherent natural variations in the studied phenomena.
 It may be due to random fluctuations,
 measurement errors,
 or other unpredictable factors.
 
\series bold
Epistemic uncertainty
\series default
 on the other hands,
 stems from a lack of knowledge or complete understanding of the studied phenomenon.
 This type of uncertainty is related to the lack of data in certain regions of the feature space.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsection
Ensemble Learning
\end_layout

\begin_layout Plain Layout
To achieve more accurate predictions and provide better approximations of nonlinear functions,
 it is common to aggregate multiple models for making predictions.
\end_layout

\begin_layout Plain Layout
Ensemble learning is based on the emergence of collective intelligence within a set of weak learners.
 A weak learner is a model whose performance is at least as good as a model making random predictions.
 During the learning process,
 a set of models (which may differ from one another) are trained in parallel or sequentially 
\begin_inset CommandInset citation
LatexCommand cite
key "polikarEnsembleLearning2012"
literal "false"

\end_inset

.
 The objective is to encourage diversity among the models so that they do not all capture the same patterns in the data 
\begin_inset CommandInset citation
LatexCommand cite
key "dietterichEnsembleMethodsMachine2000"
literal "false"

\end_inset

.
 An input is transmitted to all weak learners,
 each of which makes a prediction proposal.
 A heuristic is implemented to select one of the proposals or to weight each of them in order to construct the final prediction.
 We distinguish several major approaches in ensemble learning which are Boosting,
 Bagging and Stacking.
\end_layout

\begin_layout Plain Layout
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add figure to compare bagging,
 boosting and stacking
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visual comparison of bagging,
 boosting and stacking
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
In Bagging 
\begin_inset CommandInset citation
LatexCommand cite
key "breiman1996bagging"
literal "false"

\end_inset

 multiple models (usually homogeneous) are trained in parallel on different subsets of the training data to introduce diversity,
 reduce variance and improve stability.
 Then the final prediction is obtained by averaging the predictions of the weak learners (regression) or by majority voting (classification).
 Unlike Bagging,
 in Boosting 
\begin_inset CommandInset citation
LatexCommand cite
key "freund1997decision"
literal "false"

\end_inset

,
 the models are trained sequentially.
 Each new model focuses on correcting the errors of the previous ones to reduce bias and improve accuracy.
 Then the final prediction is obtained from a weighted average of the predictions of the all the weak learners.
 Finally,
 there is Stacking 
\begin_inset CommandInset citation
LatexCommand cite
key "wolpert1992stacked"
literal "false"

\end_inset

 that falls under meta-learning.
 We train in parallel a set of heterogeneous models and then a meta-model is trained to combine the predictions of each model to obtain the final output of the system,
 in order to capture complementary strengths of each learning algorithms involved in the learning process.
\end_layout

\begin_layout Plain Layout
The family of systems presented in this chapter,
 CELL,
 falls within ensemble learning and we could label it as a Bagging approach because we consider a set of weak learners as a collection of self-organizing cooperative agents.
 Each one of them is a local expert on the function to be approximated.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Synthesis and Research Gaps
\end_layout

\begin_layout Standard
The transition from Batch Learning with global learners to local self-organizing Online Learning highlights a tension between generalization capabilities and adaptability to non-stationarity (e.g stability-plasticity dilemma).
 In this section,
 we synthesize the reviewed literature to identify the specific research gaps that motivate the works of this thesis.
\end_layout

\begin_layout Standard
In the context of this thesis,
 some of the core challenges of Online Learning like catastrophic forgetting,
 non-stationarity and uncertainty take on a specific meaning:
\end_layout

\begin_layout Itemize

\series bold
Mitigation of Catastrophic Forgetting
\series default
:
 Traditional global approximators such as deep neural networks suffer from catastrophic forgetting because for each update,
 every parameter of the network can be impacted,
 potentially reshaping the entire knowledge base.
 They remain structurally vulnerable to forgetting,
 despite being powerful function approximators,
 very efficient in Batch Learning.
 The works of this thesis favor Spatial Isolation of parameters through local learning to alleviate this issue.
 Restricting updates to specific regions of the input space ensures that newly acquired knowledge does not corrupt representations that correspond to unrelated contexts.
 
\end_layout

\begin_layout Itemize

\series bold
Handling of Non-Stationarity
\series default
:
 Human behavior in HRC is inherently non-stationary.
 Parametric models are limited by a capacity ceiling (fixed number of parameters).
 In this thesis,
 we argue for the use of Non-Parametric methods because they allow the model's complexity to grow and refine alongside the data stream.
 By treating the model as an evolving population of agents rather than a frozen set of weights,
 the Ashby's Law of Requisite Variety can be satisfied.
\end_layout

\begin_layout Itemize

\series bold
Estimation of Epistemic Uncertainty
\series default
:
 Safety in HRC requires the controller to know when its internal model is unreliable.
 Unlike global black-box models that may confidently extrapolate in Out-of-Distribution (OoD) regions,
 learning with local experts provides a natural mechanism for epistemic uncertainty quantification.
 The spatialization of experts allows the system to detect knowledge gaps in the input space.
 For example with multi-agent local learning approaches based on a set of expert agents,
 if no expert is close for a given input,
 the system can signal a high epistemic uncertainty (no training data 
\begin_inset Formula $\rightarrow$
\end_inset

 no expert 
\begin_inset Formula $\rightarrow$
\end_inset

 no reliable prediction).
\end_layout

\begin_layout Standard
This section argued for the promising nature of Local Learning approaches for HRC.
 However,
 most existing reference approaches such as LWPR,
 exhibit a structural rigidity where the spatialization and update logics are tightly coupled.
 This limits the modularity of such system,
 presenting the use of heterogeneous models in the system that could allow for more parsimonious local learner by better representing the local complexity of the data.
 Indeed,
 local learners often suffer from local expert overgrowth.
 Without carefully designed mechanisms for expert creation and pruning,
 the number of local models can expand exponentially in high-dimensional input spaces,
 leading to computational saturation and overfitting.
\end_layout

\begin_layout Standard
To address these limitations,
 this thesis works explore local learning through multi-agent systems.
 This kind of system exhibits an architecture where spatialization and updates are decoupled,
 in which social cooperation or competition rules regulate the population can be considered.
 This bottom-up design philosophy introduces more possibilities in terms of modularity,
 enabling the use for a broader diversity in the classes of local learners.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
- Synthesis of reasoning
\end_layout

\begin_layout Plain Layout
- Recap Limitations and needed properties for safe
\end_layout

\begin_layout Plain Layout
- Positioning through table
\end_layout

\begin_layout Itemize
Ensemblist method ?
\end_layout

\begin_layout Itemize
Parametric,
 non-Parametric ?
\end_layout

\begin_layout Itemize
Non-Stationarity Handling ?
 => handles non-stationarity by the non-parametric anture
\end_layout

\begin_layout Itemize
OoD (Out of Distribution) Predictions ?
 => with non parametric local models epistemic uncertainty (if a data point has been seen or not at training time) ca be estimated through the spatialization of models => no expert = no data = no reliable predictions
\end_layout

\begin_layout Itemize
Transparency of inner workings (black box / white box)
\end_layout

\begin_layout Itemize
differentiable
\end_layout

\begin_layout Plain Layout
- Why we explore mutliagent learning ?
 => compare to LWPR because this is the closest we have and position our approach correctly
\end_layout

\end_inset


\end_layout

\begin_layout Section
Positioning
\begin_inset CommandInset label
LatexCommand label
name "sec:Positioning"

\end_inset


\end_layout

\begin_layout Chapter
Context Ensemble Local Learning (CELL)
\begin_inset CommandInset label
LatexCommand label
name "chap:Context-Ensemble-Local"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Through oCELL we extend the multiagent learning towards regression tasks and show potential for introspection then with kCELL we demonstrate the non-stationary learning capabilities.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To achieve speed recommendation,
 the behavior of a vehicle driven by a human driver in response to speed recommendation set points need to be modeled.
 Therefore,
 we need a modeling algorithm able to perform online learning and learn efficiently seeing a data point once while having transparent inner workings and explainable predictions.
 For that reason we explored the use of multiagent systems as a mean of solving supervised learning tasks.
\end_layout

\begin_layout Standard
As showed in 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 a supervised learning problem can be modeled as a multiagent system.
 This perspective offers several advantages,
 including design simplicity,
 transparency,
 interpretability and explainability properties that naturally emerge from the structural organization of agents.
\end_layout

\begin_layout Standard
Building upon the Self Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

,
 this chapter introduces the CELL (Context Ensemble Local Learning) learning paradigm,
 which provides the core hypotheses and theoretical grounds for designing spatialized multiagent learning systems suited for modeling the dynamics of complex systems from online streaming data.
 This paradigm addresses online supervised learning through self-organization of multiple local expert agents paving the feature space.
 These agents are created and updated dynamically according to predefined learning rules.
 Each agent occupies a specific region in feature space,
 representing the area where it is most confident in the quality of its predictions.
 Contrary to previous works on this type of system 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 we introduce novelties regarding explainability and interpretability while exploring new cooperation mechanisms between agents and new spatialization approaches.
\end_layout

\begin_layout Standard
By leveraging the spatialization of local experts and the inherent transparency of the model,
 we derive unique informative explainability properties that provide valuable insights about the approximated function.
 Furthermore,
 we outline practical guidelines for scaling with the number of agents,
 keeping a bounded computational complexity.
 Therefore,
 the CELL paradigm is introduced through two distinct learning systems:
 oCELL and kCELL.
\end_layout

\begin_layout Standard
First,
 in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 oCELL is introduced,
 its capabilities are presented in terms of predictive performance and explainability,
 as well as its structural limitations.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 then describes kCELL,
 a more robust and expressive instantiation of CELL that addresses several of oCELL's limitations while preserving its intrinsic explainability and interpretability properties.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Parallelization-and-Differentiability"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses practical considerations for efficient implementation,
 including strategies for obtaining differentiable operations,
 GPU parallelization and spatial indexing to optimize learning speed and inference.
\end_layout

\begin_layout Section
CELL Learning Paradigm
\begin_inset CommandInset label
LatexCommand label
name "sec:CELL-Learning-Paradigm"

\end_inset


\end_layout

\begin_layout Section
oCELL:
 Multiagent Ensemble Learning with Orthotopes
\begin_inset CommandInset label
LatexCommand label
name "sec:oCELL"

\end_inset


\end_layout

\begin_layout Standard
This section introduces the first instantiation of CELL,
 referred to as oCELL (orthotope CELL).
 CELL systems are multiagent systems composed of autonomous agents,
 each possessing local knowledge and specific capabilities.
 These systems build upon the Self-Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to address online supervised learning tasks.
\end_layout

\begin_layout Standard
The objective is to approximate a function 
\begin_inset Formula $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}$
\end_inset

 that maps feature vectors to target vectors from a continuous stream of data.
 oCELL processes incoming data points by routing them to its primary components,
 the context agents.
 These agents are dynamically created and updated according to predefined learning rules.
 Each agent occupies a distinct region of the feature space defined as an orthotope,
 where it maintains the highest confidence in its predictions.
 This spatial organization allows agents to determine 
\emph on
when
\emph default
 they should contribute to the prediction process.
 To determine 
\emph on
what
\emph default
 to predict,
 each agent maintains a local machine learning model over its confidence region.
\end_layout

\begin_layout Standard
First,
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Context-Agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the internal structure of context agents is described,
 including their spatialization in the feature space and their prediction mechanisms.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Learning-Rules"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces the learning rules that cover agent creation,
 adaptation and self-organization leading to the emergence of learning in the system.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Comparative-Study"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a comparative study evaluating the performance of oCELL against other machine learning algorithms on a two-dimensional benchmark.
 Subsequently,
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents an analysis of the capabilities of oCELL in terms of interpretability and explainability,
 which naturally arise from the spatial organization of agents.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses the limitations of oCELL and outline directions for future research,
 some of which are addressed in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Context Agents
\begin_inset CommandInset label
LatexCommand label
name "subsec:Context-Agents"

\end_inset


\end_layout

\begin_layout Standard
The main entities of oCELL are context agents.
 A context agent,
 denoted as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i},f_{i}\right\} 
\]

\end_inset

is defined by two core components:
 an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

.
 The activation function determines whether the agent should contribute to the prediction for a given input 
\begin_inset Formula $x$
\end_inset

,
 while the prediction function provides the corresponding output.
\end_layout

\begin_layout Standard
Each agent can adapt the parameters of its activation and prediction functions based on reinforcement signals derived from its performance,
 enabling it to refine its behavior according to local conditions in feature space.
 Conceptually,
 a context agent acts as a local expert for the target function with activation function governing 
\emph on
when
\emph default
 the agent predicts and the prediction function specifying 
\emph on
what
\emph default
 it predicts.
\end_layout

\begin_layout Standard
First,
 the spatialization mechanism of context agents based on orthotopes is described.
 Then the prediction mechanisms arising from interactions within an agent’s neighborhood are detailed.
\end_layout

\begin_layout Subsubsection
Spatialization with Orthotopes
\begin_inset CommandInset label
LatexCommand label
name "subsec:Spatialization-with-Orthotopes"

\end_inset


\end_layout

\begin_layout Standard
To ensure transparency and interpretability,
 oCELL spatialize context agents using orthotopes (also referred to as hyper-rectangles in the literature).
 Orthotopes provide a clear geometric representation of an agent's confidence region in the feature space,
 allowing precise evaluation of local structures and facilitating shape adaptation during self-organization.
 This representation allows independent manipulation of each feature dimension,
 simplifying expansion and retraction operations.
\end_layout

\begin_layout Standard
Learning with orthotopes has been explored in previous works on supervised learning 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022,konstantinov2023interpretable"
literal "false"

\end_inset

.
 These approaches typically partition the feature space into orthotopes and model the target function locally.
 For instance,
 
\begin_inset CommandInset citation
LatexCommand cite
key "konstantinov2023interpretable"
literal "false"

\end_inset

,
 employs a gradient boosting to learn orthotope bounds,
 where each region corresponds to a simple constant model.
 However this approach is not suitable for online learning from data streams.
\end_layout

\begin_layout Standard
oCELL borrows a similar spatialization principle to 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 which uses the SACL paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to progressively pave the feature space with context agents to address classification tasks.
 However,
 unlike 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 oCELL addresses issues specifically related to regression tasks such as the need for a smoother spatialization of agents to smooth prediction accuracy (i.e smooth the learned function).
\end_layout

\begin_layout Standard
Each agent's activation function defines a 
\begin_inset Formula $n$
\end_inset

-dimensional orthotope in the feature space.
 For each feature dimension 
\begin_inset Formula $j\in\left\{ 1,\dots,n\right\} $
\end_inset

,
 the orthotope is parameterized by a lower bound 
\begin_inset Formula $l_{j}$
\end_inset

 and an upper bound 
\begin_inset Formula $h_{j}$
\end_inset

 such as
\begin_inset Formula 
\begin{equation}
\mathcal{H}_{i}=\left[l_{1},h_{1}\right]\times\dots\times\left[l_{n},h_{n}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The volume 
\begin_inset Formula $v\left(\mathcal{A}_{i}\right)$
\end_inset

 of the orthotope associated to 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined by
\begin_inset Formula 
\begin{equation}
v\left(\mathcal{A}_{i}\right)=\prod_{j=1}^{n}\left(h_{j}-l_{j}\right)\label{eq:orthotope-volume}
\end{equation}

\end_inset

An observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is considered as intersecting an orthotope if,
 for all feature 
\begin_inset Formula $j$
\end_inset

,
 
\begin_inset Formula 
\begin{equation}
l_{j}\leq x_{j}\leq h_{j}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Additionaly,
 an orthotope 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 intersects another orthotope 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

 if,
 for all feature 
\begin_inset Formula $j$
\end_inset

,
\begin_inset Formula 
\begin{equation}
\max\left(l_{1,j},l_{2,j}\right)\leq\min\left(h_{1,j},h_{2,j}\right)\label{eq:orthotope-intersection}
\end{equation}

\end_inset

with 
\begin_inset Formula $l_{1,j}$
\end_inset

,
\begin_inset Formula $l_{2,j}$
\end_inset

 and 
\begin_inset Formula $h_{1,j}$
\end_inset

,
\begin_inset Formula $h_{2,j}$
\end_inset

 denote the lower and upper bounds of 
\begin_inset Formula $\mathcal{H}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Agents in oCELL are constructed based on the assumption of uniform knowledge over their confidence region,
 i.e the area delimited by the associated orthotope.
 We distinguish between activation and neighborhood.
 When an agent is activated by a point,
 it means it is confident in its expertise to predict for that point.
 When an agent is a neighbor of a point,
 it means it has doubts about its expertise to predict for that point.
 In other words,
 it is an agent that is a candidate to become an activated agent for that point.
 The way an agent updates itself differs depending on whether the agent is activated or a neighbor.
\end_layout

\begin_layout Definition
A Context Agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is considered activated by an observation 
\begin_inset Formula $x$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 intersects with the orthotope 
\begin_inset Formula $\mathcal{H}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{\mathcal{H}}:\mathbb{R}^{n}\mapsto\left\{ 0,1\right\} $
\end_inset

 of 
\begin_inset Formula $\mathcal{A}$
\end_inset

.
 In other words,
 we define the activation function of 
\begin_inset Formula $\mathcal{A}$
\end_inset

 as
\begin_inset Formula 
\begin{equation}
\phi_{\mathcal{H}}\left(x\right)=\begin{cases}
1 & \text{if}\,\,\forall j,\,\,l_{j}\leq x_{j}\leq h_{j}\\
0 & \text{else}
\end{cases}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The neighborhood of an observation 
\begin_inset Formula $x$
\end_inset

 is defined as an orthotope 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset

 centered on 
\begin_inset Formula $x$
\end_inset

.
 A context Agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is considered a neighbor of 
\begin_inset Formula $x$
\end_inset

 if the orthotope 
\begin_inset Formula $\mathcal{H}_{i}$
\end_inset

 associated with the activation function 
\begin_inset Formula $\phi_{i}$
\end_inset

 of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

,
 intersects with 
\begin_inset Formula $\mathcal{H}_{\text{neighborhood}}$
\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:orthotope-intersection"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
For self-organization,
 agents must adapt their shape and position in the feature space.
 Unlike 
\begin_inset CommandInset citation
LatexCommand cite
key "fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 which minimizes overlap to avoid ambiguity in classification (for example agents could push each other),
 oCELL allows overlapping regions to allow prediction smoothing through ensemble averaging.
 This property is particularly useful for regression tasks as it can be more informative to average the predictions of several weak models to smooth the learned function.
 It also facilitates integration into non-linear optimization processes (cf.
 section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Hard-Constraints"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Therefore,
 an agent can change its shape by contracting or expanding its orthotope without worrying about the positions of other agents.
\end_layout

\begin_layout Definition
If a context agent 
\begin_inset Formula $\mathcal{A}$
\end_inset

 expands (resp.
 contracts) by a factor 
\begin_inset Formula $\alpha$
\end_inset

 in the direction of an observation 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

,
 then the upper bounds 
\begin_inset Formula $h_{j}^{t}$
\end_inset

 and lower bounds 
\begin_inset Formula $l_{j}^{t}$
\end_inset

 of the associated orthotope are updated according to the following relationship:
\begin_inset Formula 
\begin{align}
h_{j}^{t+1} & =\begin{cases}
\left(h_{j}^{t}-l_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+l_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
h_{j}^{t} & \text{else}
\end{cases}\\
l_{j}^{t+1} & =\begin{cases}
\left(l_{j}^{t}-h_{j}^{t}\right)\varepsilon^{\frac{1}{k}}+h_{j}^{t} & \text{if }l_{j}^{t}\leq x_{j}\leq h_{j}^{t}\\
l_{j}^{t} & \text{else}
\end{cases}
\end{align}

\end_inset

with
\begin_inset Formula 
\begin{equation}
\varepsilon=\begin{cases}
\left(1+\alpha\right) & \text{if expansion}\\
\left(1-\alpha\right) & \text{if retraction}
\end{cases}
\end{equation}

\end_inset

and 
\begin_inset Formula $k$
\end_inset

 the number of features such that 
\begin_inset Formula $l_{j}^{t}\leq x_{j}\leq h_{j}^{t}$
\end_inset

.
 Thus,
 the new volume of the orthotope associated with 
\begin_inset Formula $\mathcal{A}$
\end_inset

 is given by the relation:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align}
v_{\mathcal{A}}^{t+1} & =\varepsilon v_{\mathcal{A}}^{t}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
In summary,
 agents are spatialized through activation functions defining orthotopes that represent their 
\emph on
confidence region
\emph default
 (i.e area of expertise) in feature space.
 Each agent can adapt its bounds,
 expanding or contracting its associated orthotope as needed.
 Intuitively,
 larger agents act as 
\emph on
generalists
\emph default
,
 while smaller agents serve as 
\emph on
specialists
\emph default
.
 Consequently,
 complex regions of feature space tend to host many small agents,
 whereas simpler regions tend to be covered by fewer larger agents.
 This assumption aligns with the use of simple local models such as linear regressions,
 which we leverage in subsequent experiments to demonstrate the transparency and interpretability of oCELL.
\end_layout

\begin_layout Subsubsection
Neighborhood Prediction
\begin_inset CommandInset label
LatexCommand label
name "subsubsec:Neighborhood-Prediction"

\end_inset


\end_layout

\begin_layout Standard
The objective of oCELL is to perform online regression from a continuous data stream.
 Spcifically,
 it aims at modeling the nonlinear dynamics of a complex system for subsequent use in an optimization pipeline for optimal control (see Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Therefore,
 it is desirable to minimize gradient noise and ensure the learned function is smooth,
 as irregularities can significantly disrupt the optimization process 
\begin_inset CommandInset citation
LatexCommand cite
key "nesterov2013introductory"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
To achieve this,
 oCELL allows multiple agents to contribute to the final prediction,
 in contrast to previous works 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015,dato2021apprentissage,fourezEnsembleMultiAgentSystem2022"
literal "false"

\end_inset

,
 where a single agent was ultimately selected for prediction.
\end_layout

\begin_layout Standard
To obtain the prediction 
\begin_inset Formula $\hat{y}$
\end_inset

 from an observation 
\begin_inset Formula $x$
\end_inset

,
 the most competent agents are selected to predict the value of 
\begin_inset Formula $\hat{y}$
\end_inset

.
 If some agents are neighbors of 
\begin_inset Formula $x$
\end_inset

,
 then they each make a prediction proposal.
 If 
\begin_inset Formula $x$
\end_inset

 has no neighbor,
 the 
\begin_inset Formula $k$
\end_inset

-closest agents are selected instead.
 This fallback mechanism prevents prediction failures in regions where the system has limited knowledge (i.e poor paving of the area around 
\begin_inset Formula $x$
\end_inset

).
 The final prediction is then given by the arithmetic mean of the proposals of selected agents such as
\begin_inset Formula 
\[
\hat{y}=\frac{1}{\left|D_{\text{selected}}\right|}\times\sum_{i\in D_{\text{selected}}}f_{i}\left(x\right)
\]

\end_inset

where 
\begin_inset Formula $D_{\text{selected}}$
\end_inset

 is the set of selected agents (neighbors or closest) and 
\begin_inset Formula $f_{i}\in\mathbb{R}^{m}$
\end_inset

 the internal prediction function of the 
\begin_inset Formula $i$
\end_inset

-th agent.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/cell_prediction_diagram.png
	lyxscale 30
	width 90text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of the prediction process with agents in CELL paradigm
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-cell-prediction"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Learning Rules
\begin_inset CommandInset label
LatexCommand label
name "subsec:Learning-Rules"

\end_inset


\end_layout

\begin_layout Standard
In CELL systems,
 the design of learning rules revolves around a set of actions and trigger conditions that decide how to digest the continuous stream of 
\begin_inset Formula $\left(x_{new},y_{new}\right)$
\end_inset

 data.
 Some actions are tied to individual agents such as updating their model (prediction function) or shape (activation function);
 and others are more meta-level actions such as destroying or creating new agents.
 These actions are triggered by conditions.
 In oCELL,
 those conditions depend on the number of current neighbors,
 on the number of activated agents and on a feedback values calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
To determine the appropriate action for an agent,
 we define the prediction quality 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

 of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as
\begin_inset Formula 
\[
L_{\mathcal{A}_{i}}=g\left(\hat{y},y\right)
\]

\end_inset

 where 
\begin_inset Formula $g:\mathbb{R}^{m}\times\mathbb{R}^{m}\mapsto\mathbb{R}$
\end_inset

 is a distance measure between the proposal 
\begin_inset Formula $\hat{y}$
\end_inset

 and the true value 
\begin_inset Formula $y$
\end_inset

.
 The largest 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

,
 the worse the quality of the proposal.
 In oCELL,
 we use the squared error as the 
\begin_inset Formula $g$
\end_inset

 function but other types of error functions could be used instead.
\end_layout

\begin_layout Standard
We define two thresholds 
\begin_inset Formula $\tau_{\text{good}}$
\end_inset

 and 
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset

 to partition the values of 
\begin_inset Formula $L_{\mathcal{A}_{i}}$
\end_inset

 into three regimes:
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

 for 
\emph on
good
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

 for 
\emph on
inaccurate
\emph default
 predictions,
 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

 for 
\emph on
bad
\emph default
 predictions.
 These thresholds control the degree of accuracy expected from the system and influence the frequency of some rule activation.
\end_layout

\begin_layout Paragraph
Inaccuracy
\end_layout

\begin_layout Standard
When there are 
\begin_inset Formula $N_{A}\geq1$
\end_inset

 activated agents for 
\begin_inset Formula $x_{new}$
\end_inset

,
 it means the region around 
\begin_inset Formula $x_{new}$
\end_inset

 is already known because it is covered by agents.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset

,
 it means the prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 and it was right to declare itself as an expert on 
\begin_inset Formula $x_{new}$
\end_inset

.
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 will therefore seek to generalize in the direction of 
\begin_inset Formula $x_{new}$
\end_inset

 by extending its area of expertise.
 If 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 then the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
inaccurate
\emph default
 but not catastrophic,
 so it only refines its internal model and keeps its positions waiting for another signal to expand if needed.
 Then,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset

,
 the prediction of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
bad,

\emph default
 meaning that it shouldn't have been activated.
 In reaction to that,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 will retract to get away from 
\begin_inset Formula $x_{new}$
\end_inset

.
 This rule is the core of agents local self-organization.
 It allows the agents to move in feature space and refine their model as needed to exclude or include points to better model their close surroundings in response to feedbacks on the quality of their predictions.
\end_layout

\begin_layout Paragraph
Incompetence
\end_layout

\begin_layout Standard
When there are 
\begin_inset Formula $N_{A}=0$
\end_inset

 activated agents and 
\begin_inset Formula $N\geq1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of the closest agents are candidate on becoming activated on 
\begin_inset Formula $x_{new}$
\end_inset

.
 In this situation,
 if 
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset

,
 i.e prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
,
 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 could become an expert on 
\begin_inset Formula $x_{new}$
\end_inset

 so it refines its model and expands towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 Otherwise,
 if no neighbor gives 
\emph on
good
\emph default
 or 
\emph on
inaccurate
\emph default
 predictions,
 a new agent centered on 
\begin_inset Formula $x_{new}$
\end_inset

 is created.
 This rule promotes knowledge reuse and limit redundant agent creation.
\end_layout

\begin_layout Paragraph
Uselessness
\end_layout

\begin_layout Standard
In practice,
 we observe a need for agent destruction mechanisms within the system.
 Indeed,
 some agents may evolve into degenerate shapes if they receive too much negative feedbacks in a row.
 They become far too small to be informative.
 These 
\emph on
dead
\emph default
 agents most probably won't be activated ever again and are no longer useful in the system.
 Consequently,
 all agents whose volume falls below a certain threshold value 
\begin_inset Formula $\tau_{\text{vol}}$
\end_inset

 are destroyed.
\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Learning-rules-of-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 summarize the learning rules governing the behavior of agents in oCELL and Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Flowchart-illustrating-oCELL-learning"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the learning process.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="4">
<features tabularvalignment="middle" tabularwidth="95col%">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model 
\begin_inset Newline newline
\end_inset

+ shape (expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\forall\mathcal{A}_{i},\,L_{\mathcal{A}_{i}}\notin\left[0,\tau_{\text{good}}\right]\cup\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}\geq1$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[0,\tau_{\text{good}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(expand)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{good}},\tau_{\text{bad}}\right]$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{\mathcal{A}_{i}}\in\left[\tau_{\text{bad}},+\infty\right[$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape 
\begin_inset Newline newline
\end_inset

(retract)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N_{A}=0$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of oCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-oCELL"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert flowchart to explain learning
\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Flowchart illustrating the learning process
\begin_inset CommandInset label
LatexCommand label
name "fig:Flowchart-illustrating-oCELL-learning"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Therefore,
 oCELL relies on several hyperparameters that must be initialized prior to training.
 These parameters have an influence on the convergence of the system.
 These parameters include:
\end_layout

\begin_layout Itemize
Initial orthotope size (
\begin_inset Formula $R$
\end_inset

):
 determines the initial confidence region of newly created agents;
 overly small regions may hinder proper activation and make new agents overspecialize locally.
\end_layout

\begin_layout Itemize
Prediction thresholds (
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset

 and 
\begin_inset Formula $\tau_{\text{good}}$
\end_inset

):
 define accuracy regimes and influence rule activation frequency.
\end_layout

\begin_layout Itemize
Volume variation coefficient (
\begin_inset Formula $\alpha$
\end_inset

):
 controls the rate of expansion or retraction of agents as a fraction of their current volume.
\end_layout

\begin_layout Itemize
Destruction threshold (
\begin_inset Formula $\tau_{\text{vol}}$
\end_inset

):
 specifies the minimum volume below which an agent is considered as a candidate for destruction.
\end_layout

\begin_layout Subsection
Comparative Study
\begin_inset CommandInset label
LatexCommand label
name "subsec:Comparative-Study"

\end_inset


\end_layout

\begin_layout Standard
To evaluate the performances of oCELL,
 we conducted a comparative study against standard machine learning algorithms on a regression task.
 This section outlines the experimental protocol and compare performances against various metrics.
 For this experiment,
 each context agent employs a linear regression as its internal model.
 This choice is motivated by the simplicity and transparency of the inner workings of linear transformations.
 This aligns with the design of oCELL and facilitate clear analysis of the system's behavior.
\end_layout

\begin_layout Subsubsection
Experimental Setup
\end_layout

\begin_layout Standard
The experiment is conducted on four two-dimensional benchmark functions commonly used in optimization research.
 These functions were selected due to their nonlinear characteristics and the challenges they present for optimization,
 particularly for gradient-based methods 
\begin_inset CommandInset citation
LatexCommand cite
key "Jamil2013ALS"
literal "false"

\end_inset

.
 This choice is motivated by the fact that state-of-the-art machine learning algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "chenXGBoostScalableTree2016,keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

 partially rely on gradient-based optimization during the learning process.
\end_layout

\begin_layout Standard
To ensure relevance of the evaluation while keeping it low-dimensional,
 we selected classical functions known for their optimization difficulty,
 characterized by multiple local optima and nonlinear variations 
\begin_inset CommandInset citation
LatexCommand cite
key "aliNumericalEvaluationSeveral2005,Jamil2013ALS"
literal "false"

\end_inset

.
 The functions considered are the SSR functions (
\begin_inset Formula $f\left(x,y\right)=\sin\left(\sqrt{x^{2}+y^{2}}\right)$
\end_inset

),
 Booth,
 Goldstein-Price and Beale functions (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmaps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 For each function,
 a synthetic dataset comprising 8000 observations was generated by uniformly sampling points within the feature space.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/functions_heatmap_line.png
	lyxscale 35
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of the 2D functions used to generate the benchmark datasets.
 The color levels approaching yellow correspond to higher values,
 while the color levels approaching blue correspond to lower values.
\begin_inset CommandInset label
LatexCommand label
name "fig:Heatmaps"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We compare oCELL against widely used ensemble algorithms and common weak learners.
 The selected weak learners include decision trees 
\begin_inset CommandInset citation
LatexCommand cite
key "breimanClassificationRegressionTrees2017"
literal "false"

\end_inset

,
 SVMs 
\begin_inset CommandInset citation
LatexCommand cite
key "changLIBSVMLibrarySupport2011"
literal "false"

\end_inset

 and linear regression 
\begin_inset CommandInset citation
LatexCommand cite
key "weisbergAppliedLinearRegression2005"
literal "false"

\end_inset

.
 For ensemble methods,
 we consider both classical approaches such as gradient boosting 
\begin_inset CommandInset citation
LatexCommand cite
key "friedmanGreedyFunctionApproximation2001"
literal "false"

\end_inset

 and random forests 
\begin_inset CommandInset citation
LatexCommand cite
key "breimanRandomForests2001"
literal "false"

\end_inset

,
 alongside state-of-the-art algorithms:
 XGBoost 
\begin_inset CommandInset citation
LatexCommand cite
key "chenXGBoostScalableTree2016"
literal "false"

\end_inset

 and LightGBM 
\begin_inset CommandInset citation
LatexCommand cite
key "keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
All input features are normalized to the range 
\begin_inset Formula $-1$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

.
 Hyperparameter optimization is performed via a grid search with the goal of minimizing the mean squared error obtained through 5-fold cross-validation.
 The resulting best configurations found are reported in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "tab:Best-hyperparameters-set"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 These configurations correspond to the parameter sets exposed by the interfaces of the scikit-learn 
\begin_inset CommandInset citation
LatexCommand cite
key "pedregosaScikitlearnMachineLearning2012"
literal "false"

\end_inset

,
 xgboost 
\begin_inset CommandInset citation
LatexCommand cite
key "chenXGBoostScalableTree2016"
literal "false"

\end_inset

 and lightgbm 
\begin_inset CommandInset citation
LatexCommand cite
key "keLightGBMHighlyEfficient2017"
literal "false"

\end_inset

 python libraries.
 For oCELL,
 
\begin_inset Formula $R$
\end_inset

 is a vector corresponding to the initial length on each dimension of the sides of the orthotope for a newly created context agent.
 The parameters 
\begin_inset Formula $\tau_{\text{good}},\tau_{\text{bad}},\alpha\in\mathbb{R}^{3}$
\end_inset

 correspond to those introduced in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Learning-Rules"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 and 
\emph on
memory_length
\emph default
 sepcifies the maximum memory size allocated to an agent.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/prediction_mas_line.png
	lyxscale 30
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-the-predictions"

\end_inset

Visualization of oCELL predictions on data not included in the training dataset.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Results
\end_layout

\begin_layout Standard
The results obtained using the selected evaluation metrics across the considered benchmark functions are reported in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "tab:Comparisons-results"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 oCELL achieves the lowest mean absolute error (MAE) and the highest coefficient of determination (
\begin_inset Formula $R^{2}$
\end_inset

) for all four functions.
 It also attains the best mean squared error (MSE) on the SSR,
 Goldstein-Price and Booth functions,
 while XGBoost performs slightly better in terms of MSE on the Beale function.
 Overall,
 oCELL demonstrates comparable performances to XGBoost and LightGBM for most functions,
 while consistently outperforming the weak learners.
 These results indicate that oCELL effectively captures the nonlinear variations of the underlying functions from the data,
 as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-the-predictions"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure*}[!ht]
\end_layout

\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Float table
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{0.95
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="37" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="20col%">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
hyperparameters
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
SSR
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Booth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Goldstein-Price
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Beale
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $R$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.35$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.05$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{\text{good}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.15
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\tau_{\text{bad}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\alpha$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
memory_length
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
XG
\begin_inset Newline newline
\end_inset

Boost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
learning_rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n_estimators
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
objective
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
squ.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Light
\begin_inset Newline newline
\end_inset

GBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
learning_rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n_estimators
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
objective
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_child_samples
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
huber
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
l2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
tweedie
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
tweedie
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bootstrap
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
criterion
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_features
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_leaf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_split
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n_estimators
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
criterion
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poisson
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_features
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_leaf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_split
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
learning_rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
abs.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
huber
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
squ.
 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
huber
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_depth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max_features
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
null
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_leaf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
min_samples_split
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
epsilon
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
gamma
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
scale
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
kernel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
rbf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
rbf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
poly
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
rbf
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center

\series bold
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
fit_intercept
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
true
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Best-hyperparameters-set"

\end_inset

Best hyperparameters set found by grid search on 5-fold cross validation results
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "40col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Float table
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{0.95
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="33" columns="5">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="20col%">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $R^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MSE
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MAE
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Beale
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,983
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,94e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,07e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,995
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,08e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,19e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,996
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,61e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,75e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-0,001
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,16e+08
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,19e+04
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,997
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,34e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
2,53e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,995
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,02e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,23e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-0,139
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,74e+08
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8,28e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,997
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,29e+06
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,11e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Booth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,994
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,29e+03
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,60e+01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,39e+02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,44e+00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,38e+02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8,09e+00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,426
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,17e+05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,63e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
9,52e+00
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
9,91e-01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,998
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,57e+02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,31e+01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,811
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,89e+04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,85e+01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8,72e+01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,01e+00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
Goldstein-Price
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,994
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,02e+08
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,29e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,37e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,62e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,80e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,82e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,249
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,22e+10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,79e+04
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,21e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
7,02e+02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,998
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,98e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3,38e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-0,127
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,83e+10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,17e+04
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,46e+07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,61e+03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\align center
SSR
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,960
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,89e-02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9,30e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gradient boosting
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,997
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,22e-03
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2,30e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LightGBM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,998
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,68e-04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,98e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Linear Reg.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,77e-01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,09e-01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
oCELL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
4,97e-04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1,39e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,978
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,03e-02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6,48e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0,972
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,32e-02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7,90e-02
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XGBoost
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0,999
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5,93e-04
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,65e-02
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Comparisons-results"

\end_inset

Comparison between oCELL and the reference algorithms (best scores in bold)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{figure*}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Explainability and Interpretability
\begin_inset CommandInset label
LatexCommand label
name "subsec:Explainability-oCELL"

\end_inset


\end_layout

\begin_layout Standard
The CELL instantiations are designed to possess native mechanisms for introspection.
 While its architecture is similar to the localized approximation approach used by techniques such as LIME 
\begin_inset CommandInset citation
LatexCommand cite
key "ribeiro2016should"
literal "false"

\end_inset

,
 oCELL achieves intrinsic local explainability through its structural multiagent design.
\end_layout

\begin_layout Subsubsection
Interpretability
\end_layout

\begin_layout Standard
oCELL's design provides a basis for full model interpretability.
 When the agents employ inherently transparent models such as linear regression,
 oCELL itself works as a structurally interpretable white-box model in accordance with the definition introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:XAI"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 The system's final prediction is derived from a linear combination of predictions proposed by a restricted,
 spatially-localized subset of agents.
 This mechanism simplifies the process of credit assigment compared to traditional global ensemble models (e.g bagging or boosting),
 which often involve contributions from a large set of weak learners.
 This property makes oCELL intrinsically interpretable.
\end_layout

\begin_layout Standard
Consequently the spatial organization and internal structures of the model can be systematically analyzed to extract essential information about the function underlying the data and its complexity.
 For didactic purposes,
 the remainder of this section is based on a training carried out on a synthetic dataset generated from the Beale function (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmaps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 This nonlinear function exhibits regimes of amplitude variations that are very different across its domain of definition.
 The amplitude of the gradients of the Beale function varies greatly at the boundaries of the definition domain (
\begin_inset Formula $-4\leq x,y\leq4$
\end_inset

),
 while in the central plateau,
 the variations in gradient amplitude are more subtle.
 The Beale function is frequently used as a benchmark for testing optimization algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "zhuangAdaBeliefOptimizerAdapting2020,Jamil2013ALS"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_agents_english.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-tiling-beale"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_neighborhood_english.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-neighborhood-beale"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of the tiling of the space (normalized between 
\begin_inset Formula $-1$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

) by the context agents for the Beale function 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-tiling-beale"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 Each blue rectangle represents a context agent and the red rectangle is an example of the neighborhood of an observation.
 Visualization of the context agents in the neighborhood of an observation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-neighborhood-beale"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Uncertainty and Confidence
\end_layout

\begin_layout Standard
The notion of neighborhood and more broadly the spatial organization of agents allows to extract various metrics of the local organization of agents in the feature space.
\end_layout

\begin_layout Paragraph
Epistemic Uncertainty
\end_layout

\begin_layout Standard
During training,
 the agents organize themselves in the feature space.
 Depending on the training dataset and the complexity of the underlying function,
 the results of self-organization varies.
 As illustrated in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-tiling-beale"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 gaps (uncovered zones) in the agent tiling may remain.
 It is possible that for a given observation,
 no agent is activated.
 In such cases,
 making a prediction requires relying on the proposals of the nearest agents in the observation's neighborhood.
 To determine if the agents' prediction is reliable,
 we define the coverage index 
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

 of the observation's neighborhood as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p_{\text{coverage}}=\frac{V_{\text{agents}}}{V_{\text{neighborhood}}}
\end{equation}

\end_inset

where 
\begin_inset Formula $V_{\text{agents}}$
\end_inset

 is the volume covered by the 
\emph on
Context
\emph default
 agents in the neighborhood and 
\begin_inset Formula $V_{\text{neighborhood}}$
\end_inset

 is the volume of the hyperrectangle representing the neighborhood.
\end_layout

\begin_layout Standard
Thus,
 if 
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

 is close to 
\begin_inset Formula $1$
\end_inset

,
 the space around the observation contains few gaps:
 our model is proficient in that region of space.
 Therefore,
 it is relevant to consider the predictions of nearby agents.
 Conversely,
 if 
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

 is close to 
\begin_inset Formula $0$
\end_inset

,
 then the space around the observation contains many gaps.
 There is a high probability that this region of space was underexplored during training.
 This may indicate either gaps in the training data specific to that area of space,
 or that training did not proceed as expected for various reasons (strong non-linearities in the function to approximate,
 presence of noise,
 discontinuity,
 etc...).
 We illustrate the utility of the coverage index in a scenario where our system learns from a dataset with an entire portion of missing data 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Comparison-coverage-index"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 We observe that the coverage index helps identify the missing portion of data in the training dataset without having directly access to the actual training dataset.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/side_by_side_missing_data_cover_index_english.png
	lyxscale 30
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Comparison-coverage-index"

\end_inset

Comparison of the distribution map of observations used to train the model (left) and the visualization of the coverage index associated with this model (right).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The covergae index is therefore a quantitative measure of the epistemic uncertainty associated with a prediction.
 it provides a direct assessment of the model's learned boundaries and limitations in various regions of the feature space.
 For the development of critical systems,
 this property is essential to observe in order to assess the risk of extrapolation or interpolation errors.
\end_layout

\begin_layout Standard
This measure is fundamentally linked to both explainability and interpretability.
 Locally,
 at the individual prediction level,
 coverage index serves as a crucial component of explanation.
 By quantifying the reliability of the output,
 it effectively represents a degree of trustworhtiness and the necessity of relying on neighborhood averaging (cf.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsubsec:Neighborhood-Prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Globally,
 the aggregated coverage index allows for the systematic analysis and visualization of the entire agent organization across the feature space.
 This analysis of the overall tiling pattern directly addresses interpretability by giving tools for understanding the model's inherent structure and mechanisms.
\end_layout

\begin_layout Paragraph
Aleatoric Uncertainty
\end_layout

\begin_layout Standard
After training,
 when an observation is provided to the model,
 each activated agent makes a prediction proposal.
 We can thus calculate the discrepancy between the prediction proposals from the set of proposals of the activated agents (
\begin_inset Formula $\mathcal{D}_{\text{proposals}}$
\end_inset

) to deduce a measure of aleatoric uncertainty:
 
\begin_inset Formula 
\begin{equation}
\sigma_{\text{activated}}=\sqrt{\sum_{p\in\mathcal{D}_{\text{proposals}}}\frac{\left|p-p_{\text{mean}}\right|}{N_{A}}}
\end{equation}

\end_inset

where 
\begin_inset Formula $p_{\text{mean}}$
\end_inset

 is the average of the proposals in the set of 
\begin_inset Formula $\mathcal{D}_{\text{proposals}}$
\end_inset

 and 
\begin_inset Formula $N_{A}$
\end_inset

 is the number of activated agents.
 This value estimates the disagreement among agents which judge themselves as equally competent to propose a prediction.
\end_layout

\begin_layout Standard
This value of discrepancy quantifies the aleatoric uncertainty associated with the model's predictions.
 It captures the inherent noise and stochasticity as a disagreement among locally activated agents.
 It's linked to explainability because it primarily relates to locality at the prediction-level,
 providing useful tools to explain predictions under the angle of trust.
\end_layout

\begin_layout Standard
Then,
 as oCELL is agnostic of the internal model of the agents that compose it,
 it is possible to use a class of models capable of inherently providing a measure of uncertainty on predictions,
 such as Gaussian Processes.
 Those are models which allow estimation of both epistemic and aleatoric uncertainties 
\begin_inset CommandInset citation
LatexCommand cite
key "schulzTutorialGaussianProcess2018"
literal "false"

\end_inset

.
 Exploiting the strength of this type of model could make the estimation of aleatoric uncertainty more robust.
 Indeed,
 several activated agents are needed for 
\begin_inset Formula $\sigma_{\text{activated}}$
\end_inset

 to be informative,
 using Gaussian Processes would allow to still have a discrepancy value to use even when only one agent is activated.
 To overcome this drawback,
 we present later a generalization of this metric so that it can be used to analyze the geometric structures formed by agents during learning.
\end_layout

\begin_layout Paragraph
Variations of the Underlying Function
\end_layout

\begin_layout Standard
The shape of an agent depends on the region of space it occupies.
 Moreover,
 within its confidence area delimited by the orthotope associated to its activation function,
 the function underlying the data is locally approximable by a simple model.
 Therefore,
 in a region containing a large number of agents,
 variations in the underlying function are likely to be more 
\emph on
difficult
\emph default
 to learn.
 Thus,
 we define the density of agents around an observation as
\begin_inset Formula 
\begin{equation}
\rho=\frac{N_{\text{agents}}}{V_{\text{neighborhood}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $V_{\text{neighborhood}}$
\end_inset

 is the volume of the orthotope representing the neighborhood and 
\begin_inset Formula $N_{\text{agents}}$
\end_inset

 is the number of agents intersecting it.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-density"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the density of agents in the input variable space for the Beale function.
 We observe a corridor in the center of the figure for 
\begin_inset Formula $y\in\left[-1,1\right]$
\end_inset

 where the density of agents is low.
 In the rest of the figure,
 the density of agents is higher.
 By examining the distribution of the average volume of agents in the neighborhood of observations (
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-volume"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 we note that areas with high agent density contain smaller agents and conversely for low-density areas.
\end_layout

\begin_layout Standard
These two regions correspond to very different variation regimes of the Beale function.
 Indeed,
 the region containing the largest agents (low density) corresponds to a plateau where the gradient magnitude of the function varies little.
 In contrast,
 the region containing the smallest agents (higher density) corresponds to a region of space where the gradient magnitude of the function varies strongly as one approaches the boundary of the definition area (
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-density"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
Finally,
 to complete the analysis,
 we define the degree of discrepancy 
\begin_inset Formula $\kappa$
\end_inset

 (which is a derivative of the discrepancy of activated agents 
\begin_inset Formula $\sigma_{\text{activated}}$
\end_inset

 presented earlier) among the predictions of all agents in the neighborhood (
\begin_inset Formula $\mathcal{D}_{\text{proposals}}$
\end_inset

) as
\begin_inset Formula 
\begin{equation}
\kappa=\frac{\sqrt{\sum_{p\in\mathcal{D}_{\text{proposals}}}\frac{\left|p-p_{\text{mean}}\right|}{N}}}{\left|y_{\text{mean}}\right|}
\end{equation}

\end_inset

where 
\begin_inset Formula $N$
\end_inset

 is the number of agents in the neighborhood and 
\begin_inset Formula $y_{\text{mean}}$
\end_inset

 is the average of predictions from the agents in the neighborhood.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\kappa$
\end_inset

 is close to 
\begin_inset Formula $0$
\end_inset

,
 then the predictions of the agents in the neighborhood are very close to each other.
 This indicates that the underlying function of the data varies little around the observation.
 Conversely,
 if its value is high,
 then the agents in the neighborhood make very different predictions,
 suggesting that the regime of variation of the underlying function is likely to change abruptly in that area.
 The degree of discrepancy helps identify regions in the input space where approximating the underlying function is most challenging.
 For the Beale function,
 the degree of discrepancy highlights regions of the space with the most complex variations (see 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Visualization-discrepancy"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 where the yellow areas represent the highest disagreement between agents).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_density_english.png
	lyxscale 30
	width 28text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-density"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_mean_volume_english.png
	lyxscale 30
	width 28text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-volume"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/oCELL_comparative_study/beale_consensus_degree_english.png
	lyxscale 30
	width 28text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-discrepancy"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of density 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-density"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 average volume 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-volume"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 degree of discrepancy 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Visualization-discrepancy"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 of 
\emph on
Context
\emph default
 agents.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The metrics presented above allow to extract measures of epistemic and aleatoric uncertainty on predictions,
 as well as information on function variations based on the shape and position of agents in the feature space.
\end_layout

\begin_layout Standard
We have extracted measures of epistemic (coverage index) and aleatoric (activated discrepancy) uncertainty from the predictions of the system as well as information about the variations of underlying function from the shape (volume and density) and spatial organization of agents in the feature space (degree of discrepancy).
 These introspection tools reveal capabilities that are useful for various purposes such as fault detection,
 model debugging,
 or smart resampling strategies to improve learning in specific,
 uncertain regions of the feature space.
 Finally,
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Summary-Metrics-Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 summarizes the scopes and links between the defined metrics and the notions of explainability and interpretability.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Metric
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scope
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Explainability
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Interpretability
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Coverage Index (
\begin_inset Formula $p_{\text{coverage}}$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local + Global
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Activated Discrepancies (
\begin_inset Formula $\sigma_{\text{activated}}$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\times$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Density (
\begin_inset Formula $\rho$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local + Global
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Degree of Discrepancy (
\begin_inset Formula $\kappa$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local + Global
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of the metrics introduced and their link to explainability or interpretability
\begin_inset CommandInset label
LatexCommand label
name "tab:Summary-Metrics-Explainability-oCELL"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Limitations
\begin_inset CommandInset label
LatexCommand label
name "subsec:Limitations"

\end_inset


\end_layout

\begin_layout Standard
We demonstrated that oCELL can address supervised learning tasks,
 but several limitations remain,
 which are tackled partly in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
A first limitation concerns the neighborhood prediction mechanism.
 Our current design assumes that an agent possesses uniform knwoledge throughout its activation region (the orthotope associated with its activation function).
 In practice,
 an agent is typically more reliable near its centroid and less accurate near the boundaries of its region.
 Despite this,
 all agents contributing to a prediction currently receive equal weight.
 This is an artifact of the uniform-knowledge assumption.
 A more principle approach would weight each agent according to its estimated local expertise level at the input point.
\end_layout

\begin_layout Standard
We explored this idea by weighting predictions using the Euclidean distance between the input and each agent's centroid,
 but this did not improve performance,
 likely because centroid distance alone does not reflect the whole geometry of each orthotope.
 A more appropriate distance measure should incorporate both the agent's centroid and the shape of its support.
 As illustrated in 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Limitation orthotope agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 (side by side comparison of an overgeneralizing agent and a representative agent by visualizing their respective orthotopes (represented by a blue rectangle) and training data (represented by red dots)),
 an agent may occupy a large orthotope while its training data populate only a small manifold (i.e a subregion),
 causing spurious known-region responses and false positives.
 Accurate spatialization and potentially richer base shapes is therefore essential to capture local data structures and prevent overgeneralization.
\end_layout

\begin_layout Standard
Furthermore,
 we observed that oCELL's agent destruction mechanism was inadequate.
 Agent overproduction was a frequently observed phenomenon,
 occasionally resulting in significant local redundancy and the persistence of harmful parasitic agents within the collective.
 This necessitates the development of more sophisticated destruction strategies explicitly designed to enforce local cooperation.
 In addition to that,
 the current single-point agent creation scheme seems too limited,
 as it directly contributes to local redundancy (slow local convergence).
 It should be more stable to initialize agents using multiples points to minimize local overlap and make local convergence faster.
\end_layout

\begin_layout Standard
Moreover,
 we observed that oCELL's agent destruction system was not sufficient and that agent overproduction was fairly common,
 sometimes leading to high local redundancy and the persistence of agents that parasitize the collective without improving it.
 This highlights a need for smarter destruction mechanisms that are designed towards local cooperation and more efficient agent creation schemes because creating agents with only one point can cause high local redundancy.
\end_layout

\begin_layout Standard
Furthermore,
 although oCELL is designed for online learning,
 it treats incoming samples as independent,
 failing to exploit temporal correlations in data streams.
 This limits its sample efficiency and reduces its ability to adapt to evolving distributions.
\end_layout

\begin_layout Standard
Finally,
 some hyperparameters remain difficult to tune.
 In particular,
 the initial side lengths of newly created agents have a disproportionate impact on performance and require specifying a scale per feature dimension.
 Similarly,
 the error thresholds used to classify predictions as 
\emph on
good
\emph default
,
 
\emph on
inaccurate
\emph default
 or 
\emph on
bad
\emph default
 are hard to tune properly to enable an efficient balence in the triggering of the various adaptation mechanisms or agents (i.e learning rules).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/sane_orthotope_agent.png
	lyxscale 40
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Representative orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Representative-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/overgeneralized_orthotope_agent.png
	lyxscale 40
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Overgeneralizing orthotope
\begin_inset CommandInset label
LatexCommand label
name "fig:Overgeneralizing-orthotope-agent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Side by side comparison of representative 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Representative-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 agent against a overgeneralizing agent 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Overgeneralizing-orthotope-agent"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 The blue rectangle corresponds to the orthotope associated to the activation function of the Context agent.
 Each red dot corresponds to a training point seen by the Context agent.
\begin_inset CommandInset label
LatexCommand label
name "fig:Limitation orthotope agents"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Taken together,
 these limitations expose a broader structural issue.
 oCELL relies on spatialization and prediction aggregation mechanisms that are too rigid.
 The orthotope representation is too coarse to support reliable interpolation when agents overlap or specialize unevenly.
 These limitations also highlight the need for inference machanisms that weight agents according to their estimated expertise level rather than using discrete activations.
 These considerations motivate the design of a new CELL system in which spatialization,
 inference and adaptation are grouned in smoother data representations.
\end_layout

\begin_layout Section
kCELL:
 Multiagent Ensemble Learning with Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "sec:kCELL"

\end_inset


\end_layout

\begin_layout Standard
Building upon the limitations of oCELL,
 we introduce kCELL (kernel CELL),
 the second instantiation of the CELL paradigm.
 With oCELL,
 we demonstrated that a population of agents can achieve competitive performance and provide valuable introspection signals such as epistemic and aleatoric uncertainty estimates and qualitative information about local function variations.
 However,
 its rigid spatial representation ultimately limits its ability to build reliable and adaptive regions of expertise.
 This constraint becomes problematic when there is need for fast adaptation in an online setting.
\end_layout

\begin_layout Standard
kCELL addresses these issues by replacing orthotope-based spatialization with a kernel-based representation.
 Each agent has its activation function in the form of a RBF kernel that defines a smooth continuous distance between input features and agents,
 drawing inspiration from RBF Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "lowe1988multivariable"
literal "false"

\end_inset

 and MoE (Mixture of Experts) 
\begin_inset CommandInset citation
LatexCommand cite
key "yukselTwentyYearsMixture2012"
literal "false"

\end_inset

 gating mechanisms.
 This change allows the system to express spatial structures more finely,
 with more degrees of freedom than what is permitted with orthotopes,
 thus breaking the assumption of knowledge uniformity over the region of expertise of oCELL.
\end_layout

\begin_layout Standard
In addition to that,
 kCELL introduces a smooth aggregation rule in which agents contribute to predictions proportionally to their kernel-defined relevance,
 i.e proportionally to their estimated expertise level.
 This brings the inference closer to the probabilistic weighting strategies used in Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "seeger2004gaussian"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
For those reasons kCELL improves interpolation quality,
 agents' data representations and yield more stable learning dynamics that are less dependent on brittle hyperparameters,
 which is better suited for online adaptive learning.
 kCELL is a more expressive and robust extension of the CELL paradigm that also preserves the explainability properties demonstrated with oCELL.
\end_layout

\begin_layout Standard
First,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Context-Agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 describes the internal structure of context agents in kCELL,
 including their spatialization in the feature space and their prediction mechanisms.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Learning-Rules"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces the learning rules that cover agent creation,
 adaptation and self-organization leading to the emergence of learning in the system.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Adaptation-to-Non-Stationary"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a study of kCELL's capabilities in terms of adaption in a non-stationary environment leveraging the introspection tools specific to the models derived from CELL.
 Subsequently,
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Discussions-and-Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses the key differences between oCELL and kCELL and details the limitations of kCELL.
\end_layout

\begin_layout Subsection
Context Agents
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Context-Agents"

\end_inset


\end_layout

\begin_layout Standard
As for oCELL 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Ref to definition of context agents in oCELL
\end_layout

\end_inset

,
 the main entities of kCELL are the Context agents.
 A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is characterized by an activation function 
\begin_inset Formula $\phi_{i}\left(x\right)$
\end_inset

 and a prediction function 
\begin_inset Formula $f_{i}\left(x\right)$
\end_inset

 such as 
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i},f_{i}\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
However,
 unlike in oCELL,
 the Context agents of kCELL are spatialized differently.
 In oCELL,
 a binary activation (the point is inside or outside the associated orthotope) is used while in kCELL,
 a RBF kernel is used as a continuous and smooth activation function to represent the area of expertise in feature space.
\end_layout

\begin_layout Standard
First,
 the spatialization mechanism of context agents based on RBF kernels is described.
 Then the soft weighted prediction mechanism allowing for weighting based on estimated level of expertise is presented.
\end_layout

\begin_layout Subsubsection
Kernel Spatialization
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kernel-Spatialization"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 contrary to using orthotopes a RBF kernel is used as the activation function to unlock more degrees of freedom to represent the areas of expertise 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add ref to illustration Figure
\end_layout

\end_inset

.
 This activation function is smooth and differentiable,
 making the system more optimization-friendly to be used for control tasks as a dynamics model.
 Therefore,
 an agent is spatialized by the mean 
\begin_inset Formula $\mu_{i}\in\mathbb{R}^{n}$
\end_inset

 and covariance matrix 
\begin_inset Formula $\Sigma_{i}\in\mathbb{R}^{n\times n}$
\end_inset

 of the distribution of its training points.
 Since this activation function has statistical significance,
 it is easier to define the neighborhood as a confidence interval whose confidence value can be adjusted.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison between area of expertise oCELL vs kCELL
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Definition
The distance between a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 and a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is defined as the mahalanobis distance:
\begin_inset Formula 
\[
d\left(\mathcal{A}_{i},x\right)=D_{M}\left(\mu_{i},\Sigma_{i},x\right)=\sqrt{\left(x-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x-\mu_{i}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
A Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is considered as a neighbor of 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 if 
\begin_inset Formula $x$
\end_inset

 is likely to belong to the training dataset of 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 such as 
\begin_inset Formula 
\[
D_{M}\left(\mu_{i},\Sigma_{i},x\right)^{2}\leq\chi_{n,0.95}^{2}
\]

\end_inset

 where 
\begin_inset Formula $\chi_{n,0.95}^{2}$
\end_inset

 denotes the 
\begin_inset Formula $95$
\end_inset

th percentile of the chi-squared distribution with 
\begin_inset Formula $n$
\end_inset

 degrees of freedom.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The activation function 
\begin_inset Formula $\phi_{i}:\mathbb{R}^{n}\mapsto\left]0,1\right]$
\end_inset

 of a Context agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 for a point 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is given by the RBF kernel value
\begin_inset Formula 
\[
\phi_{i}\left(\mathcal{A}_{i},x\right)=\exp\left(-\frac{d\left(\mathcal{A}_{i},x\right)}{2l^{2}}\right)
\]

\end_inset

with 
\begin_inset Formula $l$
\end_inset

 the lengthscale of the kernel.
\end_layout

\begin_layout Definition
The activation score of a point 
\begin_inset Formula $x$
\end_inset

 for a given agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 can be interpreted as the likelihood that the agent has previously been trained on points similar to 
\begin_inset Formula $x$
\end_inset

 and thus reflects the agent's degree of knowledge over the corresponding region of feature space.
 We can draw a parallel between this activation function based on RBF kernel and the coverage index 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert ref to coverage index in previous section
\end_layout

\end_inset

,
 an explainability metric derived from oCELL which is also linked to the degree of knowledge of a point.
 In kCELL,
 this explainability property related to the knowledge of a point emerges naturally from the definition of the system.
\end_layout

\begin_layout Definition
One of the requirements of kCELL is to be lightweight,
 meaning that as few points as possible should be retained in memory to truly represent information through local models.
 As previously stated,
 the spatialization of each agent can be fully described by a mean 
\begin_inset Formula $\mu_{i}$
\end_inset

 and a covariance matrix 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 which are the parameters of the activation function 
\begin_inset Formula $\phi_{i}$
\end_inset

.
 Each time a point is ingested by agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

,
 its mean and covariance matrix are updated using the Welford's algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "welford1962note"
literal "false"

\end_inset

 such as 
\begin_inset Formula 
\begin{eqnarray*}
\mu_{i\,|\,t+1} & = & \mu_{i\,|\,t}+\frac{x-\mu_{i\,|\,t}}{n+1}\\
\Sigma_{i\,|\,t+1} & = & \frac{1}{n}\left(\Sigma_{i\,|\,t+1}+\left(x-\mu_{i\,|\,t}\right)\left(x-\mu_{i\,|\,t+1}\right)^{\top}\right)
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $n$
\end_inset

 is the number of points ingested by the agent to update its shape.
 With this approach the shape change is expressed purely as a mean and covariance estimation problem.
\end_layout

\begin_layout Definition
The notion of volume expressed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Context-Agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 (cf.
 Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:orthotope-volume"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) still carries on.
 The volume of an agent is tied to the volume of a confidence ellipsoid defined by a theshold on squared mahalanobis distance.
 Thus the volume of an agent is proportional to the square root of the determinant of the associated covariance matrix
\begin_inset Formula 
\[
v\left(\mathcal{A}_{i}\right)\propto\sqrt{\det\left(\Sigma_{i}\right)}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Soft-Weighted Prediction
\begin_inset CommandInset label
LatexCommand label
name "subsubsec:Soft-Weighted-Prediction"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 we get rid of the knowledge uniformity hypothesis of agents to better represent the knowledge of the system.
 Therefore the activation function of a context agent materializes its area of expertise through a smooth RBF kernel.
 The further a point is from the agent's centroid,
 the lower its activation value.
 This is because we assume that expertise is maximized at the agent's center.
 Agents with higher activation values contribute more heavily to the final output because they are more expert than others at predicting.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $S_{k}=\left\{ i|\mathcal{A}_{i}\,\text{is in the \ensuremath{k}-closest to}\,x\right\} $
\end_inset

 denote the index set of the 
\begin_inset Formula $k$
\end_inset

 nearest agents in feature space.
 The final prediction 
\begin_inset Formula $f\left(x\right)\in\mathbb{R}^{m}$
\end_inset

 of the system is then given by
\begin_inset Formula 
\[
f\left(x\right)=\sum_{i\in S_{k}}w_{i}\left(x\right)f_{i}\left(x\right)
\]

\end_inset

where the normalized contribution weights 
\begin_inset Formula $w_{i}\left(x\right)$
\end_inset

 are defined as
\begin_inset Formula 
\[
w_{i}\left(x\right)=\frac{\phi_{i}\left(x\right)}{\sum_{j\in S_{k}}\phi_{j}\left(x\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
This formulation ensures that each contributing agent's influence on the final prediction is proportional to its estimated competence.
\end_layout

\begin_layout Subsection
Learning Rules
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Learning-Rules"

\end_inset


\end_layout

\begin_layout Standard
As in oCELL,
 learning rules are designed around a set of actions and conditions that triggers those actions to digest 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 that are fed to the system sequentially as a data stream.
 In context agent learning systems,
 the set of actions consists of the actions that can be performed individually by agents such as updating their model or shape;
 and more meta-level actions such as destroying or creating new agents.
 These actions are triggered by conditions that generally depend on two factors:
 the number of current neighbors and a feedback value calculated from the proposals of selected agents.
\end_layout

\begin_layout Standard
When there are 
\begin_inset Formula $N>1$
\end_inset

 agents that are neighbors of 
\begin_inset Formula $x_{new}$
\end_inset

,
 all of those agents are theoretically considered as experts to predict for 
\begin_inset Formula $x_{new}$
\end_inset

.
 As the final prediction of the system 
\begin_inset Formula $f\left(x\right)=\hat{y}$
\end_inset

 is computed from the proposals of all those agents,
 the agents need to cooperate together locally to improve the local knowledge.
 For this purpose,
 we define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

,
 the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process,
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}=\frac{E_{-i}-E}{E}=\frac{\left|\hat{y}_{-i}-y_{new}\right|-\left|\hat{y}-y_{new}\right|}{\left|\hat{y}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E$
\end_inset

 is the prediction error,
 
\begin_inset Formula $E_{-i}=\left|\hat{y}_{-i}-y_{new}\right|$
\end_inset

 is the prediction error without considering the proposition of prediction of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset

 then it means that removing agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 from the prediction group had a negative impact on the prediction error,
 meaning that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 has a positive contribution to reducing the error locally and conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset

.
 This value indicates for a given point,
 which agents are strong and which are weak in predicting for 
\begin_inset Formula $x_{new}$
\end_inset

.
 We can therefore consider that weak agents need to improve their local model,
 while strong agents are already good and need to strengthen their local anchoring at the given point.
 This update rule allows for the continuous improvement of the group locally by improving the weakest agents while keeping them mobile,
 thus allowing them to position themselves elsewhere if needed.
\end_layout

\begin_layout Standard
When there is only one agent (
\begin_inset Formula $N=1$
\end_inset

) that is neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

,
 it can't be updatd according to the same rules.
 Indeed,
 its contribution to the error cannot be compared to the ones of other neighors (as if 
\begin_inset Formula $N>1$
\end_inset

).
 Therefore,
 we define 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

,
 the relative error reduction compared to a baseline prediction given by a running short term linear predictor
\begin_inset Formula 
\[
\Delta_{\mathcal{A}_{i}}^{\prime}=\frac{E_{base}-E_{i}}{E_{base}}=\frac{\left|y_{base}-y_{new}\right|-\left|\hat{y}_{i}-y_{new}\right|}{\left|y_{base}-y_{new}\right|}
\]

\end_inset

where 
\begin_inset Formula $E_{base}$
\end_inset

 is the prediction error of the short term linear predictor,
 
\begin_inset Formula $E_{i}=\left|\hat{y}_{i}-y_{new}\right|$
\end_inset

 is the prediction error of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

 then it means that 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 outperforms the short term linear predictor locally around 
\begin_inset Formula $x_{new}$
\end_inset

,
 giving indications that agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 might be useful locally and conversely for 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

.
 This value allows to estimate how expert the agent is relative to the short-term baseline.
 We can therefore consider that if the only neighbor agent is beaten by the baseline,
 then it probably shouldn't be a neighbor to this point.
 It should skip interacting this 
\begin_inset Formula $x_{new}$
\end_inset

 and 
\begin_inset Formula $y_{new}$
\end_inset

,
 waiting to reposition itself by ingesting new points,
 to be destroyed,
 or for another agent to become a neighbor in that area so they can improve together.
 Conversely,
 if it is better than the baseline,
 then it is a local expert whom should stay in that area since it represents the only local source of knowledge.
 So,
 it should improve its local model and strengthen its local anchoring around 
\begin_inset Formula $x_{new}$
\end_inset

.
 This update rule allows single neighbors to specialize locally even when alone in an area.
\end_layout

\begin_layout Standard
Finally if no agent is considered a neighbor (
\begin_inset Formula $N=0$
\end_inset

),
 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 is computed since as in the case 
\begin_inset Formula $N=1$
\end_inset

,
 there is no neighbor to compare to.
 Thus,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset

,
 it means that the neared agent is more relevant than the short term linear predictor.
 Therefore,
 it seems that this agent should encompass the point and become its neighbor by improving its model and extending its shape towards 
\begin_inset Formula $x_{new}$
\end_inset

.
 On the other hand,
 if 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset

,
 it means that even the nearest agent is not relevant for prediction and therefore the system probably has no knowledge of 
\begin_inset Formula $x_{new}$
\end_inset

 and should add it to its knowledge base by covering the space around it by creating a new agent.
 To avoid initializing the new agent with only one point (as in oCELL) and accelerate local convergence,
 it is initialized from a short term buffer containing last points seen by the system.
\end_layout

\begin_layout Standard
Since agents are created,
 a destruction mechanism is needed.
 An,
 agent might position poorly in the feature space or choose to ingest the wrong points making its model no longer representative of the covered area.
 Decision errors happen almost all the time when working in an online setting because it is impossible to know what the future points will look like.
 It can only be guessed from local relationships between successive points.
 If no destruction mechanism is introduced to mitigate the proliferation of agents,
 the number of agents will grow indefinitely and performances will be hurt by bad agents,
 preventing local specialization in the system and ultimately dragging down the predictive accuracy.
\end_layout

\begin_layout Standard
Therefore,
 we define instantaneous normalized confidence 
\begin_inset Formula $c_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

 of an agent as the various feedbacks received by the agent
\begin_inset Formula 
\[
c_{i}=\tanh\left(k\times\begin{cases}
\Delta_{\mathcal{A}_{i}} & \text{if}\,N>1\\
\Delta_{\mathcal{A}_{i}}^{\prime} & \text{else}
\end{cases}\right)
\]

\end_inset

where 
\begin_inset Formula $k$
\end_inset

 is the steepness of the 
\begin_inset Formula $\tanh$
\end_inset

 function.
\end_layout

\begin_layout Standard
Then,
 we define 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\in\left[-1,1\right]$
\end_inset

,
 the running confidence of agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 as the exponental moving average of successive instantaneous confidence values (i.e feedback values) received by the agent
\begin_inset Formula 
\[
\bar{C}_{\mathcal{A}_{i}\,|\,t+1}=\left(1-\lambda\right)\bar{C}_{\mathcal{A}_{i}\,|\,t}+\lambda c_{\mathcal{A}_{i}}
\]

\end_inset

where 
\begin_inset Formula $\lambda$
\end_inset

 the smoothing factor.
\end_layout

\begin_layout Standard
The confidence value 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}$
\end_inset

 is calculated for each agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 and updated each time 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

is selected as a neighbor to 
\begin_inset Formula $x_{new}$
\end_inset

.
 It allows to track its performance over the course of successive updates.
 When 
\family roman
\series medium
\shape up
\size normal
\emph off
\nospellcheck off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}>0$
\end_inset

,
 it means that,
 on average,
 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 is categorized as strong compared to other neighbors or the short-term baseline predictor and conversely if 
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}<0$
\end_inset

.
 Confidence this allows us to distinguish between agents that strengthen the system and those that degrade it.
 We deduce that an agent whose trust falls below a certain threshold 
\begin_inset Formula $\tau_{\text{confidence}}$
\end_inset

 should be destroyed to allow the emergence of new and more efficient local structures.
\end_layout

\begin_layout Standard
Finally,
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Learning-rules-of-kCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a summary of the learning rules that describe the behavior of context agents in kCELL.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Condition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Agent selected
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Closest
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
create agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model + shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\varnothing$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $N>1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}>0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}<0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\bar{C}_{\mathcal{A}_{i}}\leq\tau_{\text{confidence}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
destroy agent
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Learning rules of kCELL
\begin_inset CommandInset label
LatexCommand label
name "tab:Learning-rules-of-kCELL"

\end_inset

 where 
\begin_inset Formula $N$
\end_inset

 is the number of neighbors,
 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}^{\prime}$
\end_inset

 the relative error reduction compared to a baseline prediction and 
\begin_inset Formula $\Delta_{\mathcal{A}_{i}}$
\end_inset

the fractional change in error when leaving agent 
\begin_inset Formula $\mathcal{A}_{i}$
\end_inset

 out of the prediction process.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
To visualize the result of a learning and local cooperation of agents,
 we use a 1-dimensional example.
 We generate a small synthetic dataset from the function 
\begin_inset Formula $f\left(x\right)=\sin\left(x\right)+\epsilon\,\mathcal{N}\left(0,1\right)$
\end_inset

 with 
\begin_inset Formula $\epsilon\in\mathbb{R}$
\end_inset

 the noise scaling factor.
 We simulate online learning by sequentially feeding the agent one 
\begin_inset Formula $x_{new},y_{new}$
\end_inset

 tuple at a time.
 Each point is only seen once during learning as this is an important property of an effective and rapid online learning algorithm especially useful in real time dynamics modeling.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1D-Visualization-of-local-coop"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a side-by-side visualization of the spatial organization of agents 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Spatial-organization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 against the result of aggregating their predictions 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Resulting-prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 We can observe that the agents overlap and do not fit perfectly across their entire area of expertise;
 at the edges of agents the fit seems to have more errors and conversely on the center.
 This is the expected behavior resulting from the assumption of non-uniformity in the knowledge within areas of expertise.
 Finally,
 we observe that the overall predictions approximate closely the function considering the noise added to the data.
 It demonstrates kCELL's ability to generalize effectively by interpolation.
 This highlights the usefulness of a weighted aggregation function as presented in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsubsec:Soft-Weighted-Prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/local_coop_1D_illustration/viz_agents_sin1D.png
	lyxscale 40
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Spatial organization
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Spatial-organization"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/local_coop_1D_illustration/viz_inference_sin1D.png
	lyxscale 45
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Resulting prediction
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Resulting-prediction"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of local cooperation of agents in predicting a noisy sinus function.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Spatial-organization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents the spatial organization of agents where is colored segment represents the mapping of an individual agent between feature space and output space.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:1D-Resulting-prediction"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the resulting predictions obtained from the aggregation of agents local models,
 illustrating the interpolation capabilities of the model.
\begin_inset CommandInset label
LatexCommand label
name "fig:1D-Visualization-of-local-coop"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Adaptation to Non-Stationary Dynamics
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Adaptation-to-Non-Stationary"

\end_inset


\end_layout

\begin_layout Standard
In kCELL,
 the agents learn a function from a stream of data through local modeling and cooperation.
 In this section we present an experiment and introspection studies to demonstrate the capabilities of kCELL in terms of online adaptation and raw performances in online non-stationary dynamics modeling.
\end_layout

\begin_layout Subsubsection
Experimental Protocol
\end_layout

\begin_layout Standard
To evaluate the capabilities of kCELL to adapt online to non-stationary dynamics,
 we conducted experiments on two MuJoCo 
\begin_inset CommandInset citation
LatexCommand cite
key "todorov2012mujoco"
literal "false"

\end_inset

 simulation environment:
 InvertedPendulum and Hopper.
 For each environment,
 datasets were collected under three gravitational acceleration values (
\emph on
default 
\emph default
gravity
\emph on
 
\emph default

\begin_inset Formula $g=9.81$
\end_inset

,
 
\emph on
low 
\emph default
gravity 
\begin_inset Formula $g=4$
\end_inset

 ,
 
\emph on
high
\emph default
 gravity 
\begin_inset Formula $g=20$
\end_inset

) using pretrained reinforcement learning agents trained with Soft-Actor-Critic (SAC) algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "haarnoja2018soft"
literal "false"

\end_inset

 (with stable-baselines3 implementation 
\begin_inset CommandInset citation
LatexCommand cite
key "stable-baselines3"
literal "false"

\end_inset

).
 Training data were streamed in the same order (
\emph on
default 
\begin_inset Formula $\rightarrow$
\end_inset

 low 
\begin_inset Formula $\rightarrow$
\end_inset

 high
\emph default
) to simulate abrupt changes in the underlying system dynamics.
 The characteristics of the generated datasets are presented in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Characteristics-of-datasets"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
The environments were selected to contrast a low-dimensional setting (InvertedPendulum with 4-dimensional states and 1 action) with a higher-dimensional one (Hopper with 11-dimensional state and 3 actions).
 Mahalanobis distance values become larger the higher the number of dimensions.
 Thus we want to study the impact of increasing dimensionality on the representativity of the spatialization of kCELL which was one of the main limitations of oCELL (cf.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 We also compare kCELL to Adaptive Hoeffding Trees 
\begin_inset CommandInset citation
LatexCommand cite
key "bifet2009adaptive"
literal "false"

\end_inset

 which is an efficient adaptive online learning method based on decision trees designed to handle concept drift.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Environment
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
State Size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nb Actions
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dynamic Changes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nb Learning Steps
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
InvertedPendulum
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g\in\left\{ 9.81,4,20\right\} $
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
30k
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hopper
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g\in\left\{ 9.81,4,20\right\} $
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50k
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Characteristics of datasets generated with different values of 
\begin_inset Formula $g$
\end_inset

.
 
\emph on
State Size
\emph default
 stands for the number of features in states,
 
\emph on
Nb Actions
\emph default
 stands for the number of continuous actions,
 
\emph on
Dynamic Changes
\emph default
 corresponds the set of 
\begin_inset Formula $g$
\end_inset

 values used to generate the datasets,
 
\emph on
Nb Learning Steps
\emph default
 corresponds to the budget in number of training steps used to train the RL agent used to generate each dataset (one RL Agent per dataset).
\begin_inset CommandInset label
LatexCommand label
name "tab:Characteristics-of-datasets"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Prediction Error Analysis
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the evolution of Mean Absolute Error (MAE) for kCELL and Adaptive Hoeffding Trees algorithms measured on the test sets associated with each value of 
\begin_inset Formula $g$
\end_inset

 for each environment.
 Across both environments,
 the MAE consistently decreases on the test set corresponding to the currently observed gravity value,
 indicating effective online adaptation to changes in dynamics (refer to semi-transparent red areas in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
For the InvertedPendulum environment (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-mae-dynamic-changes-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 kCELL systematically outperforms Adaptive Hoeffding Trees when the training and testing gravity values coincide,
 exhibiting lower MAE throughout each stationary phase.
 This suggests that the local spatialized modeling strategy employed by kCELL allows more accurate approximation of the underlying dynamics in low-dimensional settings.
 For the Hopper environment (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-mae-dynamic-changes-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 both approaches achieve comparable MAE across the different gravity regimes.
 However,
 we notice that the error curve of kCELL displays higher variance,
 reflecting the self organization mechanisms of agents (creation,
 destruction,
 updates).
 This could also be due to numerical out-of-distribution prediction instability of CELL approaches which is a known problem.
 Indeed,
 due to spatialization,
 kCELL is not designed to predict too far outside their domain of expertise leading to very low activation scores for far away points and potential numerical instabilities.
\end_layout

\begin_layout Standard
For kCELL,
 we notice that for InvertedPendulum,
 transitions between gravity values lead to an increase in MAE on past test sets,
 seemingly reflecting partial forgetting of earlier dynamics.
 In contrast,
 for Hopper,
 kCELL exhibits stable MAE on previously encountered gravity values even after multiple regime changes,
 suggesting retiention of prior knowledge.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/mae_comparison_testsets_invertedpendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-mae-dynamic-changes-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/mae_comparison_testsets_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-mae-dynamic-changes-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of test error on each test dataset.
 Each horizontal plot shows the evolution of error on a test dataset (in order top to bottom:
 
\begin_inset Formula $g=9.81$
\end_inset

 (
\emph on
default
\emph default
),
 
\begin_inset Formula $g=4$
\end_inset

 (
\emph on
low gravity
\emph default
),
 
\begin_inset Formula $g=20$
\end_inset

 (
\emph on
high gravity
\emph default
).
 The semi-transparent red area corresponds to the training period in which the training and test sets correspond to the same dynamic variations.
 The dotted vertical red lines corresponds to changes in dynamics i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of points ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the MAE over the corresponding training set.
 The blue curve corresponds to kCELL's MAE measurements.
 For example the top plot corresponds to the MAE calculated on test data for 
\begin_inset Formula $g=9.81$
\end_inset

 and red area corresponds to the training phase in which 
\begin_inset Formula $g=9.81$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-mae-dynamic-changes"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Structural Evolution of Agent Population
\end_layout

\begin_layout Standard
We analyze the evolution of agent population during training illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-nb-agents"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 As previously hinted by MAE analysis,
 we notice contrasting dynamics in the population evolution during learning between the two environments.
 In InvertedPendulum (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 each gravity change induces a short-term surge in the number of agents,
 followed by a reduction and stabilization around a nominal value.
 This indicates a restructuring of the population,
 where novelty triggers agent creation and confidence-based mechanisms triggers destruction to eliminate less relevant agents.
\end_layout

\begin_layout Standard
In Hopper (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 the number of agents grows monotonically throughout training.
 Distinct growth regimes are observed for each gravity value with first a logaritmic growth (
\begin_inset Formula $g=9.81$
\end_inset

),
 second a seemingly linear growth (
\begin_inset Formula $g=4$
\end_inset

) and third a slight logarithmic growth (
\begin_inset Formula $g=20$
\end_inset

) with stabilization around 20k steps.
 This accumulation of agents suggests a continuous detection of local dynamics without systematic removal of existing agents.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/nb_agents_colored_zones_no_title_invertedpendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-nb-agents-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/nb_agents_colored_zones_no_title_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-nb-agents-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the number of agents in kCELL during learning.
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the number of agents in the system.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-nb-agents"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Age and Confidence Dynamics
\end_layout

\begin_layout Standard
The mean age of agents provides further insights on kCELL as presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-age"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 In InvertedPendulum (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-age-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 gravity changes coincide with abrupt drops in mean agent age.
 This means that the population becomes suddenly younger,
 which is consistent with the replacement of older agents by newly created ones following a shift in dynamics.
 This behavior aligns with a confidence-driven selection mechanism that favors agents specialized to the current dynamics.
\end_layout

\begin_layout Standard
In Hopper (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-age-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) however,
 the mean agent age increases almost constantly,
 with only minor decreases follwoing the first gravity change and a slight slowdown after the second.
 This indicates that older agents persist over time and are not fully displaced by newer ones,
 despite agent creations.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/age_of_agents_w500_no_title_colored_inverted_pendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-age-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/age_of_agents_w500_no_title_colored_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-age-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the age of agents in kCELL during learning (smoothed with a window of 500 steps).
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the mean age of agents (in steps) in the system .
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-age"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Activation and Local Expertise
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-activations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 shows the evolution of the activation of closest agent during learning.
 In InvertedPendulum (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-activations-invertedpendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 each gravity change results in a sharp drop in activation,
 signaling a loss of relevance of existing local modals.
 Activation values subsequently recovers as new agents acquire expertise under the new dynamics.
\end_layout

\begin_layout Standard
In Hopper (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-activations-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 activation levels differ across the different gravity regimes,
 with distinct nominal mean activation value observed for each values of gravity acceleration.
 Slight activation decreases are detectable immediately following changes in dynamics,
 these effects are less visible than in InvertedPendulum and partially blurred by higher variance regimes.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/max_activation_smooth_w500_colored_inverted_pendulum.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
InvertedPendulum
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-activations-invertedpendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/max_activation_smooth_w500_colored_hopper.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hopper
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-activations-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the maximum activation value of agents in kCELL during learning (smoothed with a window of 500 steps).
 Each semi-transparent colored area corresponds to a given training dataset / dynamic variation regime.
 The dotted vertical red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The 
\begin_inset Formula $x$
\end_inset

 axis corresponds to the number of point ingested (number of steps) and the 
\begin_inset Formula $y$
\end_inset

 axis corresponds to the maximum activation value of agents.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-activations"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the higher-dimensional Hopper environment,
 agent persistence can be explained by two non-exclusive mechanisms.
 First,
 it is possible that agents trained under earlier gravity settings retain partial competence in overlapping regions of the state-action space.
 Those agents are then incrementally adapted as new data arrives leading to multi-regime reuse.
 In this case the growth of agents can be explained mainly by the modeling complexity introduced by the change in dynamics.
 Second,
 high-dimensional effects may reduce the sensitivity of the Mahalanobis distance,
 yielding sparse activation of older agents that prevents both their meaningful adaption and confidence degradation.
 In this case,
 those agents can be considered as frozen because they are too tightly tied to previously visited regions that do not overlap with newly discovered ones after dynamic changes.
\end_layout

\begin_layout Standard
To disambiguate whether agent persistence in the Hopper environment arises from adaptive reuse or from limited cross-regime activation,
 we analyze the activation patterns of the final agent population obtained after full training.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-of-activations-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a heatmap of agent activations for all training samples,
 where columns correspond to agents sorted by age (from oldest to youngest) and rows correspond to training data points (in order) aggregated into bins.
 The resulting heatmap exhibits distinct block patterns,
 with older agents primarily activated for samples from the earliest dataset and progressively younger agents ddominating activation for later datasets.
 We can also observe that the shape of the number of agents curve (presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-nb-agents-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) appears in the heatmap drawn by points where agents are the most active.
 This organization further indicates that agents remain selectively active for the dynamics under which they were trained and created rather than becoming inactive or obsolete.
\end_layout

\begin_layout Standard
Complementary,
 we provide a two-dimensional UMAP 
\begin_inset CommandInset citation
LatexCommand cite
key "mcinnes2018umap"
literal "false"

\end_inset

 projection of the training data in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:UMAP-of-training-hopper"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 with samples colored according to their corresponding gravity regime.
 The projection reveals a clear separation between training datasets,
 suggesting that changes in dynamics induce distinct regions in the state-action space.
 This structural separation provides a plausible geometric explanation for the coexistence of multiple generations of agents.
 Because data from different dynamics regimes occupy largely disjoint regions,
 agents specialized to earlier dynamics remain relevant for their corresponding subspaces without interfering with those created for later regimes.
\end_layout

\begin_layout Standard
These analyses support the claim that agent retention in the Hopper environment is primarily driven by regime-specific specialization in a high-dimensional space,
 rather than by passive survival due to insufficient confidence updates that would prevent the destruction process.
 While Mahalanobis distance may lose discriminative power in higher dimensional spaces,
 the observed seperation of state-action distributions enables kCELL to maintain multiple local experts corresponding to different dynamics.
 This results in stable prediction performance across successive dynamics changes.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/agents_activation_heatmap_no_title_w300.png
	lyxscale 30
	width 70col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Heatmap of final Agents Activations on Training Datasets.
 
\begin_inset Formula $y$
\end_inset

-axis correspond to the training data (in order) aggregated into bins of size 300 (from top to bottom) and 
\begin_inset Formula $x$
\end_inset

-axis corresponds to agents ids sorted from the oldest to the youngest (left to right).
 The dotted horizontal red lines corresponds to changes in dynamic i.e to a change of train dataset with a different value of 
\begin_inset Formula $g$
\end_inset

.
 The colors corresponds to activation levels of agents over each aggregated training data bins with yellow meaning high activation and blue meaning low activation.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Heatmap-of-activations-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/dynamic_change_comparison/train_umap_without_agents.png
	lyxscale 30
	width 70col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of UMAP projection of Training data where each point is colored depending on the training dataset it comes from (blue for 
\begin_inset Formula $g=9.81$
\end_inset

;
 yellow for 
\begin_inset Formula $g=4$
\end_inset

;
 pink for 
\begin_inset Formula $g=20$
\end_inset

)
\begin_inset CommandInset label
LatexCommand label
name "fig:UMAP-of-training-hopper"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Discussion
\end_layout

\begin_layout Standard
The results presented suggest that kCELL were able to adapt to non-stationary dynamics through a combination of local specialization and structural plasticity with behaviors that depend strongly on the dimensionality and geometry of the feature space.
 In both environments,
 kCELL succesfully reduces prediction error on the currently observed dynamics demonstrating effective online adaptation without explicit task or concept drift detection modules.
 Compared to a Hoeffding Adaptive Tree baseline,
 kCELL achieves lower MAE for the low-dimensional InvertedPendulum environment when training and testing distributions coincide.
 It also achieves comparable performances for the higher-dimensional Hopper environment although with increased variability due to its structural adaptivity.
\end_layout

\begin_layout Standard
For the InvertedPendulum environment,
 changes in dynamics induced a rapid loss of relevance of agents trained on previous dynamics leading to their destruction or adjustment.
 This is reflected by sharp drops in agent activation,
 decreases in mean agent age,
 temporary surges in the number of agents followed by a stabilization and the observed increase in MAE on previously encountered dynamics.
 These indicate a population renewal process driven by confidence degradation and agent replacement.
 In this setting,
 partial forgetting emerges as a natural consequence of the overlap between the geometry of different dynamics and reflects appropriate structural adaptation rather than failure of retention.
\end_layout

\begin_layout Standard
In contrast,
 the Hopper environment exhibits persistent agent populations and stable prediction performance across successive dynamics changes.
 Although the number of agents grows monotonically,
 confidence-based destruction prevents the survival of agents that negatively impact prediction accuracy.
 The absence of population turnover is therefore not attributable to ineffective agent pruning.
 Analysis of agent activations reveals a structured specialization pattern.
 The activation heatmap of the final agent population shows distinct blocks associated with different training phases.
 Older agents are selectively activated for earlier gravity regimes and younger agents for later ones.
 This organization indicates retention of regime-specific expertise rather than passive persistence of obsolete models.
 Indeed,
 the agents do not know when a new dynamics change might occur and which dynamics will replace the current one.
\end_layout

\begin_layout Standard
This interpretation is further supported by the UMAP analysis of the training data,
 which reveals clear separation between datasets generated with different gravity values.
 The existence fo well-separated regions in the state-action space provides a plausible explanation for the coexistence of multiple generations of agents without destructive interference.
 Thus,
 in this case,
 high dimensionality enables to allocate distinct subsets of agents to different dynamics.
 Although Mahalanobis distance may lose discriminative precision as dimensionality increases,
 for this experiment with 11-dimensional states and 3-dimensional actions (resulting in a 14-dimensional input vector),
 the geometric separation induced by gravity changes appears sufficient to maintain effective specialization.
\end_layout

\begin_layout Standard
Overall,
 the results suggest that kCELL implicitly adjusts the tradeoff between forgetting and retention based on the structure of the data distribution rather than relying on explicit task boundaries.
 In low-dimensional spaces,
 adaptation is achieved through agent replacement and partial forgetting,
 while in higher-dimensional settings with separable regimes,
 the system favors retention and specialization.
 These results highlight both the strength and current limitations of kCELL.
 It paves the way for future works on the use of more robust distance metrics and activation mechanisms to account for high-dimensional geometry.
\end_layout

\begin_layout Standard
Finally,
 we highlight the ability to analyze kCELL through the spatial organization and activation patterns of agents as a key advantage in terms of interpretability.
 Introspection of agent properties allows to identify which regions of the state-action space correspond to different dynamics.
 This provide understanding on how the model responds to non-stationary conditions which can be useful to debug,
 refine learning mechanisms or build fallback strategies.
 This relates to the properties we presented in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Explainability-oCELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 showing that despite the design differences with oCELL,
 some related properties remain.
\end_layout

\begin_layout Subsection
Online Stationary Modeling
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on SARCOS + D4RL + KUKA to test raw performances with river-ml algorithms
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Comparative Study of CELL Variants
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Comparison of paving for robot in maze / or pendulum between oCELL and kCELL
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on SARCOS + D4RL to test raw performances
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Experiment on number of neighbors and mahalanobis distances in various dimensions and mention agent growth and problems of dimensionality
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Discussions and Limitations
\begin_inset CommandInset label
LatexCommand label
name "subsec:kCELL-Discussions-and-Limitations"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add comparison between oCELL and kCELL
\end_layout

\begin_layout Plain Layout
- Gaussian representation better via smoothness and degrees of freedom but still is an assumption about daat distribution => corrected via PCA ?
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Solving Control Tasks with CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Solving-Control-Tasks"

\end_inset


\end_layout

\begin_layout Standard
Building upon the Self Adaptive Context Learning (SACL) paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

,
 we introduced the CELL (Context Ensemble Local Learning) paradigm,
 which provides the core hypothesis and theoretical ground for designing spatialized multiagent learning systems.
 Within this paradigm,
 algorithms such as oCELL and kCELL rely on a population of agents spatialized in feature space.
 Each agent learns a local predictive model from a stream of data.
 These online learning systems exhibit intrinsic interpretability and explainability properties that arise from the spatial organization of agents,
 spatialized local learning and agent-level interactions.
\end_layout

\begin_layout Standard
This chapter investigates how these properties can be exploited for model-based control with learned model without prior knowledge of system dynamics.
 In this setting,
 control policies are built from the combination of a learned predictive model and an optimizer.
 This corresponds to the Model Predictive Control (MPC) framework,
 in which control actions are obtained by repeatedly optimizing predicted trajectories over a finite horizon 
\begin_inset CommandInset citation
LatexCommand cite
key "rawlings2017model"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
When the predictions of learned models lie outside the regions in the state-action space that have been sufficiently represented in the training data,
 the model is inherently limited in terms of accuracy.
 This limitation needs to be considered in optimal control problems involving hard constraints related to safety,
 stability or physical feasibility 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

.
 Indeed,
 unreliable predictions lead to unreliable optimization results.
 While data-driven control methods have achieved promising results,
 they often rely on opaque inner workings and struggle to provide reliable guarantees when operating outside the support of the training data 
\begin_inset CommandInset citation
LatexCommand cite
key "prag2022toward,berberich2025overview"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In this chapter we show that kCELL's structural transparency provides introspection tools that can be directly embedded into control and optimization pipelines.
 kCELL exposes measurable quantities such as distance-based competence,
 local prediction disagreement that provide proxies for quantifying epistemic and aleatoric uncertainties (cf.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:XAI"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 for definitions).
 kCELL's properties can then be leveraged to guide exploration,
 regularize exploitation and explain control decisions in a unified framework.
\end_layout

\begin_layout Standard
More specifically,
 the core contributions presented in this chapter are fourfold:
\end_layout

\begin_layout Itemize
We provide a discussion on how kCELL can be efficiently integrated into real-time,
 model-based control frameworks by exploiting its local linearization capabilities for gradient-based optimization and implementation strategies based on parallel computation or spatial indexing for fast trajectory unfolding in population-based MPC.
\end_layout

\begin_layout Itemize
We introduce introspection-driven strategies based on agent spatial organization and local disagreement for exploration of a low-dimensional environment without prior knowledge of the dynamics.
 We show that these strategies lead to more effective coverage of the state-action space than uninformed exploration mechanisms.
\end_layout

\begin_layout Itemize
We introduce an introspection-driven conservative regularization mechanism for trajectory optimization that leverages kCELL's explicit notion of local model competence,
 reducing the risk of extrapolation errors and improving robustness of control with learned dynamics.
\end_layout

\begin_layout Itemize
We present a novel local explanation method based on Linear Quadratic Regulator (LQR) 
\begin_inset CommandInset citation
LatexCommand cite
key "kalman1960contributions"
literal "false"

\end_inset

 for constrained model-based control.
 This approach allows quantification of constraint impact and feature importance estimation in optimized control policies.
\end_layout

\begin_layout Standard
This chapter is organized as follows.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Parallelization-and-Differentiability"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses the computational and differentiability properties of kCELL that make it suitable for real-time constrained control within a MPC scheme.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Exploration-MPC"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 focuses on exploration of unknown dynamics and shows how the spatial organization and local interactions of agents can be exploited to drive data-efficient exploration.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conservative-MPC"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 addresses robust exploitation by introducing knowledge-aware regularization for trajectory optimization with kCELL.
 Finally,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Explainable-Control-(LQR)"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 introduces a novel LQR-based explanation mechanism for constrained controllers to evaluate the impact of constraints on the optimization process and to estimate feature importance,
 highlighting how kCELL allows to obtain interpretable and explainable control decisions.
\end_layout

\begin_layout Section
Efficient kCELL for Real-Time Control
\begin_inset CommandInset label
LatexCommand label
name "sec:Parallelization-and-Differentiability"

\end_inset


\end_layout

\begin_layout Standard
kCELL provides a more robust and expressive instantiation of the CELL paradigm.
 It is capable of handling non-stationary online learning tasks and maintaining interpretability.
 However,
 its practical deployment in model-based control requires additional computational and structural considerations.
\end_layout

\begin_layout Standard
Model Predictive Control (MPC) relies on repeated model evaluations within an optimization loop.
 When using learned models,
 inference speed and mathematical structure are important to the feasibility and reliability of control,
 especially if real-time constraints need to be met.
\end_layout

\begin_layout Standard
To this end,
 two main requirements must be addressed.
 First,
 population-based optimization methods commonly employed in data-driven MPC,
 such as the Cross-Entropy Method (CEM) 
\begin_inset CommandInset citation
LatexCommand cite
key "de2005tutorial"
literal "false"

\end_inset

,
 require fast and batched predictions over large sets of candidate trajectories whose computational cost must remain predictable across control steps.
 Purely sequential inference with naive expert lookup in kCELL prohibitively expensive.
 Second,
 gradient-based optimization methods,
 such as Sequential Quadratic Programming (SQP) 
\begin_inset CommandInset citation
LatexCommand cite
key "rawlings2017model"
literal "false"

\end_inset

,
 require differentiable predictive models in order to compute local linearization of the dynamics and to handle hard constraints efficiently.
\end_layout

\begin_layout Standard
kCELL must therefore comprise optimized implementations to enable fast batched inference and differentiable representations to support gradient-based control methods.
 Regarding computational efficiency,
 in kCELL,
 expert selection can be accelerated significantly through spatial indexing or parallel execution,
 enabling efficient batched inference on modern hardware such as GPUs.
 Regarding differentiability,
 when activation functions and internal models are differentiable,
 kCELL admits analytic gradients and straightforward local linearization,
 making it naturally compatible with gradient-based MPC formulations.
\end_layout

\begin_layout Standard
Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Efficient-Implementation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 discusses strategies that can be implemented to accelerate inference and learning in kCELL,
 making it suitable for use with random shooting optimization methods like CEM.
 Then,
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:MPC-and-Local-Linearization"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows how the local structure of kCELL lead to trivial local linearizations of the learned dynamics,
 making kCELL suited for constrained MPC solved using SQP.
\end_layout

\begin_layout Subsection
Efficient Implementation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Efficient-Implementation"

\end_inset


\end_layout

\begin_layout Standard
Population based trajectory optimization algorithms are broadly used in robotics for their robustness to non-convex and non-smooth dynamics or cost functions 
\begin_inset CommandInset citation
LatexCommand cite
key "chai2019review"
literal "false"

\end_inset

.
 This includes stochastic shooting methods such as Model Path Predictive Integral (MPPI) or CEM (which is used in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Exploration-MPC"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 These methods rely heavily on parallel evaluation of large population of candidate trajectories at each control step within the MPC framework.
 In this section,
 we show that GPU parallel brute force is more reliable than geospatial indexing for nearest neighbor selection to speed up learning and inference process in kCELL for population based MPC.
\end_layout

\begin_layout Subsubsection
Geospatial Tree Indexing
\end_layout

\begin_layout Standard
In CELL instanciations like kCELL and oCELL,
 a learning step always begins with a neighboring agent selection phase.
 Since the agents are spatially distributed in the feature space,
 then the selection of neighboring agents can be broken down into two components:
 distance calculation to find the closest agents and thresholding of those distances to discriminate neighbors.
\end_layout

\begin_layout Standard
Because agents are spatially distributed within the feature space,
 managing the ensemble of agents as a geospatial database can be considered.
 In this case,
 to speed up nearest neighbor searches,
 spatial indexing techniques can be leveraged to select the k-closest agents with a reduced complexity.
 Indexing in geospatial databases is most commonly performances using tree-based methods such as KD-tree or R-tree 
\begin_inset CommandInset citation
LatexCommand cite
key "guting1994introduction"
literal "false"

\end_inset

.
 The KD-tree (for k-dimensional tree) is a binary tree data structure.
 It recursively partition space by splitting along alternating dimensions,
 making it efficient for range queries and nearest neighbor searches on point data 
\begin_inset CommandInset citation
LatexCommand cite
key "bentley1975multidimensional"
literal "false"

\end_inset

 (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-KD-tree"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 The R-tree is a hierarchical tree structure designed for indexing multi-dimensional objects like rectangles or polygons.
 Each node of the tree represents a bounding rectangle that encloses child nodes.
 R-trees are particularly suited for range,
 intersection and nearest neighbor queries in GIS and geospatial databases 
\begin_inset CommandInset citation
LatexCommand cite
key "guttman1984r"
literal "false"

\end_inset

 (cf.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Visualization-of-R-tree"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/kdtree_illustration.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
KD-tree
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-KD-tree"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/rtree_illustration.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
R-tree
\begin_inset CommandInset label
LatexCommand label
name "fig:Visualization-of-R-tree"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of KD-tree and R-tree on 2D data
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-KD-tree-and-R-tree"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the context of CELL instantiations,
 R-trees are better suited than KD-trees because they are designed to handle polygons and orthotopes,
 i.e 
\begin_inset Formula $n$
\end_inset

-dimensional generalizations of rectangles.
 Therefore,
 agents can be indexed by their bounding orthotope.
 For kCELL,
 this is the orthotope encompassing the agent's confidence interval specified as a parameter.
 Furthermore,
 R-trees can be incrementally updated,
 making them compatible with the online learning nature of CELL instantiations 
\begin_inset CommandInset citation
LatexCommand cite
key "guttman1984r"
literal "false"

\end_inset

.
 Finally,
 with a spatial index based on a R-tree,
 the selection process can be broken down into three ordered steps:
 searching for the k-closest agents in the R-tree,
 calculating the distances between the point and the k-closest agents and finally thresholding the distances to discriminate the neighbor agents.
\end_layout

\begin_layout Standard
Implementing a R-tree as a geospatial index over the agents reduces the neighborhood searches from 
\begin_inset Formula $O\left(n\right)$
\end_inset

 in the naive case to 
\begin_inset Formula $O\left(\log n\right)$
\end_inset

.
 However,
 for insertion and deletion,
 the average time complexity increases from 
\begin_inset Formula $O\left(1\right)$
\end_inset

 in the naive case to 
\begin_inset Formula $O\left(\log n\right)$
\end_inset

 with geospatial indexing.
 While geospatial indexing seems less advantageous in terms of insertion and deletion,
 it should be remembered that agent creations and destructions are generally less frequent then neighborhood searches in kCELL.
\end_layout

\begin_layout Subsubsection
GPU Parallelization
\end_layout

\begin_layout Standard
However,
 as the dimensionality of the feature space increases,
 the structural advantages of the R-tree diminish due to distance distention and bounding box overlap making the search complexity degenerate to 
\begin_inset Formula $O\left(n\right)$
\end_inset

.
 In such cases,
 the overhead induced by geospatial indexing offers no advantage over a brute-force approach.
 To address these limitations,
 the embarrassingly parallelizable nature of neighborhood search in kCELL (and oCELL) can be exploited through GPU acceleration.
 By shifting from pointer-based tree structures to dense tensor representations,
 kCELL (and oCELL) can leverage massive parallel throughput as the selection phase can be executed as a vectorized linear algebra operation.
\end_layout

\begin_layout Paragraph
Memory Layout
\end_layout

\begin_layout Standard
To maximize the efficiency of using the GPU for agent selection,
 agent data is stored in contiguous memory block.
 For example,
 for kCELL system,
 we define two global agent tensors for storing the parameters of the activation functions,
\begin_inset Formula 
\[
\mathcal{T}_{\mu}\in\mathbb{R}^{N\times n},\,\,\mathcal{T}_{\Sigma}\in\mathbb{R}^{N\times n\times n}
\]

\end_inset

 where 
\begin_inset Formula $N$
\end_inset

 is the maximum agent capacity of the agent pool and 
\begin_inset Formula $n$
\end_inset

 is the number of features.
 
\begin_inset Formula $\mathcal{T}_{\mu}$
\end_inset

 is for storing the means and 
\begin_inset Formula $\mathcal{T}_{\Sigma}$
\end_inset

 is for storing the covariance matrices.
 With this layout,
 the GPU hardware can easily saturate its bandwith for efficient distance computations.
\end_layout

\begin_layout Paragraph
Dynamic Agent Population
\end_layout

\begin_layout Standard
In CELL systems,
 the number of agents is dynamic.
 Agents can be created or destroyed depending on the needs of the system.
 In a GPU parallelization context with contiguous memory storage,
 managing a dynamic set of agents requires efficient creation and deletion strategies to avoid costly memory allocations.
\end_layout

\begin_layout Standard
The most straightforward approach consists in a dynamic reallocation of memory each time an agent is created or destroyed as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Illustration-of-dynamic-reallocation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 Although easy to implement,
 this approach is unsuitable for high-frequency learning loops due to the overhead induced by re-allocating GPU memory and copying of existing data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/dynamic_reallocation_creation_destruction.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of agent creation and destruction in dynamic reallocation regime
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-dynamic-reallocation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
To achieve 
\begin_inset Formula $O\left(1\right)$
\end_inset

 updated complexity,
 another strategy can be considered.
 Fixed-capacity tensors are pre-allocated to store agents data.
 A boolean masking vector 
\begin_inset Formula $\mathcal{M}\in\left\{ 0,1\right\} ^{N}$
\end_inset

 is maintained to track which memory slot contains an agent or not.
\end_layout

\begin_layout Standard
Agent creation then consists in assigning new agents data to the first index 
\begin_inset Formula $i$
\end_inset

 such that 
\begin_inset Formula $\mathcal{M}_{i}=0$
\end_inset

.
 If the agent population exceeds the predefined capacity,
 standard dynamic resizing strategies can be employed.
\end_layout

\begin_layout Standard
Conversely,
 agent deletion sets 
\begin_inset Formula $\mathcal{M}_{i}=0$
\end_inset

,
 marking the slot as available to host data of future agents as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Illustration-of-preallocated-memory-pool"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 This effectively hide the agent from the selection kernel without moving data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/preallocated_memorpool_creation_destruction.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of agent creation and destruction in preallocated memory pool with masking regime
\begin_inset CommandInset label
LatexCommand label
name "fig:Illustration-of-preallocated-memory-pool"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For selection,
 the mask 
\begin_inset Formula $\mathcal{M}$
\end_inset

 is used to filter the active memory slots and retrieve only relevant distance computations (i.e those corresponding to existing agents).
\end_layout

\begin_layout Subsubsection
Comparison between GPU and Tree Selection
\end_layout

\begin_layout Standard
The choice of using a geospatial index or the parallelization enabled by a GPU depends on the number of features and the quantity of agents required for learning the function underlying the data which is highly correlated to its complexity.
\end_layout

\begin_layout Standard
To evaluate the impact of this structural shift,
 we benchmark neighborhood selection in Python using 
\emph on
PyTorch
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2019pytorch"
literal "false"

\end_inset

 for GPU accelerated computations and using 
\emph on
Rtree
\emph default
 package 
\begin_inset CommandInset citation
LatexCommand cite
key "gilliesRtreeSpatialIndexing"
literal "false"

\end_inset

 for efficient R-tree implementation.
 We compare the two selection approaches presented previously on a synthetic nearest neighbor selection task for variable amount of features and agents.
 The synthetic centroids are generated to form 100 clusters to simulate high density manifolds.
 As shown in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 in CELL instantiations like oCELL and kCELL,
 agents organize spatially according to the data encountered.
 In real-world cases,
 these data points are rarely uniformly distributed.
 Indeed,
 uniform distribution could overestimate the volume of search.
 Using clustered centroid distribution allows a fairer comparison for R-trees whose main strength is to prune empty space.
\end_layout

\begin_layout Standard
From a set of 1000 input points,
 the time to find the 5-nearest neighbors is measured and averaged across 3 cycles.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 exposes a heatmap of the relative execution time difference in percentage expressed as
\begin_inset Formula 
\[
\Delta_{t}=\frac{\Delta_{\text{GPU}}-\Delta_{\text{R-tree}}}{\Delta_{\text{R-tree}}}\times100
\]

\end_inset

 where 
\begin_inset Formula $\Delta_{\text{GPU}}$
\end_inset

 and 
\begin_inset Formula $\Delta_{\text{R-tree}}$
\end_inset

 the execution time of a nearest neighbor query averaged over 3 cycles.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Binary-winner-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows which strategy has obtained lowest execution time in each studied configuration.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Spatial Indexing:
 explain how the expert lookup is accelerated by KD-tree,
 grid-based indexing,
 or other structures.
\end_layout

\begin_layout Plain Layout
GPU Parallelization:
 show batching of local predictions for multiple states/actions.
\end_layout

\begin_layout Plain Layout
Optionally include a profiling experiment:
 inference time vs number of experts/states.
\end_layout

\begin_layout Plain Layout
Highlight differentiability:
 why it is essential for gradient-based MPC/SQP.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/benchmark/relative_time_diff_rtree_gpu_comprison_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Relative Execution Time Difference Heatmap
\begin_inset CommandInset label
LatexCommand label
name "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/benchmark/binary_perf_diff_rtree_gpu_comprison_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Winner Binary Heatmap
\begin_inset CommandInset label
LatexCommand label
name "fig:Binary-winner-R-tree-GPU"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of the execution times of GPU and R-tree on various 
\begin_inset Formula $\left\{ n,N\right\} $
\end_inset

 configurations for a clustered distribution of synthetic centroids.
\begin_inset CommandInset label
LatexCommand label
name "fig:Comparison-R-tree-GPU-agent-selection"

\end_inset

 contains a heatmap of the relative execution time difference between the two strategies (
\begin_inset Formula $\Delta_{t}$
\end_inset

).
 Shades of yellow correspond to 
\begin_inset Formula $\Delta_{t}>0$
\end_inset

,
 i.e to R-tree being faster.
 Conversely,
 shades of blue correspond to 
\begin_inset Formula $\Delta_{t}<0$
\end_inset

,
 i.e to GPU being faster.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 contains a binary heatmap clearly showing in which configuration which strategy was faster.
 White cells corresponds to configurations in which R-tree was faster and black cells correspond to configurations in which GPU was faster.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The benchmarking results show that R-tree maintains a competitive edge in low-dimensional regimes (
\begin_inset Formula $n\leq5$
\end_inset

).
 This is an expected result as R-trees struggles in higher dimensions due to the curse of dimensionality.
 In higher dimensional regimes the distinction between nearest and farthest points becomes meaningless and pruning becomes ineffective 
\begin_inset CommandInset citation
LatexCommand cite
key "kouiroukidis2011effects"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
However,
 the performances of the R-tree compared to GPU does not seem monotonic.
 In Figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Heatmap-Relative-time-diff-comparison-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Binary-winner-R-tree-GPU"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we notice a non linear phase transition area (looking like a 
\begin_inset Quotes eld
\end_inset

semi-banana
\begin_inset Quotes erd
\end_inset

) that extends from 
\begin_inset Formula $N=2500$
\end_inset

 centroids and 
\begin_inset Formula $n=70$
\end_inset

 features to 
\begin_inset Formula $N=20000$
\end_inset

 and 
\begin_inset Formula $n=50$
\end_inset

.
 Within this region,
 R-tree is competitive or faster than GPU.
\end_layout

\begin_layout Standard
As shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Winner-binary-heatmap-uniform"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the competitive advantage of R-trees within the non linear phase transition area fades when the centroids are uniformly distributed.
 In this case the R-trees are almost never faster than GPU computation.
 It shows that the structure of data needs to be analyzed beforehand to make sure R-tree indexing is a pertinent indexing option.
 This is an expected result because R-trees are particularly adapted to prune large empty spaces.
 The uniform distribution of centroids does not exhibit exploitable structures for the R-tree.
 This is not an issue for the GPU based nearest neighbor computations that is a brute force approach that does not rely on structure.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/benchmark/binary_perf_diff_rtree_gpu_comprison_uniform_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Winner binary heatmap with uniformly distributed synthetic centroids
\begin_inset CommandInset label
LatexCommand label
name "fig:Winner-binary-heatmap-uniform"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
These observations indicate that the performance of nearest neighbor selection with R-trees compared to using GPUs is better in low dimensional regimes (
\begin_inset Formula $n\leq5$
\end_inset

) and depends heavily on the underlying data structures when the number of dimensions increases (
\begin_inset Formula $n\geq5$
\end_inset

) due to the curse of dimensionality.
\end_layout

\begin_layout Standard
From an engineering standpoint,
 GPU-based selection provides a more predictable and stable latency profile,
 independent of data distribution.
 While R-tree indexing can provide large gains in very specific sparse regimes,
 its performance is highly sensitive to the latent structure of the learned model (i.e the distribution of agents).
\end_layout

\begin_layout Standard
In an online learning setting for adaptive control in a MPC scheme without prior knowledge of the dynamics of the environment,
 the data distribution is not known in advance and may evolve over time.
 For this reason,
 the GPU-based brute-force selection is preferred for its 
\emph on
deterministic latency
\emph default
 and 
\emph on
hardware scalability
\emph default
.
 Indeed,
 GPU execution time scales predictably with 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $N$
\end_inset

,
 whereas R-tree latency exhibits high variance depending on tree depth and splits overlap.
 Moreover,
 GPUs naturally handles batch queries as a single high-throughput operation,
 which can be deemed useful for population-based optimization.
\end_layout

\begin_layout Standard
The implementation strategies discussed in this section address the primary computational bottleneck of kCELL for use in a MPC scheme,
 namely the repeated selection and evaluation of local experts under strict real-time constraints.
 By leveraging either spatial indexing or GPU brute force selection,
 kCELL can be integrated into population-based trajectory optimizers while maintaining predictable inference and learning latency.
\end_layout

\begin_layout Standard
However,
 computational efficiency alone is not sufficient for kCELL to be deployed with gradient-based optimizers that could potentially handle hard constraints.
 Such approaches require predictive models to admit local linearizations.
\end_layout

\begin_layout Subsection
Differentiability and Local Linearization for Gradient-Based MPC
\begin_inset CommandInset label
LatexCommand label
name "subsec:MPC-and-Local-Linearization"

\end_inset


\end_layout

\begin_layout Standard
Fast and scalable inference in kCELL is essential for its integration into real-time MPC frameworks,
 especially when using population-based or gradient-based trajectory optimization methods that rely on repeated model evaluations.
\end_layout

\begin_layout Standard
However,
 computational efficiency alone is insufficient when MPC formulation rely on gradient-based optimization methods that exploit local structures to enforce hard constraints.
 Such approaches require predictive models that admit reliable local linearizations of the learned system dynamics.
\end_layout

\begin_layout Standard
In this section,
 we show that kCELL naturally provides local affine approximations of the dynamics that are directly compatible with gradient-based optimization approaches such as Sequential Quadratic Programming (SQP).
\end_layout

\begin_layout Subsubsection
Differentiability in CELL instantiations
\end_layout

\begin_layout Standard
In CELL instantiations,
 online learning is performed by maintaining a set of self-organizing spatialized agents that map the target function locally (cf.
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 A context agent is denoted as
\begin_inset Formula 
\[
\mathcal{A}_{i}=\left\{ \phi_{i},f_{i}\right\} 
\]

\end_inset

where 
\begin_inset Formula $\phi_{i}:\mathbb{R}^{n}\mapsto\left]0,1\right]$
\end_inset

 is an activation function that maps features to a level of expertise for predicting a given input and 
\begin_inset Formula $f_{i}:\mathbb{R}^{n}\mapsto\mathbb{R}^{m}$
\end_inset

 is local internal prediction function that maps features to target outputs.
\end_layout

\begin_layout Standard
In CELL instantiations,
 the global prediction is obtained by aggregating the predictions of agents,
 leveraging activation and prediction functions through an aggregation function.
 If the activation function,
 the prediction function and the aggregation function are differentiable,
 then,
 by standard composition rule,
 the global prediction function of the system is differentiable.
\end_layout

\begin_layout Standard
For kCELL,
 we consider a RBF kernel as the activation function,
 an affine function as the prediction function and a weighted average as the aggregation function.
 The final prediction is obtained by 
\begin_inset Formula 
\begin{equation}
f\left(x\right)=\frac{\sum_{i}\phi_{i}\left(x\right)f_{i}\left(x\right)}{\sum_{i}\phi_{i}\left(x\right)}=\sum_{i}w_{i}\left(x\right)f_{i}\left(x\right)
\end{equation}

\end_inset

where 
\begin_inset Formula $w_{i}\left(x\right)$
\end_inset

 are the normalized weights such as 
\begin_inset Formula $\sum_{i}w_{i}\left(x\right)=1$
\end_inset

.
\end_layout

\begin_layout Standard
As all the involved functions are differentiable with respect to 
\begin_inset Formula $x$
\end_inset

,
 the derivative of the prediction function of the system if given by
\begin_inset Formula 
\begin{equation}
\frac{\partial f}{\partial x}\left(x\right)=\sum_{i}\left(\frac{\partial w_{i}}{\partial x}\left(x\right)f_{i}\left(x\right)+w_{i}\left(x\right)\frac{\partial f_{i}}{\partial x}\left(x\right)\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This property makes kCELL usable in gradient-based nonlinear optimization frameworks.
 However,
 we argue that a principled approach to linearization can be leveraged by exploiting kCELL's internal structure.
 In typical model-based control,
 non-linear dynamics are lienarized via a first-order Taylor expansion to fit the requirements of convex optimization 
\begin_inset CommandInset citation
LatexCommand cite
key "rawlings2017model"
literal "false"

\end_inset

.
 However,
 when the predictive model is already an ensemble of local linear structures,
 applying a Taylor expansion becomes conceptually redundant.
 For this reason,
 we propose to bypass standard differentiation in favor of the structural local linearization capabilities of kCELL.
\end_layout

\begin_layout Subsubsection
Local Linearization
\end_layout

\begin_layout Standard
In kCELL,
 the spatial organization of agents and their linear internal models allows to extract local affine models without computing full Jacobians or Taylor expansions.
\end_layout

\begin_layout Standard
In MPC,
 the predictive model predicts the next state 
\begin_inset Formula $s_{t+1}$
\end_inset

 from 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

 where 
\begin_inset Formula $s_{t}$
\end_inset

 is the current state of the system and 
\begin_inset Formula $u_{t}$
\end_inset

 is the action to take.
 Assuming agents have linear internal models 
\begin_inset Formula $f_{i}\left(x_{t}\right)=A_{i}s_{t}+B_{i}u_{t}+c_{i}$
\end_inset

,
 the local affine model around a input point 
\begin_inset Formula $x_{t}$
\end_inset

 is given by
\begin_inset Formula 
\begin{eqnarray}
A\left(x_{t}\right)s+B\left(x_{t}\right)u+c\left(x_{t}\right) & = & \sum_{i}w_{i}\left(x_{t}\right)f_{i}\left(x_{t}\right)\\
 & = & \sum_{i}w_{i}\left(x_{t}\right)\left(A_{i}s_{t}+B_{i}u_{t}+c_{i}\right)\\
 & = & \underbrace{\sum_{i}w_{i}\left(x_{t}\right)A_{i}}_{A\left(x_{t}\right)}s_{t}+\underbrace{\sum_{i}w_{i}\left(x_{t}\right)B_{i}}_{B\left(x_{t}\right)}u_{t}+\underbrace{\sum_{i}w_{i}\left(x_{t}\right)c_{i}}_{c\left(x_{t}\right)}\label{eq:kcell-local-linear-model}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
This approach offers a significant advanatge for control because it preserves the dynamics as learned by the model in the first place.
\end_layout

\begin_layout Subsubsection
Sequential Quadratic Programming (SQP)
\end_layout

\begin_layout Standard
Sequential Quadratic Programming (SQP) is a local optimization method designed for solving nonlinear constrained problems.
 The optimization problem to solve is a nonlinear program formulated as
\begin_inset Formula 
\begin{align*}
\min_{u_{0:T-1}}\,\,\, & J\left(s_{0:T},u_{0:T-1}\right)\\
\text{s.t.\,\,\, } & s_{t+1}=f\left(s_{t},u_{t}\right)\\
 & h\left(s_{t},u_{t}\right)\leq0\\
 & g\left(s_{t},u_{t}\right)=0
\end{align*}

\end_inset

where 
\begin_inset Formula $J:\mathbb{R}^{n\times T}\mapsto\mathbb{R}$
\end_inset

 is the cost function,
 
\begin_inset Formula $f$
\end_inset

 the dynamic function describing the system,
 
\begin_inset Formula $h$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 correspond respectively to the supplementary inequality and equality constraints.
\end_layout

\begin_layout Standard
At each iteration,
 the original nonlinear program is approximated by a Quadratic Program (QP) in which the objective is quadratic and the dynamics and constraints are linearized around a reference trajectory
\begin_inset Formula 
\begin{align*}
\min_{u_{0:T-1}}\,\,\, & \sum_{t=0}^{T-1}\left(s_{t}^{\top}Q_{t}s_{t}+q_{t}^{\top}s_{t}+u_{t}^{\top}R_{t}u_{t}+r_{t}^{\top}u_{t}\right)\\
\text{s.t.\,\,\, } & s_{t+1}=A_{t}s_{t}+B_{t}u_{t}+c_{t}\\
 & h_{\text{lin}}\left(s_{t},u_{t}\right)\leq0\\
 & g_{\text{lin}}\left(s_{t},u_{t}\right)=0
\end{align*}

\end_inset

where 
\begin_inset Formula $A_{t}$
\end_inset

,
 
\begin_inset Formula $B_{t}$
\end_inset

 and 
\begin_inset Formula $c_{t}$
\end_inset

 define the locally linearized dynamics obtained from a first-order Taylor expansion,
 
\begin_inset Formula $h_{\text{lin}}$
\end_inset

 and 
\begin_inset Formula $g_{\text{lin}}$
\end_inset

 correspond respectively to the linearized inequality and equality constraints obtained from a first-order Taylor expansion,
 the matrices 
\begin_inset Formula $Q_{t}$
\end_inset

,
 
\begin_inset Formula $R_{t}$
\end_inset

 and vectors 
\begin_inset Formula $q_{t}$
\end_inset

,
 
\begin_inset Formula $r_{t}$
\end_inset

 are obtained from a second-order Taylor expansion of the original cost 
\begin_inset Formula $J$
\end_inset

 around the reference trajectory 
\begin_inset Formula $\tau_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
Solving this QP yields a new trajectory 
\begin_inset Formula $\tau_{t+1}$
\end_inset

 than is used to compute a descent direction 
\begin_inset Formula $\tau_{t+1}-\tau_{t}$
\end_inset

.
 Since both SQP and kCELL rely on locally valid approximations of the dynamics,
 the update step must be restricted to remain within the region where the linearization is accurate.
 To this end,
 a line search 
\begin_inset CommandInset citation
LatexCommand cite
key "grippo1986nonmonotone"
literal "false"

\end_inset

 or trust-region strategy 
\begin_inset CommandInset citation
LatexCommand cite
key "conn2000trust,schulman2015trust"
literal "false"

\end_inset

 is typically employed to determine an appropriate step size that keeps linearization error contained and ensures sufficient cost decrease.
 This mechanism guarantees stable convergence when optimization trajectories with learned dynamics.
 The process is repeated until convergence.
\end_layout

\begin_layout Standard
Due to its spatialized agent-based structure,
 kCELL provides naturally the linearized dynamics needed for the local QP.
 As shown in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:kcell-local-linear-model"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 for a input point 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 the local affine model
\begin_inset Formula 
\[
s_{t+1}\approx\underbrace{A\left(x_{t}\right)}_{A_{t}}s_{t}+\underbrace{B\left(x_{t}\right)}_{B_{t}}u_{t}+\underbrace{c\left(x_{t}\right)}_{c_{t}}
\]

\end_inset

provides exactly the matrices needed for the linearized dynamics in the QP.
 This way the approximated QP subproblem is fully compliant with the dynamics initially learned by the model,
 without having to build a proxy through differentiation and Taylor expansion.
 Consequently,
 SQP-based MPC provides a principled and efficient way to exploit kCELL's local structure while being able to enforce hard constraints.
\end_layout

\begin_layout Standard
In this section we discussed about the integration of kCELL into real-time MPC pipelines by exploiting both its computational and structural properties.
 First the differentiable and modular nature of kCELL enables highly parallel trajectory unfolding,
 making population-based optimizer tractable through GPU based implmentations.
 This approach is particularly adapted for large-scale trajectory sampling and global solution exploration.
 Then,
 we showed that kCELL's agent-based structure provides both differentiability and explicit local affine models of the learned dynamicsk for gradientt-based MPC.
 This property naturally allow the use of SQP,
 which exploits local linear models to efficiently enforce hard constraints and produce smooth control trajectories.
 Ultimately,
 we showed that using a kCELL predictive dynamics model,
 both population-based and gradient-based optimization schemes could be leveraged.
\end_layout

\begin_layout Standard
Beyond computational efficiency,
 kCELL exposes introspection signals such as distance-based competence and local model disagreement that quantify the reliability of the predictions along candidate trajectories.
 in the remainder of this chapter,
 we explore the use of these introspection signals to improve control in terms of exploration and exploitation under operational constraints.
\end_layout

\begin_layout Section
Exploration MPC with kCELL
\begin_inset CommandInset label
LatexCommand label
name "sec:Exploration-MPC"

\end_inset


\end_layout

\begin_layout Standard
The integration of kCELL into SQP framework provides a solid and efficient way of exploiting current model knowledge.
 However,
 the performances of any model-based controller is bounded by the quality of the learned dynamics.
 In settings where no prior knowledge of the system is available,
 the controller must balance the minization of the task cost with the need to collect informative data in unknownn or poorly modeled regions of the state-action space.
\end_layout

\begin_layout Standard
Conventional exploration methods typically depend on heuristic noise processes (e.g Ornstein-Uhlenbeck noise 
\begin_inset CommandInset citation
LatexCommand cite
key "uhlenbeck1930theory"
literal "false"

\end_inset

) or on uncertainty-based mechanisms derived from auxiliary models,
 such bayesian posterior variances in Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "srinivas2009gaussian,ruiz2015general"
literal "false"

\end_inset

,
 intrinsic motivation signals in Curiosity-driven exploration 
\begin_inset CommandInset citation
LatexCommand cite
key "pathak2017curiosity"
literal "false"

\end_inset

,
 or novelty scores learned through Random Network Distillation 
\begin_inset CommandInset citation
LatexCommand cite
key "burda2018exploration"
literal "false"

\end_inset

.
 While effective in many situations,
 these approaches quantify uncertainty through probabilistic inference or learned proxies that are determined by model design choices,
 whereas kCELL exposes uncertainty as a structural and geometric property of its spatialized local learning architecture.
\end_layout

\begin_layout Standard
kCELL's spatialized agent-based architecture provides two distinct introspection signals that can be directly embedded into the MPC objective function to drive exploration of unknown states:
 distance-based competence and local model disagreement.
\end_layout

\begin_layout Standard
Distance-based competence quantifies how far a state-action pair lies from regions that are sufficiently covered by agents,
 providing a geometrical grounded measure of feature space epistemic uncertainty.
 Local model disagreement captures variability in the predicted dynamics across neighboring agents,
 yielding a local estimate of predictive uncertainty.
 Because kCELL operates in an online learning regime,
 these introspection quantities evolve through constant interaction with the environment and can be evaluated at every MPC iteration without retraining,
 posterior computations,
 or auxiliary optimization procedures.
\end_layout

\begin_layout Standard
Exploration can therefore be formulated as a deterministic,
 introspection-based regularization of the control objective,
 leading to the following augmented cost function
\begin_inset Formula 
\[
J\left(s_{t},u_{t}\right)=\alpha J_{\text{task}}\left(s_{t},u_{t}\right)+\lambda J_{\text{explore}}\left(s_{t},u_{t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $J_{\text{task}}$
\end_inset

 is the task-related cost function,
 
\begin_inset Formula $J_{\text{explore}}$
\end_inset

 the exploration penalty and 
\begin_inset Formula $\alpha\in\mathbb{R},\,\lambda\in\mathbb{R}$
\end_inset

 the adjustment weights to trade-off task exploitation and exploration.
\end_layout

\begin_layout Subsection
Distance-based Competence
\begin_inset CommandInset label
LatexCommand label
name "subsec:Distance-based-Competence"

\end_inset


\end_layout

\begin_layout Standard
Unlike opaque black-box models,
 kCELL provides an explicit measure of its degree of knowledge about specific regions of the feature space through the spatial distribution of agents.
 To encourage exploration,
 the model must acquire data that lie outside the currently covered regions,
 i.e outside regions that have been sufficiently visited.
 The degree of knowledge associated with a state-action pair can be quantified by evaluating the Mahalanobis distance between the pair and the closest agents.
\end_layout

\begin_layout Standard
The objective is to deliberately drive the state-action trajectories away from the currently covered regions of the feature space to collect informative samples in poorly modeled areas.
 To achieve this,
 we introduce a distance-based penalty term 
\begin_inset Formula $p_{\text{dist}}\left(x_{t}\right)$
\end_inset

 that augments the MPC cost function by promoting exploration of unknown regions such as
\begin_inset Formula 
\begin{eqnarray}
p_{\text{dist}}\left(x_{t}\right) & = & -\sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)\left(\left(x_{t}-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x_{t}-\mu_{i}\right)\right)\\
 & = & -\sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)d\left(\mathcal{A}_{i},x_{t}\right)^{2}
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 
\begin_inset Formula $D_{\text{closest}}$
\end_inset

is the set of the 
\begin_inset Formula $k$
\end_inset

-closest agents,
 
\begin_inset Formula $\mu_{i}$
\end_inset

 and 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 are the parameters of their activation function,
 
\begin_inset Formula $w_{i}\left(x_{t}\right)=\frac{\phi_{i}\left(x_{t}\right)}{\sum_{j}\phi_{j}\left(x_{t}\right)}$
\end_inset

 are the weights depending on the activation of each agent on 
\begin_inset Formula $x_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
Because the penalty is negative,
 minimizing the augmented MPC objective encourages trajectories that maximize the distance to the currently well-covered regions.
 in this context,
 
\begin_inset Formula $p_{\text{dist}}\ll0$
\end_inset

 means that 
\begin_inset Formula $x_{t}$
\end_inset

 is currently not supported by the agents' training data.
 Conversely,
 
\begin_inset Formula $p_{\text{dist}}\approx0$
\end_inset

 indicates that 
\begin_inset Formula $x_{t}$
\end_inset

 is close to a well-covered (known) region of feature space and is therefore likely to be already included in the current knowledge base.
\end_layout

\begin_layout Subsection
Local Disagreement
\begin_inset CommandInset label
LatexCommand label
name "subsec:Local-Disagreement"

\end_inset


\end_layout

\begin_layout Standard
In regions where multiple agents are close in feature space,
 the variance between their individual predictions serves as a proxy for local predictive inconsistency.
 High disagreement suggests that the local dynamics are either stochastic,
 noisy or that the model has not yet converged to a stable local representation.
\end_layout

\begin_layout Standard
The objective is to drive the state-action trajectories towards regions exhibiting high predictive disagreement to force the model to discover new areas or to converge in already known region of feature space.
 This mechanism is functionally analogous to uncertainty-driven exploration strategies proposed in 
\begin_inset CommandInset citation
LatexCommand cite
key "srinivas2009gaussian,ruiz2015general,pathak2017curiosity,burda2018exploration"
literal "false"

\end_inset

 while remaining fully intrinsic to the kCELL architecture.
\end_layout

\begin_layout Standard
To achieve this,
 we introduce a disagreement-based penalty term 
\begin_inset Formula $p_{\text{disagree}}\left(x_{t}\right)$
\end_inset

 that augments the MPC cost function by promoting exploration of highly uncertain regions of feature space,
 such as
\begin_inset Formula 
\begin{eqnarray}
p_{\text{disagree}}\left(x_{t}\right) & = & -\sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)\left\Vert f\left(x_{t}\right)-f_{i}\left(x_{t}\right)\right\Vert ^{2}
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 
\begin_inset Formula $D_{\text{closest}}$
\end_inset

is the set of the 
\begin_inset Formula $k$
\end_inset

-closest agents,
 
\begin_inset Formula $f\left(x_{t}\right)$
\end_inset

 is the global prediction of the system obtained by aggregating the predictions of the closest agents,
 
\begin_inset Formula $f_{i}\left(x_{t}\right)$
\end_inset

 is the prediction of the 
\begin_inset Formula $i$
\end_inset

-th agent,
 
\begin_inset Formula $w_{i}\left(x_{t}\right)=\frac{\phi_{i}\left(x_{t}\right)}{\sum_{j}\phi_{j}\left(x_{t}\right)}$
\end_inset

 are the weights depending on the activation of each agent on 
\begin_inset Formula $x_{t}$
\end_inset

.
\end_layout

\begin_layout Subsection
Comparative Study
\begin_inset CommandInset label
LatexCommand label
name "subsec:Exploration-Comparative-Study"

\end_inset


\end_layout

\begin_layout Standard
This section evaluates the effectiveness of the proposed introspection-driven exploration strategies based on distance-based competence and local model disagreement.
 The objective is to assess whether embedding these signals into the MPC objective leads to improved coverage of feature space in an online learning setup,
 compared to random uninform or purely exploitative exploration strategies.
\end_layout

\begin_layout Subsubsection
Experimental Protocol
\end_layout

\begin_layout Standard
This experiment is conducted on the classical Pendulum control task available in gymnasium reinforcement learning library 
\begin_inset CommandInset citation
LatexCommand cite
key "towers2024gymnasium"
literal "false"

\end_inset

,
 which exhibits nonlinear dynamics and presents a nontrivial exploration challenge.
\end_layout

\begin_layout Standard
States are composed of the 
\begin_inset Formula $x,y$
\end_inset

 2D-coordinates of the tip of the pendulum and of 
\begin_inset Formula $\dot{\theta}$
\end_inset

 the angular velocity.
 For convenience reasons,
 in subsequent figures,
 states are also represented by 
\begin_inset Formula $\theta$
\end_inset

,
 the angle and 
\begin_inset Formula $\dot{\theta}$
\end_inset

 to allow for 2D representations.
\end_layout

\begin_layout Standard
The pendulum is initialized at the bottom equilibrium with zero angular velocity (
\begin_inset Formula $\left\{ \theta=\pi,\,\dot{\theta}=0\right\} $
\end_inset

) at the beginning of each episode.
 No initial state randomization is applied.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Insert graph presenting the pendulum with polar coordinates and xy coordinates
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This way,
 high energy states are harder to reach,
 making the exploration harder for uninformed random strategies.
 The cost function to minimize to solve the task is the following
\begin_inset Formula 
\begin{equation}
\min_{u_{0:T}}\sum_{t=0}^{T}\left(\left(s_{t}-s_{\text{ref}}\right)^{\top}Q\left(s_{t}-s_{\text{ref}}\right)+u_{t}^{\top}Ru_{t}\right)+\left(\left(s_{T+1}-s_{\text{ref}}\right)^{\top}Q\left(s_{T+1}-s_{\text{ref}}\right)\right)
\end{equation}

\end_inset

with 
\begin_inset Formula $Q\in\mathbb{R}^{3\times3}$
\end_inset

,
 
\begin_inset Formula $R\in\mathbb{R}^{1\times1}$
\end_inset

 and 
\begin_inset Formula $s_{\text{ref}}$
\end_inset

 the target state to reach for the pendulum which usually is the top neutral position.
\end_layout

\begin_layout Standard
The agent interacts with the environment for a total of 5000 time steps,
 divided into episodes of 500 steps.
 During interaction,
 a kCELL model is learned online from streaming data to predict the next state.
\end_layout

\begin_layout Standard
Trajectory optimization is performed using the Cross-Entropy Method (CEM) because this approach is stochastic.
 Using a population-based optimizer naturally introduces variability in candidate action sequecnes.
 This stochasticity is important in the early learning phase of kCELL,
 as it avoids situations where newly created agents would be initialized with near-zero action variance,
 which can greatly hurt local model learning.
\end_layout

\begin_layout Standard
Four exploration strategies are evaluated:
\end_layout

\begin_layout Enumerate
Distance intrinsic exploration,
 where the cost function to minimize is the distance-based competence penalty introduced in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Distance-based-Competence"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
Disagreement intrinsic exploration,
 where the cost function to minimize is the disagreement-based penalty introduced in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Local-Disagreement"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
Pure exploitation,
 where only the original task cost is minimized without any exploration regularization.
\end_layout

\begin_layout Enumerate
Uniform random exploration,
 where actions are sampled uniformly at random within admissible bounds.
\end_layout

\begin_layout Standard
For all exploration strategies,
 the same kCELL architecture,
 with same hyperparameters and interaction budget is learned.
 The metrics measured in subsequent sections are averaged over 5 seeds to eliminate part of the stochastic bias induced by using stochastic optimizer and random exploration strategies.
 All strategies share identical model architecture,
 hyperparameters and interaction budget ensuring that observed differences arise solely from the exploration strategy.
\end_layout

\begin_layout Subsubsection
Quantitative State-Space Coverage
\end_layout

\begin_layout Standard
To quantify the state exploration performance,
 the continuous state space is discretized into a regular grid of bins (50 bins per dimension).
 Each visited state is mapped to its corresponding bin,
 which is then marked as visited.
 State-space coverage is then defined as the ratio of visited bins to the total number of bins.
 The final coverage ratios are (averaged over 5 seeds),
 are reported in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Space-Coverage"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{0.95
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disagreement (ours)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Distance (ours)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Uniform
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Full Exploitation
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Coverage (in %)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\begin_inset Formula $\mathbf{82.7\pm4}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\begin_inset Formula $\mathbf{80.8\pm4}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $62.4\pm11$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10.5\pm5$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Measured state space coverage ratio (in %) after 5000 exploration steps.
 Best scores are highlighted in bold.
 
\begin_inset CommandInset label
LatexCommand label
name "tab:Space-Coverage"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{0.95
\backslash
columnwidth}{!}{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disagreement (ours)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Distance (ours)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Uniform
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Full Exploitation
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Coverage (in %)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\begin_inset Formula $\mathbf{58.6\pm5}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\begin_inset Formula $\mathbf{57.9\pm3}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $49.2\pm6$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $8\pm4$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Measured state space coverage ratio (in %) after 2000 exploration steps.
 Best scores are highlighted in bold.
 
\begin_inset CommandInset label
LatexCommand label
name "tab:Space-Coverage"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The results show that both introspection-driven strategies (distance-based competence and local disagreement) achieve significantly higher state-space coverage than the uninformed random uniform strategy under the same interaction budget:
 
\begin_inset Formula $\approx10\%$
\end_inset

 higher ratio for introspection-based strategies.
 Conversely,
 with pure exploitation strategy,
 where the controller optimizes only the task cost without any exploration regularization,
 results in the lowest coverage.
 This indicates that in the absence of prior knowledge of the dynamics,
 exploitation (i.e optimizing the task objective) alone is insufficient to drive the system toward diverse and informative regions of the state space.
\end_layout

\begin_layout Standard
Furthermore,
 The distance-based and disagreement-based strategies achieve comparable final coverage levels,
 indicating that both introspection signals are effective at promoting exploration beyond the regions initially supported by the data.
\end_layout

\begin_layout Subsubsection
Evolution of Coverage during Exploration
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-the-coverage"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolution of state-space coverage over time averaged over 5 seeds.
 The two introspection-driven strategies consistently dominate the random uniform baseline.
 Pure exploitation seems to remain confined to a narrow subset of states and fails to significantly increase coverage.
\end_layout

\begin_layout Standard
Both introspection-driven strategies show comparable growth in coverage over time.
 Minor differences in variability across seeds are observed but the mean coverage remains similar.
 This suggests that both strategies effectively promote exploration.
 Any apparent differences should be interpreted cautiously as they may not be statistically significant.
\end_layout

\begin_layout Standard
Overall,
 these results confirm that embedding introspection signals directly into the MPC objective yields an exploration advantage over uninformed stochastic action sampling.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/coverage_evolution_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Evolution of the measured state space coverage ratio during exploration phase.
 
\emph on
x
\emph default
-axis corresponds to the number of steps and 
\emph on
y
\emph default
-axis corresponds to the measured state space coverage ratio.
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-the-coverage"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Spatial Distribution of Visited States
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Obtained-space-coverage"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents heatmaps of visited states in the (
\begin_inset Formula $\theta,\,\dot{\theta}$
\end_inset

) space after the exploration phase.
 For all strategies,
 states corresponding to low angular velocities and angles that are close to the starting configuration (
\begin_inset Formula $\theta\approx\pi$
\end_inset

) are visited more frequently,
 reflecting the energy barrier associated with reaching high energy states associated with throwing the pendulum tip all the way to the top.
\end_layout

\begin_layout Standard
Clear differences emerge between strategies.
 Both distance-based and disagreement-based explorations achieve substantially broader coverage,
 with frequent visits to high-energy states corresponding to near-upright pendulum configurations (
\begin_inset Formula $\theta\approx0$
\end_inset

 or 
\begin_inset Formula $2\pi$
\end_inset

) and large angular velocities.
 In contrast,
 the random uniform strategy exhibits sparse and uneven coverage,
 with large regions remaining unvisited (especially in high energy regions).
 Pure exploitation remains almost entirely confined near the starting state.
 It consistently fails to overcome the energy barrier required to explore the upper half of the state space.
\end_layout

\begin_layout Standard
These observations highlight the limitations of uninformed random exploration in structured dynamical systems and demonstrate that introspection driven objectives allow the controller to deliberately seek out to reach informative regions of that are otherwise difficult to reach.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/coverage_heatmap_2x2_notitle_5k.png
	lyxscale 15
	width 95col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Obtained space coverage for the exploration strategies considered.
 
\emph on
Top-left
\emph default
 corresponds to Disagreement strategy;
 
\emph on
Top-right
\emph default
 corresponds to Distance strategy,
 
\emph on
Bottom-left
\emph default
 corresponds to Random Uniform strategy;
 and 
\emph on
Bottom-right
\emph default
 corresponds to Full Exploitation strategy.
 The more yellow,
 the more the cell has been visited across the different seeds,
 conversely for blue colored cells.
 
\emph on
y
\emph default
-axis corresponds to the angle and 
\emph on
x
\emph default
-axis corresponds to angular velocity.
\begin_inset CommandInset label
LatexCommand label
name "fig:Obtained-space-coverage"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Activation Patterns and Local Geometry
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation Patterns"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 illustrates the spatial organization of kCELL agents after the exploration phase.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-XY-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows agent activations projected onto the Cartesian coordinates of the pendulum tip.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 displays activations in the (
\begin_inset Formula $\theta,\,\dot{\theta}$
\end_inset

) space.
\end_layout

\begin_layout Standard
For the distance-based and disagreement-based strategises,
 agent activations cover the entire circular manifold corresponding to the pendulum's reachable positions,
 indicating that even high-energy and rarely visited states are locally modeled by dedicated agents.
 In contrast,
 with the random uniform and pure exploitation strategies,
 agent activations are concentrated in the lower-energy regions of the state space.
\end_layout

\begin_layout Standard
A broader diversity in agent sizes can be observed for the introspection-driven strategies.
 This is most likely due to kCELL agent creation mechanism,
 which creates agents from a minimum number of samples to ensure thet local models are quickly reliable.
 In high-velocity regimes or during abrupt torque changes such as strong braking events,
 state transitions are more widely distributed,
 leading to larger initial covariance estimates.
 These larger agents are not pathological artifacts but instead reflect an specific experience of data,
 here corresponding to regions of high local variability.
\end_layout

\begin_layout Standard
For example,
 in the (
\begin_inset Formula $\theta,\,\dot{\theta}$
\end_inset

) projection,
 some agents appear elongated along one dimension especially for the Distance-based strategy.
 Analysis of their covariance matrices reveals that these agents correspond to sharp directional changes in the dynamics,
 typically induced by large control intpus applied against the direction of motion.
 As such,
 agent geometry seems to provide an interpretable signature of local dynamical regimes encountered during exploration.
 The Distance-based strategy seeming to have more of these king of agents could be due to a more agressive exploration strategy that prioritizes more extreme action variations.
\end_layout

\begin_layout Standard
These activation patterns demonstrate that kCELL does not cover the state space uniformly but organizes local models in a manner that reflects the underlying geometry and variability of the dynamics encountered during exploration.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/activation_patterns_xy_notitle_5k.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Activation-Patterns-XY-Pendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/activation_patterns_angle_angular_velocity_5k_notitle.png
	lyxscale 30
	width 45col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Activation Patterns"

\end_inset

 Visualization of the activation patterns of agents for all considered strategies.
 Starting from the top,
 
\begin_inset Formula $1^{st}$
\end_inset

 plot corresponds to the Disagreement strategy;
 
\begin_inset Formula $2^{nd}$
\end_inset

 plot corresponds to the Distance strategy,
 
\begin_inset Formula $3^{rd}$
\end_inset

 plot corresponds to the Random Uniform Strategy and finally 
\begin_inset Formula $4^{th}$
\end_inset

 plot corresponds to the Full Exploitation strategy.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-XY-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the activation patterns of agents projected in the space of 2D coordinates of the tip of the pendulum (
\begin_inset Formula $x=\cos\left(\theta\right)$
\end_inset

 and 
\begin_inset Formula $y=\sin\left(\theta\right)$
\end_inset

).
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the activation patterns of agents projected in the space of Angle (
\emph on
y
\emph default
-axis) and Angular Velocity (
\emph on
x
\emph default
-axis).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Agent Population Dynamics
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Evolution-of-agent-population-pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolutions of the number of agents during exploration.
 Both introspection-driven strategies lead to a substantially larger number of agents than the random uniform and pure exploration baselines.
 This increase is positively correlated with the observed improvement in state-space coverage.
\end_layout

\begin_layout Standard
While both introspection-driven strategies generate more agents overall,
 the disagreement-based strategy exhibits higher variability in agent population across the 5 considered seeds,
 which is consistent with the higher sensitivity of disagreement to local modeling inconsistencies.
 The more the space is covered,
 the more the local models can conflict locally and drive exploration to them for consolidation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/nb_agents_evolution_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Evolution-of-agent-population-pendulum"

\end_inset

Evolution of agent population for the four considered strategies average over 5 seeds.
 
\emph on
y
\emph default
-axis corresponds to the number of agents and 
\emph on
x
\emph default
-axis corresponds to the number of exploration steps.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Prediction Accuracy and Sample Efficiency
\end_layout

\begin_layout Standard
To assess whether introspection-driven exploration strategies translate into better models,
 we evaluate the predictive accuracy of kCELL after the exploration phase.
 For each exploration strategy,
 the learned model is evaluated on an exhaustive test set crafted specifically to cover a large portion of the state-action space.
 Model performance is quantified using the root mean squared error (RMSE) between predicted and ground-truth next states.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RMSE-after-exploration"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 presents a bar plot that reports the average RMSE across five seeds for the four exploration strategies.
\end_layout

\begin_layout Standard
Both introspection-driven strategies achieve substantially lower prediction error than the random uniform and pure exploitation baselines.
 In contrast,
 no statistically significant difference in RMSE is observed between the distance-based and disagreement-based strategies.
\end_layout

\begin_layout Standard
These results indicate that introspection-driven exploration improves the sample efficiency of online model learning in kCELL.
 While the two introspection signals lead to slightly different exploration dynamics,
 they results in comparable models in terms of predictive quality under the same interaction budget.
 This suggests that the shallow performance differences observed in state-space coverage are not likely associated with systematic differences in model accuracy under the considered interaction budget and evaluation protocol.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/RMSE_bar_no_title_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RMSE-after-exploration"

\end_inset

RMSE averaged over 5 seeds.
 
\emph on
y
\emph default
-axis is the RMSE and 
\emph on
x
\emph default
-axis ticks corresponds to the corresponding exploration strategy.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Global Action Distribution
\end_layout

\begin_layout Standard
Although distance-based and disagreement-based strategies yield comparable coverage and predictive accuracy,
 minor differences in exploration dynamics were observed in coverage variability and in agent population statistics across seeds.
 Those variations are subtle and may reflect stochastic effects of the optimizer rather than systematic differences.
 To investigate the general behavior of the controller under introspection-driven exploration objectives,
 we analyzed the distribution of actions taken during exploration.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Actions-KDE-after-exploration"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents kernel density estimates of the applied control inputs.
\end_layout

\begin_layout Standard
The resulting action distributions are very similar for both introspection-driven strategies.
 Three dominant modes can be observed centered around saturated control actions (-2,
 2) and near-zero actions.
 This multimodal structure contrasts with the random uniform baseline.
 It indicates that both introspection-driven strategies induce structured non-uniform action profiles.
 The presence of repeated extreme actions suggests that introspection-driven objectives actively promote saturated actions in order to reach higher energy states rather than relying on diffuse stochastic perturbations.
\end_layout

\begin_layout Standard
These results suggest that the observed similarities in coverage and model accuracy are more likely attributable to how these signals interact with local geometry and agent creation rather than fundamentally different global action sampling behaviors.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/exploration/actions_KDE_5k.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Actions-KDE-after-exploration"

\end_inset

KDE density over actions taken during exploration for each considered exploration strategy.
 
\emph on
y
\emph default
-axis is the KDE density and 
\emph on
x
\emph default
-axis ticks corresponds to the actions (in pendulum it corresponds to the applied torque).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Discussion
\end_layout

\begin_layout Standard
The experimental results presented in this section demonstrate that introspection-driven exploration strategies based on kCELL online modeling improve exploration efficiency in model-based control settings without prior knowledge of the system dynamics.
 By embedding distance-based competence and local model disagreement directly into the MPC objective,
 the controller is able to consistently escape well-modeled regions and acquire informative data in unknown regions of the state-action space.
\end_layout

\begin_layout Standard
Coverage metrics and spatial visualizations show that both introspection-driven strategies lead to a better coverage than uninformed random uniform exploration and pure exploitation.
 Introspection-driven strategies are able to overcome the energy barrier induced by the pendulum environment.
 High energy configurations are repeatedly visited despite being hard to reach for uninformed strategies.
 These results confirm that effective exploration cannot be achieved through randomly uniform actions alone,
 but instead requires additional motivations like model knowledge or uncertainty.
\end_layout

\begin_layout Standard
The analysis of global action distributions confirms that both introspection-driven strategies induce structured multimodal action profiles that facilitate exploration of high-energy states.
 The similarities observed in these distributions suggest that the two strategies behave comparably interms of global action patterns.
 Differences in coverage or agent population arise primarily from interactions with local agent geometry rather than fundamentally different action sampling.
\end_layout

\begin_layout Standard
At the agent level,
 activation patterns and population dynamics provide insights into the underlying mechanisms of introspection-driven exploration strategies.
 Increased agent creation correlates strongly with improved coverage.
 This indicates that exploration emerges from the interaction between the introspection objective and kCELL's agent creation process.
 Furthermore,
 agent geometry and size variability reflect local properties of the dynamics.
 For example,
 for high-velocity regimes,
 created agents tend to be larger or for sharp directional changes,
 agents displays a high variance on the action dimension.
 Each agent represents a singular experience of data.
 This highlights one of the key advantage of kCELL,
 which is its interpretability.
 Indeed,
 uncertainty and model structure are not hidden within opaque parameters but instead manifest explicitly through the spatial organization of agents.
\end_layout

\begin_layout Standard
Finally,
 the observed improvements in predictive accuracy confirm that introspection-driven exploration translates into concrete benefits for online model learning.
 Under a fixed interaction budget,
 broader and more structured exploration leads to more accurate learning dynamics.
 It reinforces the link between exploration strategy,
 model quality and downstream control performance.
\end_layout

\begin_layout Standard
Overall,
 kCELL's architecture allows to extract introspection signals that can be leveraged successfully to build efficient uncertainty-aware exploration mechanisms without prior knowledge about the dynamics of the environment.
 Those mechanisms do not rely on external stochastic processes or auxiliary uncertainty models.
\end_layout

\begin_layout Subsubsection
Limitations
\end_layout

\begin_layout Standard
While the results demonstrate the effectiveness of introspection-driven exploration with kCELL,
 several limitations still stand and need to be acknowledged.
\end_layout

\begin_layout Standard
kCELL was introduced to address the overoptimistic spatial representations of oCELL (cf.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) that originated from the use of orthotope based spatialization.
 While allowing more degrees of freedom and a better representative power,
 using Gaussian-based spatialization introduces its own set of constraints.
 Agents are spatialized using RBF kernels parameterized by the mean and covariance estimated from local ingested data.
 As a result,
 agent creation requires a minimum diversity level to avoid ill-conditioned covariance estimates.
 In practice,
 this makes early exploration phases or low-variability action regimes potentially problematic.
 On the other hand,
 while population-based optimizers such as CEM introduce stochasticity that partially mitigates this issue by inducing action variability,
 excessive dispersion of actions can lead to overly extended agents and interpolation errors.
 This effect can be observed in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Activation-Patterns-AngleAngularVelocity-Pendulum"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 through some agents that appear elongated (especially for distance-based strategy) due to too spread out actions.
 These agents still represent valid local experiences but such behavior may pose challenges when extending the approach to more complex control environments.
\end_layout

\begin_layout Standard
The Gaussian assumption underlying agent spatialization restricts the ability of kCELL to faithfully represent complex or multimodal feature manifolds that cannot be represented by a single Gaussian kernel.
 The agent population can approximate such structures through multiple overlapping agents,
 but this approximation remains indirect.
 Extending the spatialization mechanism beyond Gaussian assumptions,
 for example by using kernel density estimates or mixture-based representations,
 could allow kCELL to better capture complex feature geometries.
\end_layout

\begin_layout Standard
The experimental evaluation is restricted to a low-dimensional control problem (3 state dimensions and 1 action dimension).
 The pendulum environment captures nontrivial exploration challenges such as energy barriers.
 However,
 scalability to higher-dimensional systems remains an open question for kCELL.
 In such settings,
 agent management,
 coverage estimation and computational overhead may require additional mechanisms such as dimensionality reduction (which we explore in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
Finally,
 this study considers distance-based competence and local disagreement as independent exploration objectives.
 A combined approach was not explored,
 primarily because thses introspection signals operate on very different scales and have distinct geometrical interpretations.
 Investigating principled combinations or adaptive weighting schemes between distance-based and disagreement-based objectives could reveal complementary effects and lead to more exhaustive exploration strategies.
\end_layout

\begin_layout Standard
Beyond exploration,
 introspection signals extracted from kCELL naturally lead to the design of conservative control strategies under learned dynamics.
 While exploring exploits these signals to deliberately seek poorly modeled regions,
 the same quantities can be repurposed during exploitation to bias the controller toward states where the model is locally reliable.
 In this setting,
 introspection costs no longer acts as penalties but as a confidence-aware bonuses that encourage trajectoires to remain close to existing agents,
 i.e close to the current knwoledge of the model.
\end_layout

\begin_layout Section
Conservative MPC with kCELL
\begin_inset CommandInset label
LatexCommand label
name "sec:Conservative-MPC"

\end_inset


\end_layout

\begin_layout Standard
Exploration strategies relying on kCELL intrinsic multiagent structure have shown successful to drive exploration in an unknown environment,
 leading to better predictive learned dynamic models than when exploring with uninformed random strategies.
\end_layout

\begin_layout Standard
To achieve safe control with learned models,
 i.e reliability of controllers,
 the problem of compounding errors and uncertainty in the model predictions needs to be addressed at exploitation time 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

.
 With inexact dynamic models,
 small errors on the first horizon steps leads to massive errors over time.
 Compounding errors are deeply linked to epistemic uncertainty (lack of knowledge about the underlying true dynamics).
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

,
 the authors discuss using Gaussian Processes (GPs) 
\begin_inset CommandInset citation
LatexCommand cite
key "williams1995gaussian"
literal "false"

\end_inset

 or Bayesian Neural Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "blundell2015weight"
literal "false"

\end_inset

 to quantify the prediction uncertainty and take it into account in optimization to obtain safe conservative control policies.
\end_layout

\begin_layout Standard
kCELL's spatialized agent-based architecture provides valuable introspection signals that can serve as proxies for epistemic uncertainty.
 Those introspection signals can be directly embedded into the MPC objective to regularize the behavior of the resulting policy by keeping the explored states at optimization time into the knowledge landscape of the model,
 avoiding wandering into unknown states that would induce large error compounding effects.
\end_layout

\begin_layout Standard
In this chapter we focus specifically on distance-based competence introspection signals that quantify how far a state lies from regions that are sufficiently covered by agents.
 It provides a geometrically grounded measure of epistemic uncertainty.
\end_layout

\begin_layout Standard
To bias the policy toward a more conservative knowledge-aware regime,
 an introspection-based regularization of the control objective is defined,
 leading to the following augmented cost function
\begin_inset Formula 
\[
J\left(s_{t},u_{t}\right)=\alpha J_{\text{task}}\left(s_{t},u_{t}\right)+\lambda J_{\text{conservative}}\left(s_{t},u_{t}\right)
\]

\end_inset

where 
\begin_inset Formula $J_{\text{task}}$
\end_inset

 is the task-related cost function,
 
\begin_inset Formula $J_{\text{conservative}}$
\end_inset

 the conservative regularization term and 
\begin_inset Formula $\alpha\in\mathbb{R},\,\lambda\in\mathbb{R}$
\end_inset

 the adjustment weights to trade-off task exploitation and conservatism.
 In this context we define a conservative policy,
 as a policy that is biased toward minimizing epistemic uncertainty.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Mention the fact that in results,
 we observe that getting closer to the knowledge base of the model = less compounding errors => solid argument in favor of the local expertise hypothesis.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Define reliability
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
We use regularization to increase the confidence we can have in the model at optimization time => this is required for safety / reliability of the controller (cf.
 paper Safe Control Review) => we advance toward safety
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Distance-based Conservatism
\begin_inset CommandInset label
LatexCommand label
name "subsec:Distance-based-Conservatism"

\end_inset


\end_layout

\begin_layout Standard
Unlike opaque black-box models,
 kCELL provides an explicit measure of its degree of knowledge about specific regions of the feature space through the spatial distribution of agents.
 To encourage conservatism,
 the controller must keep evaluated solutions and state trajectories close to the covered regions of the feature space.
 In kCELL,
 the degree of knowledge associated with an input 
\begin_inset Formula $x_{t}$
\end_inset

 can be quantified by evaluating the Mahalanobis distance between 
\begin_inset Formula $x_{t}$
\end_inset

 and the closest agents.
\end_layout

\begin_layout Standard
In kCELL one of the structural hypothesis is that agents are local experts on the function to approximate and that the closer an input is to the center of an agent,
 the most probable the prediction will be accurate.
 Thus,
 the objective is to deliberately drive the trajectories close to the currently covered regions,
 that is to say,
 closer to the center of agents.
\end_layout

\begin_layout Standard
To achieve this,
 we introduce a distance-based regularization term 
\begin_inset Formula $q_{\text{dist}}\left(x_{t}\right)$
\end_inset

 that augments the MPC cost function by promoting conservative behaviors such as
\begin_inset Formula 
\begin{eqnarray}
q_{\text{dist}}\left(x_{t}\right) & = & \sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)\left(\left(x_{t}-\mu_{i}\right)^{\top}\Sigma_{i}^{-1}\left(x_{t}-\mu_{i}\right)\right)\\
 & = & \sum_{i\in D_{\text{closest}}}w_{i}\left(x_{t}\right)d\left(\mathcal{A}_{i},x_{t}\right)^{2}
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $x_{t}=\left[s_{t},u_{t}\right]$
\end_inset

,
 
\begin_inset Formula $D_{\text{closest}}$
\end_inset

is the set of the 
\begin_inset Formula $k$
\end_inset

-closest agents,
 
\begin_inset Formula $\mu_{i}$
\end_inset

 and 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 are the parameters of their activation function,
 
\begin_inset Formula $w_{i}\left(x_{t}\right)=\frac{\phi_{i}\left(x_{t}\right)}{\sum_{j}\phi_{j}\left(x_{t}\right)}$
\end_inset

 are the weights depending on the activation of each agent on 
\begin_inset Formula $x_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
Because the penalty is positive,
 minimizing the augmented MPC objective encourages trajectories that minimize the distance to the currently well-covered regions (in constrast to what is done for exploration in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Distance-based-Competence"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 in this context,
 
\begin_inset Formula $q_{\text{dist}}\gg0$
\end_inset

 means that 
\begin_inset Formula $x_{t}$
\end_inset

 is currently not supported by the agents' training data.
 Conversely,
 
\begin_inset Formula $q_{\text{dist}}\approx0$
\end_inset

 indicates that 
\begin_inset Formula $x_{t}$
\end_inset

 is close to a well-covered (known) region of feature space and is therefore likely to have been encountered during training.
 As 
\begin_inset Formula $q_{\text{dist}}$
\end_inset

 is convex,
 it can easily be embedded for optimization with fast conic solvers like OSQP 
\begin_inset CommandInset citation
LatexCommand cite
key "stellato2020osqp"
literal "false"

\end_inset

 within the context of Sequential Quadratic Programming (SQP) optimization framework.
\end_layout

\begin_layout Subsection
Comparative Study
\end_layout

\begin_layout Standard
This section evaluates the effectiveness of the proposed introspection-driven regularization term based on distance to agents in a learned kCELL system through a low-dimensional experiment.
 The objective is to assess whether embedding this regularization term into the MPC objective yields better known trajectories,
 less compounding errors and if there is a tradeoff between conservativeness and task resolution performance.
\end_layout

\begin_layout Subsubsection
Experimental Protocol
\end_layout

\begin_layout Standard
This experiment evaluates the impact of introspection-driven conservative regularization on the reliability of trajectory optimization using a kCELL learned dynamics model within a MPC scheme.
 The objective is to assess whether considering the spatialization of agents of a kCELL model during optimization reduces extrapolation errors and improves robustness of long-horizon predictions.
\end_layout

\begin_layout Standard
The experiment is conducted on the classical Pendulum control task available in gymnasium reinforcement learning library 
\begin_inset CommandInset citation
LatexCommand cite
key "towers2024gymnasium"
literal "false"

\end_inset

 which exhibits nonlinear dynamics.
 States are composed of the 
\begin_inset Formula $x,\,y$
\end_inset

 2D-coordinates of the tip of the pendulum and of 
\begin_inset Formula $\dot{\theta}$
\end_inset

 the angular velocity.
\end_layout

\begin_layout Standard
A kCELL model is learned online from streaming interaction data.
 The population of linear agent predictors is spatialized in the state space (not including actions).
 This design choice is motivated by empirical observations on the pendulum task.
 Indeed,
 spatializing agents jointly over state and action dimensions leads to slower stabilization of agent population,
 whereas state-only spatialization resulted in faster convergence of local models and more stable agent coverage.
 Given the low-dimensional action space and the smooth dynamics,
 state-based spatialization provides a favorable tradeoff between model predictive accuracy and sample efficiency.
\end_layout

\begin_layout Standard
To ensure a sufficient coverage of the state space,
 an informed finetuned stochastic exploration policy based on Ornstein-Uhlenbeck (OU) noise is used to interact with the simulation environment to collect learning data.
 This exploration phase to build a kCELL model is conducted for a fixed interaction budget of 30k steps.
 The learned dynamics model is frozen and used subsequently for evaluation.
 No further learning occurs during evaluation,
 ensuring that observed effects are attributable to the optimization strategy rather than continued model adaptation.
\end_layout

\begin_layout Standard
Control actions are obtained using a MPC scheme.
 Action sequences are optimized over a finite horizon using the learned kCELL dynamics.
 Trajectory optimization is performed using SQP with OSQP conic solver to solve the local Quadratic Programs at each iteration.
 Using SQP,
 a gradient-based optimizer,
 allows to isolate the effect of the proposed regularization without introducing stochastic variability which is inherent to population-based optimization methods.
\end_layout

\begin_layout Standard
The baseline optimization objective,
 i.e the cost function to minimize to solve the task is the following
\begin_inset Formula 
\begin{equation}
\min_{u_{0:T}}\sum_{t=0}^{T}\left(\left(s_{t}-s_{\text{ref}}\right)^{\top}Q\left(s_{t}-s_{\text{ref}}\right)+u_{t}^{\top}Ru_{t}\right)+\left(\left(s_{T+1}-s_{\text{ref}}\right)^{\top}Q\left(s_{T+1}-s_{\text{ref}}\right)\right)
\end{equation}

\end_inset

with 
\begin_inset Formula $Q\in\mathbb{R}^{3\times3}$
\end_inset

,
 
\begin_inset Formula $R\in\mathbb{R}^{1\times1}$
\end_inset

 and 
\begin_inset Formula $s_{\text{ref}}$
\end_inset

 the target state to reach for the pendulum which usually is the top neutral position.
\end_layout

\begin_layout Standard
To this objective,
 an additional conservative regularization term 
\begin_inset Formula $q_{\text{dist}}$
\end_inset

 is introduced (cf.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Distance-based-Conservatism"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 This regularization term is weighted by a coefficient 
\begin_inset Formula $\lambda\geq0$
\end_inset

,
 penalizing predicted trajectories that run accross low coverage regions of the state space,
 envouraging solutions that remain within areas well covered by the agent.
 The goal is to stay close to what the model knows.
\end_layout

\begin_layout Standard
The evaluation is conducted for multiple values of 
\begin_inset Formula $\lambda$
\end_inset

.
 We refer to the unregularized case 
\begin_inset Formula $\lambda=0$
\end_inset

 as the baseline.
 To evaluate robustness and reliability independently of exploration stochasticity,
 control performance is assessed from an exhaustive set of initial states sampled over a grid in the state space.
 For each initial state,
 the predictions produced by kCELL with the found solution are compared against the ground-truth trajectory.
 This allows direct measurement of prediction error against the true dynamics,
 also allowing to assess the compounding effects on a given horizon.
 All evaluations are performed using identical MPC horizons (
\begin_inset Formula $T=20$
\end_inset

),
 cost function,
 solver parameters and constraints across regularization settings.
\end_layout

\begin_layout Subsubsection
Validation of Regularization Behavior
\end_layout

\begin_layout Standard
To validate the behavior of the regularization term,
 we measure the mean agent activation along optimized trajectories.
 Activation of agents serves as a proxy for epistemic uncertainty by measuring the distance to the closest experts in state space.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Boxplot-Mean-Activation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents boxplots of the mean agent activation for each considered values of 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Standard
As 
\begin_inset Formula $\lambda$
\end_inset

 increases,
 we observe a clear increase in mean agent activation indicating that the optimizer progressively favors trajectories that remain closer to the centers of kCELL agents,
 i.e within regions that are well supported by training data.
 This behavior is consistent with the expected behavior of the regularization term 
\begin_inset Formula $q_{\text{dist}}$
\end_inset

.
 The optimization landscape is effectively reshaped.
\end_layout

\begin_layout Standard
In addition to that,
 increasing 
\begin_inset Formula $\lambda$
\end_inset

 also yields a noticeable reduction in the spread of the activation distributions across initial conditions.
 This reduced variability indicates that under stronger regularization trajectories initialized in different regions are increasingly constrained to remain within similarly well-supported regions.
 This effect suggests that the regularization not only increases overall conservatism but also homogenizes the level of model support encountered along optimized trajectories.
\end_layout

\begin_layout Standard
These results validate the behavior of the introspection-driven regularization mechanism.
 The regularizer acts as intended by increasing the proximity of optimized trajectories to kCELL agent centers and reduces variability in model competence across initial conditions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/boxplot_mean_activation_vs_reg_coeff.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Boxplot-Mean-Activation"

\end_inset

 Boxplots of the mean activation over optimized trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the mean activation over optimized trajectories and 
\emph on
x
\emph default
-axis corresponsd to values of 
\begin_inset Formula $\lambda$
\end_inset

.
 The blue curve corresponds to the global mean and the orange bars correspond to the median value.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Impact on Prediction Accuracy
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Boxplot-Pred-Error"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents boxplots of the mean absolute error over trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 For each value of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

,
 along each optimized rollout,
 the predicted state transitions produced by kCELL are compared against ground-truth trajectories.
 Prediction error is computed and aggregated over the horizon.
\end_layout

\begin_layout Standard
As the regularization coefficient increases,
 a downward shift of the error distributions can be observed.
 Higher values of 
\begin_inset Formula $\lambda$
\end_inset

 correspond to lower median and mean prediction errors indicating that trajectories optimized under strong regularization are predicted more accurately on average by the learned model.
 This behavior is consistent with the core hypothesis of kCELL that stipulates that regions of high agent activation correspond to areas where local linear models provide the most reliable approximations of the true dynamics.
\end_layout

\begin_layout Standard
This reduction in prediction error does not arise from any modification of the learned kCELL model itself which remains fixed during evaluation.
 Instead,
 it is a direct consequent of the optimizer preferentially selecting trajectories that remain within regions of the state space that are well supported by training data.
 Thus,
 the regularization acts as a mechanism for smarter model usage rather than model improvement.
 By penalizing trajectories that lie too much in lowly covered regions,
 the optimizer performs a form of constrained optimization where the constraint is the validity of the local linear approximation.
\end_layout

\begin_layout Standard
In addition to that,
 the downward shift in mean absolute error distributions for increasing values of 
\begin_inset Formula $\lambda$
\end_inset

 is accompanied to a decrease in the spread of the error distributions.
 This indicates that large mean prediction errors become progressively less frequent as regularization strength increases.
 This suggests that distance-based regularization not only improves average prediction accuracy but also reduces the occurence of extreme prediction failures across considered initial conditions.
 This effect is particularly relevant in terms of reliability of the model as it seems to successfully prevent to some extent,
 the controller to exploit faulty out of distribution trajectories.
\end_layout

\begin_layout Standard
Overall,
 these results confirm that the spatial organization of agents in a kCELL model encodes meaningful information about local model reliability.
 This information can be effectively exploited during trajectory optimization.
 By encouraging trajectories to remain within regions of high agent coverage,
 the proposed regularization yields more accurate and more consistent predictions.
 This way it improves the reliability of model-based control with learned dynamics.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/boxplot_mean_absolute_error.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Boxplot-Pred-Error"

\end_inset

Boxplots of the mean absolute error over optimized trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the mean absolute error over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to values of 
\begin_inset Formula $\lambda$
\end_inset

.
 The blue curve corresponds to the global mean and the orange bars correspond to the median value.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Impact on Compounding Errors
\end_layout

\begin_layout Standard
One of the main limitations of learned dynamics models in model-based control is their susceptibility to error accumulation over long prediction horizons.
 Even small local inaccuracies can compound across successive rollout steps rapidly degrading the prediction quality and optimization results in the process.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pred-Error-vs-Horizon-Steps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolution of the mean absolute prediction error over the prediction horizon for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Standard
In the absence of regularization,
 for the baseline,
 the prediction error increases rapidly with the horizon length reflecting the compounding effects of model errors in multi-step rollouts.
 This behavior highlights represents a challenge in standard MPC schemes based on learned dynamics models when operating with out of distribution data 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunke2022May"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
As 
\begin_inset Formula $\lambda$
\end_inset

 values increase,
 the rate at which prediction error grows with the horizon steps is substantially reduced.
 Stronger regularization leads to consistently lower prediction errors especially for more distant horizon steps.
 This confirms that the primary benefit of the proposed regularization lies in mitigating compounding errors rather than improving one-step prediction accuracy.
\end_layout

\begin_layout Standard
Overall,
 these results show that this introspection-based regularization term improves the reliability of long-horizon predictions in MPC.
 By maintaining the trajectory within highly covered regions,
 the error propagation is dampened,
 preventing the exponential divergence typically observed in the unregularized case over the horizon.
 It reduces the myopic behavior induced by error-prone rollouts and enhances the practical usability of kCELL learned dynamics models for more reliable control policies.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/mean_prediction_error_per_horizon_step.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Pred-Error-vs-Horizon-Steps"

\end_inset

Evolution of the mean absolute error over the prediction horizon for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the mean absolute error over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to the horizon steps.
 Each colored curve corresponds to a given value of 
\begin_inset Formula $\lambda$
\end_inset

.
 The 
\begin_inset Formula $\lambda=0$
\end_inset

 curve corresponds to the unregularized baseline case.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Cost-Accuracy Tradeoff
\end_layout

\begin_layout Standard
While the introspection-based regularization term improves the reliability of predictions in a model-based control setting,
 such conservatism is expected to impact global task solving performance.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Boxplot-Cum-Cost-with-Baseline"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 show boxplots of the cumulative task cost over trajectories for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
 As 
\begin_inset Formula $\lambda$
\end_inset

 increases,
 the mean cumulative cost slightly increases compared to the unregularized baseline (
\begin_inset Formula $\lambda=0$
\end_inset

).
 This indicates that the controller increasingly sacrifices task optimality in order to remain within regions of the state space that are well supported by the learned kCELL model.
 In addition to that,
 the spread of the cost distributions decreases with stronger regularization.
 This suggests that conservative behavior leads to more uniform,
 less optimal,
 performances across initial conditions.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Mean-Cum-Cost-vs-Horizon-Steps"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the evolution of the mean cumulative cost over the horizon steps for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
 Higher regularization coefficiens 
\begin_inset Formula $\lambda$
\end_inset

 resulted in higher accumulated costs compared to the baseline.
 This effect is more pronounced for longer horizons.
 It indicates that conservative trajectory selection restricts the optimizer's ability to exploit agressive control strategies that rely extensively on extrapolation in predictions.
\end_layout

\begin_layout Standard
To explicitely relate predictive performance to task performance,
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pareto-Error-vs-Cost"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 presents a scatter plot of mean absolute prediction error over cumulative cost for various values of 
\begin_inset Formula $\lambda$
\end_inset

.
 By interpolating a cubic polynomial on those points,
 a nonlinear relationship can be observed between the prediction error and cumulative costs.
 Indeed,
 trajectories associated with lower prediction errors tend to incur higher costs.
 The interpolated curve exhibits a steep initial decrease in cost as prediction error increases,
 followed by a more gradual regime.
\end_layout

\begin_layout Standard
Overall,
 for this specific control task,
 these results reveal an explicit reliability-performance tradeoff induced by the introspection-based regularization term we introduced.
 Stronger regularization improves prediction accuracy and reduces error accumulation at the expense of control optimality.
 The shape of the tradeoff shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pareto-Error-vs-Cost"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 suggests that it is possible to find intermediate values of the regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

 that yields substantial gains in predictive accuracy for a limited increase in cost.
 Further works on different control tasks should be carried on to find a practical tuning mechanism for the conservative coefficient.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/boxplot_cost.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Boxplot-Cum-Cost-with-Baseline"

\end_inset

Boxplots of the cumulative costs over optimized trajectories for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the cumulated cost over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to values of 
\begin_inset Formula $\lambda$
\end_inset

.
 The blue curve corresponds to the global mean and the orange bars correspond to the median value.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/cost_diff_per_horizon_step.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Mean-Cum-Cost-vs-Horizon-Steps"

\end_inset

Evolution of the cumulative cost over the prediction horizon for various values of regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

.
 
\emph on
y
\emph default
-axis corresponds to the cumulative cost over optimized trajectories and 
\emph on
x
\emph default
-axis corresponds to the horizon steps.
 Each colored curve corresponds to a given value of 
\begin_inset Formula $\lambda$
\end_inset

.
 The 
\begin_inset Formula $\lambda=0$
\end_inset

 curve corresponds to the unregularized baseline case.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename assets/images/experiments/conservative/pareto_cost_vs_error.png
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Pareto-Error-vs-Cost"

\end_inset

Visualization of cumulative cost against mean absolute error.
 
\emph on
y
\emph default
-axis corresponds to the cumulative costs and 
\emph on
x
\emph default
-axis corresponds to the mean absolute errors over trajectories.
 Each colored point is associated to a value of 
\begin_inset Formula $\lambda$
\end_inset

.
 The greyed out line corresponds to a cubic interpolation.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Discussion
\end_layout

\begin_layout Standard
This experiment shows that the spatial organization of agents in kCELL can be directly exploited during trajectory optimization to improve the reliability of model-based control with a learned kCELL model.
 A distance-based regularization term derived from agent coverage is embedded into the MPC objective and it effectively bias the optimizer toward regions of the state space where the learned dynamics are supported by training data.
\end_layout

\begin_layout Standard
The results show that this regularization method leads to trajectories that remain closer to agent centers,
 reduced prediction errors and attenuated error compounding over horizon steps.
 These effects are observed without modifying the learned kCELL model.
 The improvement arises solely from how the model is exploited by the optimizer,
 rather than from improved accuracy that would be obtained by continuous learning.
 The proposed regularization mechanism does not attempt to make the model more accurate.
 Instead,
 it exploits epistemic awareness to make the better off of it.
\end_layout

\begin_layout Standard
Moreover,
 these results provide empirical support for the local expertise hypothesis that represents the core of kCELL.
 A correlation between activation of agents and reduced prediction error can be observed.
 It validates the assumption that local linear models are more and more reliable the closest the features are to their center.
 The regularization mechanism transforms this hypothesis into a control-relevant advanatage.
\end_layout

\begin_layout Standard
By increasing the regularization coefficient,
 the reduction in the growth rate of prediction error across the horizon steps improves largely the longer the horizon.
 In this case,
 it seems that the main effect of this introspection-based regularization approach lies in mitigatin erorr compounding effects.
 The regularization term prevents the optimizer from relying too much on aggressive extrapolated trajectories.
 This way,
 the controller looks to avoid MPC instabilities that arise from inaccurate predictions and misguided optimization.
 The pendulum environment is forgiving,
 because due to inertia,
 an unregularized MPC controller can recover from mistakes.
 However,
 in more complex control environments with less smooth dynamics this might not be the case and a regularization strategy could prove useful.
\end_layout

\begin_layout Standard
At the same time,
 theresults show a tradeoff between predictive accuracy and task performance in term of cumulated costs.
 Increasing conservatism leads to higher cumulative costs and lower predictive error.
 This behavior is expected and results directly from enforcing knowledge-aware regularization to the controller.
 The regularization acts as a soft feasibility constraint on the validity of the model,
 considering that unknown regions are somewhat unfeasible or dangerous.
 This is similar to trust-region methods in nonlinear optimization 
\begin_inset CommandInset citation
LatexCommand cite
key "conn2000trust,schulman2015trust"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pareto-Error-vs-Cost"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 showed that this tradeoff seems nonlinear.
 Reductions in prediction error can be obtained for relatively small increases in cost,
 suggesting that intermediate regularization strengths may offer a practical compromise between safety and performance.
 This observation is relevant for real-world applications where safety is required.
 In these cases,
 slight suboptimality is acceptable in exchange for improve reliability and reduced risk of catastrophic failure.
\end_layout

\begin_layout Standard
Overall,
 this study shows that kCELL's interpretability properties can be embedded into optimization pipelines.
 The proposed regularization mechanism consistures a principle way to translate structural transparency into conservative control behavior.
 This approach is a little step further towards reliable (i.e safe) model-based control based on learned dynamics models.
\end_layout

\begin_layout Subsubsection
Limitations
\end_layout

\begin_layout Standard
The comparative study that we conducted as well as the proposed introspection-based regularization mechanism exhibit some limitations that should be acknowledged.
\end_layout

\begin_layout Standard
In the presented experiments,
 proximity to agent centers correlates well with prediction accuracy.
 However,
 the distance-based competence measure used in this study is only a proxy for epistemic uncertainty.
 It is not a calibrated uncertainty estimate.
 As such,
 this regularization approach should be interpreted as a heuristic for risk reduction rather than a formal safety guarantee.
 Its effectiveness deeply depends on the structure and distribution of agents.
 No guarantees can be provided at the moment if the agent coverage is insufficient or poorly aligned with the true dynamics of the system.
\end_layout

\begin_layout Standard
The experiment has been conducted on a low-dimensional dynamical system (the pendulum) with smooth dynamics.
 As pointed out in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:kCELL-Discussions-and-Limitations"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 in low dimensional case,
 Mahalanobis distances (that are used for regularization) are not too distorted and remain meaningful.
 In higher dimensional cases the agent coverage might become more sparse.
 The impact of dimensionality on the effectiveness of the proposed regularization has not been studied in this chapter and remains an important limitation.
 This regularization approach might require additional mechanisms to remain effective.
\end_layout

\begin_layout Standard
We made the choice of spatializing agents only in the state space for convenience reasons to stabilize faster the agent population at learning time.
 This choice limits expressiveness of agents regarding actions.
 While this design choice is appropriate for the pendulum control task,
 it may not generalize to other dynamical systems.
 In such cases,
 regularization in joint state-action space could be required.
\end_layout

\begin_layout Standard
Another limitation relates to the density and sparsity of agent population.
 The conducted experiment rely on a single learned kCELL model trained with a fixed exploration budget.
 The effect of the sparsity of agent population on the conservative regularization behavior has not beed studied.
 Training multiple models with varying agent densities would be necessary to better characterize how coverage quality impacts the reliability gains.
\end_layout

\begin_layout Standard
In this work we show that it might be possible to find a value for the regularization coefficient 
\begin_inset Formula $\lambda$
\end_inset

 that could represent a satisfying tradeoff between performance loss and increased predictive accuracy.
 However,
 we do not provide a principled way to tune the 
\begin_inset Formula $\lambda$
\end_inset

 regularization coefficient.
 It must be done manually depending on the task nature and on the scale of task cost.
 Further investigations across different control environments are needed to extract practical insights and rules to chose the value of 
\begin_inset Formula $\lambda$
\end_inset

 depending on the problem characteristics as well as performance and predictive accuracy requirements.
\end_layout

\begin_layout Standard
Finally,
 the proposed approach improves the reliability of the controller but does not ensure safety.
 The regularization reduces the likelihood of failure due to prediction errors by discouraging extrapolation but it does not prevent it entirely.
\end_layout

\begin_layout Section
Towards Safe Explainable Control under Hard Constraints 
\begin_inset CommandInset label
LatexCommand label
name "sec:Explainable-Control-(LQR)"

\end_inset


\end_layout

\begin_layout Chapter
Scalable Non-Linear CELL
\begin_inset CommandInset label
LatexCommand label
name "chap:Scalable-Non-Linear-CELL"

\end_inset


\end_layout

\begin_layout Standard
In chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we presented an ensemble learning algorithm to solve continuous supervised learning tasks.
 Then,
 in chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we demonstrated how to use our approach to continuously model the dynamics of a system in order to solve a constrained control task.
 Through our experiments,
 we have noticed that,
 when the state and action dimensions increased,
 the concept of neighborhood as we have defined it loses its consistency and informativeness due to the dilation of distances in the feature space 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
A justifier avec une petite xp à la fin du chapitre 3
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Indeed,
 when the number of features increases,
 it is much rarer for an agent to be considered a neighbor of a new point.
 Therefore,
 the amoung of data required for training is much greater and the number of agents created grows rapidly.
 Thus,
 we identify a need to limit the growth in the number of agents to increase sample efficiency and limit redundancy in the knowledge base.
 Until now,
 to mitigate this problem,
 we needed to rely on hard-to-tune hyperparameters to define the initial size of agents on each feature 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3 ou papier PRIMA
\end_layout

\end_inset

 or on locality hypothesis on consecutive points among a given trajectory to identify relevant closest agents 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
REF chap 3
\end_layout

\end_inset

.
 In this chapter,
 we present SGP-CELL a novel approach based on Gaussian Processes 
\begin_inset CommandInset citation
LatexCommand cite
key "williams1995gaussian"
literal "false"

\end_inset

 effectively tailored for scalable online learning.
 Our contributions are threefold:
\end_layout

\begin_layout Itemize
we propose a new spatialization approach for context agents based on Principal Component Analysis (PCA) 
\begin_inset CommandInset citation
LatexCommand cite
key "jolliffe2011principal"
literal "false"

\end_inset

 to robustify neighborhoods in larger feature spaces.
\end_layout

\begin_layout Itemize
we introduce a new learning process for individual agents based on model selection and greedy objective minimization.
\end_layout

\begin_layout Itemize
we demonstrate the performances and sample efficiency of SGP-CELL compared to a Sparse Gaussian Process baseline on a forward dynamics modeling task.
\end_layout

\begin_layout Section
Related Works
\end_layout

\begin_layout Standard
Gaussian Processes (GP) are non-parametric Bayesian approaches to solve regression tasks while modeling uncertainty in predictions.
 GPs have been successful in robotics to model inverse or forward dynamics of a system to solve safe non linear control problems 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
+ de REF ?
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "berkenkamp2015safe"
literal "false"

\end_inset

.
 However,
 GP have a high computational cost with a learning complexity of 
\begin_inset Formula $O\left(kN^{3}\right)$
\end_inset

 with 
\begin_inset Formula $N$
\end_inset

 the number of training points and 
\begin_inset Formula $k$
\end_inset

 the number of optimization steps to find optimal kernel parameters,
 which results from the inversion of the covariance matrix 
\begin_inset Formula $K$
\end_inset

.
 This makes GPs no able to handle large datasets.
\end_layout

\begin_layout Standard
Approximation methods like Sparse Gaussian Processes (SGP) alleviate this scaling issue.
 Instead of using the whole training dataset to build the model,
 a set of 
\begin_inset Formula $M$
\end_inset

 inducing points (with 
\begin_inset Formula $N\gg M$
\end_inset

) are selected to represent the whole dataset.
 The inducing points allow for a cheaper low-rank representation for approximating the posterior distribution lowering the complexity to 
\begin_inset Formula $O\left(NM^{2}\right)$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "snelson2005sparse,naish2007generalized"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Other works have extended SGP with Variational Inference to further enhance scalability with stochastic minibatch optimization to handle large datasets,
 improve generalization and reduce overfitting 
\begin_inset CommandInset citation
LatexCommand cite
key "titsias2009variational,bauer2016understanding"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
For
\end_layout

\begin_layout Subsection
Gaussian Process Regression
\end_layout

\begin_layout Subsection
Online Gaussian Processes
\end_layout

\begin_layout Section
SGP-CELL
\end_layout

\begin_layout Subsection
Scaling Neighborhoods
\end_layout

\begin_layout Subsection
Non-Linear Local Modeling
\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Section
Practical Design Guidelines
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Add formalism for the whole CELL family
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Based on our experience designing our multiagent systems based on context agents for supervised learning,
 we present in this section comprehensive overview of common obstacles that must be overcome for such a system to work properly,
 allowing the emergence of learning.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
feedback (
\begin_inset Formula $\Delta$
\end_inset

)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
update shape
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\Delta$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
kCELL features
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion and limitations
\end_layout

\begin_layout Chapter
Speed Recommendation:
 Industrial Use Cases
\begin_inset CommandInset label
LatexCommand label
name "chap:Industrial-use-Case"

\end_inset


\end_layout

\begin_layout Standard
The enforcement of the EU General Safety Regulation has accelerated the adoption of Intelligent Speed Assistance (ISA) systems in new vehicles,
 emphasizing the need for reliable embedded speed recommendations.
 Unlike classical speed control approaches that are centered on vehicle dynamics modeling,
 speed recommendation requires reasoning that considers the driver in the loop,
 introducing behavioral variability and acceptance constraints.
 Designing deployable systems further demands attention to safety compliance,
 homologation requirements,
 robustness under sensor failure and potential impacts on energy consumption.
 In this chapter,
 we discuss these challenges and outline design principles for building speed recommendation systems suitable for real-world deployment and propose search directions to advance the field toward operational intelligent speed recommendation solutions.
\end_layout

\begin_layout Chapter
Conclusion and Future Works
\begin_inset CommandInset label
LatexCommand label
name "chap:Conclusion"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Mention similarities with LWPR and
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Section
Contributions
\begin_inset CommandInset label
LatexCommand label
name "sec:Contributions"

\end_inset


\end_layout

\begin_layout Plain Layout
This thesis addresses the problem of controlling complex,
 non-stationary systems with unknown dynamics with local online learning models under interpretability and explainability requirements.
 The contributions are organized around three axes:
 local online learning,
 control using learned models and prospective directions towards scalability and refining of local representations in multi-agent systems for online learning.
\end_layout

\begin_layout Subsection
Local Online Learning
\begin_inset CommandInset label
LatexCommand label
name "subsec:Local-Online-Learning"

\end_inset


\end_layout

\begin_layout Plain Layout
This section presents a set of contributions concerning the design of interpretable and adaptive learning architectures capable of improving continuously in non-stationary environments.
\end_layout

\begin_layout Plain Layout
We introduce CELL (Context Ensemble Local Learning),
 a new formalism inspired from SACL (Self Adaptive Context Learning) 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 for designing ensemble multi-agent systems that learn from local rules from an online stream of data.
 CELL provides the theoretical foundations for local adaptations that allow for online learning in non-stationary environments while preserving spatialized representations that support interpretability and epistemic uncertainty estimation.
\end_layout

\begin_layout Plain Layout
Building upon the CELL formalism,
 we propose two instantiations designed for solving regression tasks and to be usable for control.
 First,
 we propose oCELL,
 a multi-agent ensemble learning algorithm that combines orthotope-based spatialization and local predictions aggregations.
 We show that the spatial organization of agents in oCELL offers powerful introspection capabilities that can be used to enhance interpretability and explainability of the model.
 The effectiveness of oCELL is evaluated on a low dimensional benchmark through a comparative study against state-of-the-art regression methods,
 demonstrating competitive performance while offering additional introspection capabilities.
\end_layout

\begin_layout Plain Layout
Through the analysis of oCELL's limitations in terms of local representations and adaptability,
 we introduce kCELL.
 While keeping the same introspection capabilities,
 kCELL is built on a smoother spatialization approach to better represent the local manifolds and to better accomodate to non-stationary dynamics.
 Its adaptation capabilities are validated through experiments on non-stationary datasets and comparative evaluations with other learning algorithms.
\end_layout

\begin_layout Plain Layout
This iterative development from oCELL to kCELL illustrates how multiagent local learning architectures can be progressively refined to address the challenges of adaptive control.
\end_layout

\begin_layout Subsection
Control with Learned Models
\begin_inset CommandInset label
LatexCommand label
name "subsec:Control-with-Reliable-Learned-Models"

\end_inset


\end_layout

\begin_layout Plain Layout
This thesis also investigates how CELL online learning models can be integrated into control pipelines while maintaining safety and reliability.
 We show how kCELL can be integrated within optimization-based control schemes like MPC.
\end_layout

\begin_layout Plain Layout
Furthermore,
 we propose exploration and exploitation strategies that leverage the introspection capabilities of kCELL.
 At exploration time,
 introspection guides data collection toward regions where the model exhibits high uncertainty to improve the quality of the learned dynamics.
 At exploitation time,
 introspection is used to prevent optimization from going into poorly modeled regions,
 reducing the risk of unreliable control decisions.
\end_layout

\begin_layout Plain Layout
Finally,
 we introduce a novel explainability approach for constrained control that exploits the structure of kCELL to analyze and quantify the influence of constraints on optimization outcomes.
 This contribution addresses the loss of transparency commonly induced by the introduction of a black box optimizer in the context of MPC,
 where decision-making becomes opaque despite interpretable underlying models.
\end_layout

\begin_layout Subsection
Prospective Works on Scalability
\begin_inset CommandInset label
LatexCommand label
name "subsec:Prospective-Works-on-Scalability"

\end_inset


\end_layout

\begin_layout Plain Layout
Then,
 we outline prospective research directions for CELL systems.
 We discuss extensions for CELL systems aiming at improving scalability in higher-dimensional spaces through novel spatialization techniques We also discuss the use of heterogeneous local modeling approaches to increase expressiveness.
 These perspectives highlight how the CELL formalism can be extended beyond linear local models to scale to more complex local models while preserving local interpretability.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
As a summary,
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Summary-of-the-Contributions"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 maps the identified research gaps and scientific challenges to the specific contributions of this thesis.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Itemize
In this thesis we contribute to online learning and control with learned models but we do not tackle HRC as is.
 This work represents a step toward HRC,
 works still remain to do.
\end_layout

\begin_layout Plain Layout
[Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

] Contributions:
 Online Learning
\end_layout

\begin_layout Enumerate
We propose CELL (Context Ensemble Local Learning),
 a formalism inspired from SACL learning paradigm 
\begin_inset CommandInset citation
LatexCommand cite
key "boesSelfAdaptiveContextLearning2015"
literal "false"

\end_inset

 to design ensemble multiagent systems (Bottom-up approach) that learn locally from an online stream of data.
\end_layout

\begin_deeper
\begin_layout Enumerate
Why local learning?
 local updates to address the stability-plasticity dilemma and spatialization in non parametric approaches like those based on multiagent systems for supervised learning allow to estimate epistemic uncertainty (lack of knowledge) => very powerful to detect when the model is extrapolating in control (could allow the use of fallback strategies if the model not competent to answer)
\end_layout

\begin_layout Enumerate
Why new formalism?
 Lack of formalism in this field (multiagent systems for supervised learning) and algorithms not adapted for control.
\end_layout

\end_deeper
\begin_layout Enumerate
We propose oCELL system and exposed new introspection capabilities for this kind of model.
 We showed that we could extract interpretability and explainability properties from the spatial organization of agents in the feature space to analyze the system's behavior.
 We also provide a low-dimensional benchmark study (on regression task in a supervised learning setting) of CELL performance against SotA algorithms.
 
\begin_inset CommandInset citation
LatexCommand cite
key "blanco2024explainability"
literal "false"

\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Why new system ?
 Need for algorithms for regression tasks in the field (before,
 mainly classification was considered) and for smoother representations for use in control (that's why we added the aggregation function to build the global input of the model)
\end_layout

\begin_layout Enumerate
Why looking for interpretability ?
 For future certifiability and trust in HRC as shown in 
\begin_inset Quotes eld
\end_inset

Background and Motivation
\begin_inset Quotes erd
\end_inset

 Section.
\end_layout

\end_deeper
\begin_layout Enumerate
Then,
 in response to oCELL limitations,
 we introduce kCELL system and demonstrate its adaptation capabilities to non stationary dynamics through an analysis of the system using the introspection capabilities of the model.
 We also provide a comparative study of the performance of kCELL against other learning algorithms on a robotics dataset.
\end_layout

\begin_deeper
\begin_layout Enumerate
Why new system ?
 oCELL limited in its internal representations and needed to be smoothed.
\end_layout

\begin_layout Enumerate
Why studying non stationarity of the model ?
 Because we want to tackle Adaptive Control problem.
\end_layout

\end_deeper
\begin_layout Plain Layout
[Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

] Contributions:
 Control with Learned Model
\end_layout

\begin_layout Enumerate
We provide a discussion on the scalability and computational efficiency of CELL instantiations.
 We suggest the use of geospatial indexing or massively parallel GPU computations to make expert agent selection faster.
 Moreover,
 we demonstrate the differentiability of kCELL and thus,
 the possibility of integrating it into traditional gradient-based constrained optimization pipeline.
 I.e we propose the formalization of a novel coupling method to integrate the kCELL learning mechanism into traditional optimization solvers for solving complex constrained control problems with learned models.
\end_layout

\begin_deeper
\begin_layout Enumerate
Why seeking to scale ?
 As non parametric methods and relying on spatialization,
 local learning methods when ingesting too much complex data can be harder to scale in terms of computational efficiency.
 Computational efficiency can also help to couple kCELL with population-based optimization algorithms (CEM,
 MPPI,
 etc...) for control in MPC scheme.
\end_layout

\begin_layout Enumerate
Why integrate into gradient based optimization pipelines ?
 Because some gradient based solvers are able to handle constraints (ex:
 OSQP) => safety;
 and gradient based optimizers are local which fits particularly with the local structure of the considered local learning systems.
 Indeed,
 kCELL provides linearization 
\begin_inset Quotes eld
\end_inset

by design
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_deeper
\begin_layout Enumerate
We propose a novel exploration method based that uses kCELL's introspection capabilities to learn the dynamics of an environment by interaction without prior knowledge of the dynamics.
 We propose a comparative study of our approach with an uninformed random exploration strategy.
\end_layout

\begin_deeper
\begin_layout Enumerate
Why Exploring ?
 Using a learned model in a MPC scheme (model-based) condition the performance of the controller on the precision of the model.
 Learned models often struggle with out of distribution predictions.
 So without prior knowledge of the dynamics,
 it's necessary to explore exhaustively the interaction environment to build the most performance model possible.
\end_layout

\end_deeper
\begin_layout Enumerate
We propose a novel exploitation method that uses kCELL's introspection capabilities to enhance safety and enhance the reliability of the learned model in the optimization pipeline in a MPC scheme.
\end_layout

\begin_deeper
\begin_layout Enumerate
Why exploiting ?
 => Learned models often struggle with out of distribution predictions.
 At exploitation time,
 the optimizer should be aware of the limits of the model to avoid going into unmodeled regions and optimization on ghost knowledge.
 The goal is not to improve the model but ot make the best out of it.
\end_layout

\end_deeper
\begin_layout Enumerate
We propose a novel XAI method that leverages kCELL's structure to quantify and explain the impact of constraints on optimization outcomes for constrained control (safe control).
 => justification of decisions
\end_layout

\begin_deeper
\begin_layout Enumerate
Why ?
 Because using optimizers add a layer of complexity to the system making it more opaque.
 We lose interpretability and explainability during the optimization process.
 So we need mechanisms to explain the control law in MPC because interpretable dynamics model is not sufficient to justify the decisions if the optimizer is a black box.
\end_layout

\end_deeper
\begin_layout Plain Layout
[Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 (mainly prospective future works)] Contributions:
 Online Learning
\end_layout

\begin_layout Enumerate
The spatialization in oCELL and kCELL need to be improved to keep being informative in higher dimensions.
 For this reason we discuss about using a new spatialization approach based on Principal Component Analysis (PCA) to leverage feature reduction.
\end_layout

\begin_deeper
\begin_layout Enumerate
Why ?
 oCELL and kCELL spatializations are limited in the number of dimensions they can handle due to the explosion of distances in higher dimensions => need for more robust spatialization techniques.
\end_layout

\end_deeper
\begin_layout Enumerate
We show that CELL formalism can be used to scale some machine learning approaches like Gaussian Processes that are notoriously difficult to scale due to computational complexity.
\end_layout

\begin_deeper
\begin_layout Enumerate
Why ?
 We mainly used CELL systems with linear regression as local expert models.
 However,
 linear regressions are limited,
 and in most cases some regions of feature space are harder to model than others.
 Thus,
 it would be interesting to have heterogeneous agents with more complex local models in more hard to model regions and inversely.
 Gaussian Processes,
 as a non parametric machine learning approach,
 could simulate this heterogeneity by being used as internal model for agents.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="4">
<features tabularvalignment="middle">
<column alignment="left" valignment="top" width="15col%">
<column alignment="left" valignment="top" width="25col%">
<column alignment="left" valignment="top" width="25col%">
<column alignment="left" valignment="top" width="25col%">
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Focus Area
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Research Challenge
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Contribution
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Impact
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Local Online Learning
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Continuous adaptation under non-stationary dynamics with interpretable models
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CELL formalism and local learning systems (oCELL,
 kCELL)
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\emph on
(Chapter 
\emph default

\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Context-Ensemble-Local"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\emph on
)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Enables online adaptation through localized updates while preserving traceability and introspection via spatialized representations
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Control with Learned Models
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Unreliable control decisions due to model uncertainty and extrapolation
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Introspection-aware integration of kCELL into constrained MPC
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\emph on
(Chapter 
\emph default

\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\emph on
)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Improves control reliability and safety by guiding exploration and restricting optimization to well-modeled regions
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Interpretability & Explainability
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Loss of transparency in constrained optimization-based control
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Constraint influence analysis for learned-model control
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\emph on
(Chapter 
\emph default

\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Solving-Control-Tasks"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\emph on
)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Restores explainability by quantifying and justifying the impact of constraints on control decisions
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scalability & Expressiveness
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Curse of dimensionality and limited expressiveness of local models
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Non-linear and heterogeneous extensions of CELL
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\emph on
(Chapter 
\emph default

\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Scalable-Non-Linear-CELL"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset


\emph on
)
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Extends local learning to higher-dimensional spaces and complex dynamics while preserving locality and interpretability
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of the contributions 
\begin_inset CommandInset label
LatexCommand label
name "tab:Summary-of-the-Contributions"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "manuscript"
options "plain"
encoding "default"

\end_inset


\end_layout

\end_body
\end_document
